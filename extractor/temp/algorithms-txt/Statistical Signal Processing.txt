ABOUT
Statistical signal processing is an area of Applied Mathematics and Signal Processing that treats signals as stochastic processes, dealing with their statistical properties (e.g., mean, covariance, etc.). Because of its very broad range of application Statistical signal processing is taught at the graduate level in either Electrical Engineering, Applied Mathematics, Pure Mathematics/Statistics, or even Biomedical Engineering and Physics departments around the world, although important applications exist in almost all scientific fields. 
FULL TEXT
Statistical signal processing is an area of Applied Mathematics and Signal Processing that treats signals as stochastic processes, dealing with their statistical properties (e.g., mean, covariance, etc.). Because of its very broad range of application Statistical signal processing is taught at the graduate level in either Electrical Engineering, Applied Mathematics, Pure Mathematics/Statistics, or even Biomedical Engineering and Physics departments around the world, although important applications exist in almost all scientific fields. 

In many applications, a signal is modeled as functions consisting of both a deterministic and a stochastic component. A simple example and also a common model of many statistical systems is a signal 



y
(
t
)


{\displaystyle y(t)}

 that consists of a deterministic part 



x
(
t
)


{\displaystyle x(t)}

 added to noise which can be modeled in many situations as white Gaussian noise 



w
(
t
)


{\displaystyle w(t)}

:
where
White noise simply means that the noise process is completely uncorrelated. As a result, its autocorrelation function is an impulse:
where
Given information about a statistical system and the random variable from which it is derived, we can increase our knowledge of the output signal; conversely, given the statistical properties of the output signal, we can infer the properties of the underlying random variable. These statistical techniques are developed in the fields of estimation theory, detection theory, and numerous related fields that rely on statistical information to maximize their efficiency.
The Computation of Average Transients (CAT) is used routinely in FT-NMR spectroscopy (nuclear magnetic resonance) to improve the signal-noise ratio of nmr spectra. The signal is measured repeatedly n times and then averaged.
Assuming that the noise is white and that its variance is constant in time it follows by error propagation that
Thus, if 10,000 measurements are averaged the signal to noise ratio is increased by a factor of 100, enabling the measurement of 13C NMR spectra at natural abundance (1.1%) of 13C.
