ABOUT
A pseudorandom number generator (PRNG), also known as a deterministic random bit generator (DRBG),[1] is an algorithm for generating a sequence of numbers whose properties approximate the properties of sequences of random numbers. The PRNG-generated sequence is not truly random, because it is completely determined by a relatively small set of initial values, called the PRNG's seed (which may include truly random values). Although sequences that are closer to truly random can be generated using hardware random number generators, pseudorandom number generators are important in practice for their speed in number generation and their reproducibility.[2]
FULL TEXT
A pseudorandom number generator (PRNG), also known as a deterministic random bit generator (DRBG),[1] is an algorithm for generating a sequence of numbers whose properties approximate the properties of sequences of random numbers. The PRNG-generated sequence is not truly random, because it is completely determined by a relatively small set of initial values, called the PRNG's seed (which may include truly random values). Although sequences that are closer to truly random can be generated using hardware random number generators, pseudorandom number generators are important in practice for their speed in number generation and their reproducibility.[2]
PRNGs are central in applications such as simulations (e.g. for the Monte Carlo method), electronic games (e.g. for procedural generation), and cryptography. Cryptographic applications require the output not to be predictable from earlier outputs, and more elaborate algorithms, which do not inherit the linearity of simpler PRNGs, are needed.
Good statistical properties are a central requirement for the output of a PRNG. In general, careful mathematical analysis is required to have any confidence that a PRNG generates numbers that are sufficiently close to random to suit the intended use. John von Neumann cautioned about the misinterpretation of a PRNG as a truly random generator, and joked that "Anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin."[3]


A PRNG can be started from an arbitrary initial state using a seed state. It will always produce the same sequence when initialized with that state. The period of a PRNG is defined thus: the maximum, over all starting states, of the length of the repetition-free prefix of the sequence. The period is bounded by the number of the states, usually measured in bits. However, since the length of the period potentially doubles with each bit of "state" added, it is easy to build PRNGs with periods long enough for many practical applications.
If a PRNG's internal state contains n bits, its period can be no longer than 2n results, and may be much shorter. For some PRNGs, the period length can be calculated without walking through the whole period. Linear Feedback Shift Registers (LFSRs) are usually chosen to have periods of exactly 2n−1. Linear congruential generators have periods that can be calculated by factoring.[citation needed] Although PRNGs will repeat their results after they reach the end of their period, a repeated result does not imply that the end of the period has been reached, since its internal state may be larger than its output; this is particularly obvious with PRNGs with a one-bit output.
Most PRNG algorithms produce sequences which are uniformly distributed by any of several tests. It is an open question, and one central to the theory and practice of cryptography, whether there is any way to distinguish the output of a high-quality PRNG from a truly random sequence without knowing the algorithm(s) used and the state with which it was initialized. The security of most cryptographic algorithms and protocols using PRNGs is based on the assumption that it is infeasible to distinguish use of a suitable PRNG from use of a truly random sequence. The simplest examples of this dependency are stream ciphers, which (most often) work by exclusive or-ing the plaintext of a message with the output of a PRNG, producing ciphertext. The design of cryptographically adequate PRNGs is extremely difficult, because they must meet additional criteria (see below). The size of its period is an important factor in the cryptographic suitability of a PRNG, but not the only one.
In practice, the output from many common PRNGs exhibit artifacts that cause them to fail statistical pattern-detection tests. These include:
Defects exhibited by flawed PRNGs range from unnoticeable (and unknown) to very obvious. An example was the RANDU random number algorithm used for decades on mainframe computers. It was seriously flawed, but its inadequacy went undetected for a very long time.
In many fields, much research work prior to the 21st century that relied on random selection or on Monte Carlo simulations, or in other ways relied on PRNGs, is much less reliable than it might have been as a result of using poor-quality PRNGs.[4] Even today, caution is sometimes required, as illustrated by the following warning, which is given in the International Encyclopedia of Statistical Science (2010).[5]
The list of widely used generators that should be discarded is [long] ... Check the default [PRNG] of your favorite software and be ready to replace it if needed. This last recommendation has been made over and over again over the past 40 years. Perhaps amazingly, it remains as relevant today as it was 40 years ago.
As an illustration, consider the widely used programming language Java. As of 2016[update], Java still relies on a linear congruential generator (LCG) for its (non-cryptographically-secure) PRNG;[6] yet LCGs are of low quality—see further below.
The first PRNG to avoid major problems and still run fairly quickly was the Mersenne Twister (discussed below), which was published in 1998. Other high-quality PRNGs have since been developed.
In the second half of the 20th century, the standard class of algorithms used for PRNGs comprised linear congruential generators. The quality of LCGs was known to be inadequate, but better methods were unavailable. Press et al. (2007) described the result thus: "If all scientific papers whose results are in doubt because of [LCGs and related] were to disappear from library shelves, there would be a gap on each shelf about as big as your fist".[7]
A major advance in the construction of pseudorandom generators was the introduction of techniques based on linear recurrences on the two-element field; such generators are related to linear feedback shift registers.
The 1997 invention of the Mersenne Twister,[8] in particular, avoided many of the problems with earlier generators. The Mersenne Twister has a period of 219937−1 iterations (≈4.3×106001), is proven to be equidistributed in (up to) 623 dimensions (for 32-bit values), and at the time of its introduction was running faster than other statistically reasonable generators.
Subsequently, the WELL family of generators was developed.[9] The WELL generators in some ways improves on the quality of the Mersenne Twister—which has a too-large state space and a very slow recovery from state spaces with a large number of zeros.
In 2003, George Marsaglia introduced the family of xorshift generators,[10] again based on a linear recurrence. Such generators are extremely fast and, combined with a nonlinear operation, they pass strong statistical tests.[11]
A PRNG suitable for cryptographic applications is called a cryptographically secure PRNG (CSPRNG). A requirement for a CSPRNG is that an adversary not knowing the seed has only negligible advantage in distinguishing the generator's output sequence from a random sequence. In other words, while a PRNG is only required to pass certain statistical tests, a CSPRNG must pass all statistical tests that are restricted to polynomial time in the size of the seed. Though a proof of this property is beyond the current state of the art of computational complexity theory, strong evidence may be provided by reducing the CSPRNG to a problem that is assumed to be hard, such as integer factorization.[12] In general, years of review may be required before an algorithm can be certified as a CSPRNG.
Some classes of CSPRNGs include the following:
It has been shown to be likely that the NSA has inserted an asymmetric backdoor into the NIST certified pseudorandom number generator Dual_EC_DRBG.[15]
The German Federal Office for Information Security (Bundesamt für Sicherheit in der Informationstechnik, BSI) has established four criteria for quality of deterministic random number generators.[16] They are summarized here:
For cryptographic applications, only generators meeting the K3 or K4 standard are acceptable.
Given
We call a function 



f
:


N


1


→

R



{\displaystyle f:\mathbb {N} _{1}\rightarrow \mathbb {R} }

 (where 





N


1


=

{
1
,
2
,
3
,
…
}



{\displaystyle \mathbb {N} _{1}=\left\{1,2,3,\dots \right\}}

 is the set of positive integers) a pseudo-random number generator for 



P


{\displaystyle P}

 given 





F




{\displaystyle {\mathfrak {F}}}

 taking values in 



A


{\displaystyle A}

 iff
(



#
S


{\displaystyle \#S}

 denotes the number of elements in the finite set 



S


{\displaystyle S}

.)
It can be shown that if 



f


{\displaystyle f}

 is a pseudo-random number generator for the uniform distribution on 




(
0
,
1
)



{\displaystyle \left(0,1\right)}

 and if 



F


{\displaystyle F}

 is the CDF of some given probability distribution 



P


{\displaystyle P}

, then 




F

∗


∘
f


{\displaystyle F^{*}\circ f}

 is a pseudo-random number generator for 



P


{\displaystyle P}

, where 




F

∗


:

(
0
,
1
)

→

R



{\displaystyle F^{*}:\left(0,1\right)\rightarrow \mathbb {R} }

 is the percentile of 



P


{\displaystyle P}

, i.e. 




F

∗


(
x
)
:=
inf

{
t
∈

R

:
x
≤
F
(
t
)
}



{\displaystyle F^{*}(x):=\inf \left\{t\in \mathbb {R} :x\leq F(t)\right\}}

. Intuitively, an arbitrary distribution can be simulated from a simulation of the standard uniform distribution.
An early computer-based PRNG, suggested by John von Neumann in 1946, is known as the middle-square method. The algorithm is as follows: take any number, square it, remove the middle digits of the resulting number as the "random number", then use that number as the seed for the next iteration. For example, squaring the number "1111" yields "1234321", which can be written as "01234321", an 8-digit number being the square of a 4-digit number. This gives "2343" as the "random" number. Repeating this procedure gives "4896" as the next result, and so on. Von Neumann used 10 digit numbers, but the process was the same.
A problem with the "middle square" method is that all sequences eventually repeat themselves, some very quickly, such as "0000". Von Neumann was aware of this, but he found the approach sufficient for his purposes, and was worried that mathematical "fixes" would simply hide errors rather than remove them.
Von Neumann judged hardware random number generators unsuitable, for, if they did not record the output generated, they could not later be tested for errors. If they did record their output, they would exhaust the limited computer memories then available, and so the computer's ability to read and write numbers. If the numbers were written to cards, they would take very much longer to write and read. On the ENIAC computer he was using, the "middle square" method generated numbers at a rate some hundred times faster than reading numbers in from punched cards.
The middle-square method has since been supplanted by more elaborate generators.
Numbers selected from a non-uniform probability distribution can be generated using a uniform distribution PRNG and a function that relates the two distributions.
First, one needs the cumulative distribution function 



F
(
b
)


{\displaystyle F(b)}

 of the target distribution 



f
(
b
)


{\displaystyle f(b)}

:
Note that 



0
=
F
(
−
∞
)
≤
F
(
b
)
≤
F
(
∞
)
=
1


{\displaystyle 0=F(-\infty )\leq F(b)\leq F(\infty )=1}

. Using a random number c from a uniform distribution as the probability density to "pass by", we get
so that
is a number randomly selected from distribution 



f
(
b
)


{\displaystyle f(b)}

.
For example, the inverse of cumulative Gaussian distribution 




erf

−
1


⁡
(
x
)


{\displaystyle \operatorname {erf} ^{-1}(x)}

 with an ideal uniform PRNG with range (0, 1) as input 



x


{\displaystyle x}

 would produce a sequence of (positive only) values with a Gaussian distribution; however
Similar considerations apply to generating other non-uniform distributions such as Rayleigh and Poisson.