ABOUT
The control variates method is a variance reduction technique used in Monte Carlo methods. It exploits information about the errors in estimates of known quantities to reduce the error of an estimate of an unknown quantity.[1]
FULL TEXT
The control variates method is a variance reduction technique used in Monte Carlo methods. It exploits information about the errors in estimates of known quantities to reduce the error of an estimate of an unknown quantity.[1]


Let the unknown parameter of interest be 



μ


{\displaystyle \mu }

, and assume we have a statistic 



m


{\displaystyle m}

 such that the expected value of m is μ: 




E


[
m
]

=
μ


{\displaystyle \mathbb {E} \left[m\right]=\mu }

, i.e. m is an unbiased estimator for μ. Suppose we calculate another statistic 



t


{\displaystyle t}

 such that 




E


[
t
]

=
τ


{\displaystyle \mathbb {E} \left[t\right]=\tau }

 is a known value. Then
is also an unbiased estimator for 



μ


{\displaystyle \mu }

 for any choice of the coefficient 



c


{\displaystyle c}

. The variance of the resulting estimator 




m

⋆




{\displaystyle m^{\star }}

 is
It can be shown that choosing the optimal coefficient
minimizes the variance of 




m

⋆




{\displaystyle m^{\star }}

, and that with this choice,
where
is the correlation coefficient of m and t. The greater the value of 



|

ρ

m
,
t


|


{\displaystyle \vert \rho _{m,t}\vert }

, the greater the variance reduction achieved.
In the case that 





Cov



(
m
,
t
)



{\displaystyle {\textrm {Cov}}\left(m,t\right)}

, 





Var



(
t
)



{\displaystyle {\textrm {Var}}\left(t\right)}

, and/or 




ρ

m
,
t





{\displaystyle \rho _{m,t}\;}

 are unknown, they can be estimated across the Monte Carlo replicates. This is equivalent to solving a certain least squares system; therefore this technique is also known as regression sampling.
We would like to estimate
using Monte Carlo integration. This integral is the expected value of 



f
(
U
)


{\displaystyle f(U)}

, where
and U follows a uniform distribution [0, 1]. Using a sample of size n denote the points in the sample as 




u

1


,
⋯
,

u

n




{\displaystyle u_{1},\cdots ,u_{n}}

. Then the estimate is given by
Now we introduce 



g
(
x
)
=
1
+
x


{\displaystyle g(x)=1+x}

 as a control variate with a known expected value 




E


[
g

(
U
)

]

=

∫

0


1


(
1
+
x
)


d

x
=



3
2





{\displaystyle \mathbb {E} \left[g\left(U\right)\right]=\int _{0}^{1}(1+x)\,\mathrm {d} x={\tfrac {3}{2}}}

 and combine the two into a new estimate
Using 



n
=
1500


{\displaystyle n=1500}

 realizations and an estimated optimal coefficient 




c

⋆


≈
0.4773


{\displaystyle c^{\star }\approx 0.4773}

 we obtain the following results
The variance was significantly reduced after using the control variates technique. (The exact result is 



I
=
ln
⁡
2
≈
0.69314718


{\displaystyle I=\ln 2\approx 0.69314718}

.)