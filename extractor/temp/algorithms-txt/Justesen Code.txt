ABOUT
In coding theory, Justesen codes form a class of error-correcting codes that have a constant rate, constant relative distance, and a constant alphabet size.
FULL TEXT
In coding theory, Justesen codes form a class of error-correcting codes that have a constant rate, constant relative distance, and a constant alphabet size.
Before the Justesen error correction code was discovered, no error correction code was known that had all of these three parameters as a constant.
Subsequently, other ECC codes with this property have been discovered, for example expander codes. These codes have important applications in computer science such as in the construction of small-bias sample spaces.
Justesen codes are derived as the code concatenation of a Reed–Solomon code and the Wozencraft ensemble.
The Reed–Solomon codes used achieve constant rate and constant relative distance at the expense of an alphabet size that is linear in the message length.
The Wozencraft ensemble is a family of codes that achieve constant rate and constant alphabet size, but the relative distance is only constant for most of the codes in the family.
The concatenation of the two codes first encodes the message using the Reed–Solomon code, and then encodes each symbol of the codeword further using a code from the Wozencraft ensemble – using a different code of the ensemble at each position of the codeword.
This is different from usual code concatenation where the inner codes are the same for each position. The Justesen code can be constructed very efficiently using only logarithmic space.


Justesen code is concatenation code with different linear inner codes, which is composed of an 



(
N
,
K
,
D

)


q

k






{\displaystyle (N,K,D)_{q^{k}}}

 outer code 




C

o
u
t




{\displaystyle C_{out}}

 and different 



(
n
,
k
,
d

)

q




{\displaystyle (n,k,d)_{q}}

 inner codes 




C

i
n


i




{\displaystyle C_{in}^{i}}

, 



1
≤
i
≤
N


{\displaystyle 1\leq i\leq N}

.
More precisely, the concatenation of these codes, denoted by 




C

o
u
t


∘
(

C

i
n


1


,
.
.
.
,

C

i
n


N


)


{\displaystyle C_{out}\circ (C_{in}^{1},...,C_{in}^{N})}

, is defined as follows. Given a message 



m
∈
[

q

k



]

K




{\displaystyle m\in [q^{k}]^{K}}

, we compute the codeword produced by an outer code 




C

o
u
t




{\displaystyle C_{out}}

: 




C

o
u
t


(
m
)
=
(

c

1


,

c

2


,
.
.
,

c

N


)


{\displaystyle C_{out}(m)=(c_{1},c_{2},..,c_{N})}

.
Then we apply each code of N linear inner codes to each coordinate of that codeword to produce the final codeword; that is, 




C

o
u
t


∘
(

C

i
n


1


,
.
.
,

C

i
n


N


)
(
m
)
=
(

C

i
n


1


(

c

1


)
,

C

i
n


2


(

c

2


)
,
.
.
,

C

i
n


N


(

c

N


)
)


{\displaystyle C_{out}\circ (C_{in}^{1},..,C_{in}^{N})(m)=(C_{in}^{1}(c_{1}),C_{in}^{2}(c_{2}),..,C_{in}^{N}(c_{N}))}

.
Look back to the definition of the outer code and linear inner codes, this definition of the Justesen code makes sense because the codeword of the outer code is a vector with 



N


{\displaystyle N}

 elements, and we have 



N


{\displaystyle N}

 linear inner codes to apply for those 



N


{\displaystyle N}

 elements.
Here for the Justesen code, the outer code 




C

o
u
t




{\displaystyle C_{out}}

 is chosen to be Reed Solomon code over a field 





F



q

k






{\displaystyle \mathbb {F} _{q^{k}}}

 evaluated over 





F



q

k




−
{
0
}


{\displaystyle \mathbb {F} _{q^{k}}-\{0\}}

 of rate 



R


{\displaystyle R}

, 



0


{\displaystyle 0}

 < 



R


{\displaystyle R}

 < 



1


{\displaystyle 1}

.
The outer code 




C

o
u
t




{\displaystyle C_{out}}

 have the relative distance 




δ

o
u
t


=
1
−
R


{\displaystyle \delta _{out}=1-R}

 and block length of 



N
=

q

k


−
1


{\displaystyle N=q^{k}-1}

. The set of inner codes is the Wozencraft ensemble 



{

C

i
n


α



}

α
∈


F



q

k




∗






{\displaystyle \{C_{in}^{\alpha }\}_{\alpha \in \mathbb {F} _{q^{k}}^{*}}}

.
As the linear codes in the Wonzencraft ensemble have the rate 





1
2




{\displaystyle {\frac {1}{2}}}

, Justesen code is the concatenated code 




C

∗


=

C

o
u
t


∘
(

C

i
n


1


,

C

i
n


2


,
.
.
,

C

i
n


N


)


{\displaystyle C^{*}=C_{out}\circ (C_{in}^{1},C_{in}^{2},..,C_{in}^{N})}

 with the rate 





R
2




{\displaystyle {\frac {R}{2}}}

. We have the following theorem that estimates the distance of the concatenated code 




C

∗




{\displaystyle C^{*}}

.
Let 



ε
>
0.


{\displaystyle \varepsilon >0.}

 Then 




C

∗




{\displaystyle C^{*}}

 has relative distance of at least 



(
1
−
R
−
ε
)

H

q


−
1



(



1
2



−
ε
)

.


{\displaystyle (1-R-\varepsilon )H_{q}^{-1}\left({\tfrac {1}{2}}-\varepsilon \right).}


In order to prove a lower bound for the distance of a code 




C

∗




{\displaystyle C^{*}}

 we prove that the Hamming distance of an arbitrary but distinct pair of codewords has a lower bound. So let 



Δ
(

c

1


,

c

2


)


{\displaystyle \Delta (c^{1},c^{2})}

 be the Hamming distance of two codewords 




c

1




{\displaystyle c^{1}}

 and 




c

2




{\displaystyle c^{2}}

. For any given
we want a lower bound for 



Δ
(

C

∗


(

m

1


)
,

C

∗


(

m

2


)
)
.


{\displaystyle \Delta (C^{*}(m_{1}),C^{*}(m_{2})).}


Notice that if 




C

o
u
t


(
m
)
=
(

c

1


,
⋯
,

c

N


)


{\displaystyle C_{out}(m)=(c_{1},\cdots ,c_{N})}

, then 




C

∗


(
m
)
=
(

C

i
n


1


(

c

1


)
,
⋯
,

C

i
n


N


(

c

N


)
)


{\displaystyle C^{*}(m)=(C_{in}^{1}(c_{1}),\cdots ,C_{in}^{N}(c_{N}))}

. So for the lower bound 



Δ
(

C

∗


(

m

1


)
,

C

∗


(

m

2


)
)


{\displaystyle \Delta (C^{*}(m_{1}),C^{*}(m_{2}))}

, we need to take into account the distance of 




C

i
n


1


,
⋯
,

C

i
n


N


.


{\displaystyle C_{in}^{1},\cdots ,C_{in}^{N}.}


Suppose
Recall that 




{

C

i
n


1


,
⋯
,

C

i
n


N


}



{\displaystyle \left\{C_{in}^{1},\cdots ,C_{in}^{N}\right\}}

 is a Wozencraft ensemble. Due to "Wonzencraft ensemble theorem", there are at least 



(
1
−
ε
)
N


{\displaystyle (1-\varepsilon )N}

 linear codes 




C

i
n


i




{\displaystyle C_{in}^{i}}

 that have distance 




H

q


−
1



(



1
2



−
ε
)

⋅
2
k
.


{\displaystyle H_{q}^{-1}\left({\tfrac {1}{2}}-\varepsilon \right)\cdot 2k.}

 So if for some 



1
⩽
i
⩽
N
,

c

i


1


≠

c

i


2




{\displaystyle 1\leqslant i\leqslant N,c_{i}^{1}\neq c_{i}^{2}}

 and the code 




C

i
n


i




{\displaystyle C_{in}^{i}}

 has distance 



⩾

H

q


−
1



(



1
2



−
ε
)

⋅
2
k
,


{\displaystyle \geqslant H_{q}^{-1}\left({\tfrac {1}{2}}-\varepsilon \right)\cdot 2k,}

 then
Further, if we have 



T


{\displaystyle T}

 numbers 



1
⩽
i
⩽
N


{\displaystyle 1\leqslant i\leqslant N}

 such that 




c

i


1


≠

c

i


2




{\displaystyle c_{i}^{1}\neq c_{i}^{2}}

 and the code 




C

i
n


i




{\displaystyle C_{in}^{i}}

 has distance 



⩾

H

q


−
1


(



1
2



−
ε
)
⋅
2
k
,


{\displaystyle \geqslant H_{q}^{-1}({\tfrac {1}{2}}-\varepsilon )\cdot 2k,}

 then
So now the final task is to find a lower bound for 



T


{\displaystyle T}

. Define:
Then 



T


{\displaystyle T}

 is the number of linear codes 




C

i
n


i


,
i
∈
S


{\displaystyle C_{in}^{i},i\in S}

 having the distance 




H

q


−
1



(



1
2



−
ε
)

⋅
2
k
.


{\displaystyle H_{q}^{-1}\left({\tfrac {1}{2}}-\varepsilon \right)\cdot 2k.}


Now we want to estimate 




|

S

|

.


{\displaystyle |S|.}

 Obviously 




|

S

|

=
Δ
(

C

o
u
t


(

m

1


)
,

C

o
u
t


(

m

2


)
)
⩾
(
1
−
R
)
N


{\displaystyle |S|=\Delta (C_{out}(m_{1}),C_{out}(m_{2}))\geqslant (1-R)N}

.
Due to the Wozencraft Ensemble Theorem, there are at most 



ε
N


{\displaystyle \varepsilon N}

 linear codes having distance less than 




H

q


−
1


(



1
2



−
ε
)
⋅
2
k
,


{\displaystyle H_{q}^{-1}({\tfrac {1}{2}}-\varepsilon )\cdot 2k,}

 so
Finally, we have
This is true for any arbitrary 




m

1


≠

m

2




{\displaystyle m_{1}\neq m_{2}}

. So 




C

∗




{\displaystyle C^{*}}

 has the relative distance at least 



(
1
−
R
−
ε
)

H

q


−
1



(



1
2



−
ε
)

,


{\displaystyle (1-R-\varepsilon )H_{q}^{-1}\left({\tfrac {1}{2}}-\varepsilon \right),}

 which completes the proof.
We want to consider the "strongly explicit code". So the question is what the "strongly explicit code" is. Loosely speaking, for linear code, the "explicit" property is related to the complexity of constructing its generator matrix G.
That in effect means that we can compute the matrix in logarithmic space without using the brute force algorithm to verify that a code has a given satisfied distance.
For the other codes that are not linear, we can consider the complexity of the encoding algorithm.
So by far, we can see that the Wonzencraft ensemble and Reed-Solomon codes are strongly explicit. Therefore, we have the following result:
Corollary: The concatenated code 




C

∗




{\displaystyle C^{*}}

 is an asymptotically good code(that is, rate 



R


{\displaystyle R}

 > 0 and relative distance 



δ


{\displaystyle \delta }

 > 0 for small q) and has a strongly explicit construction.
The following slightly different code is referred to as the Justesen code in MacWilliams/MacWilliams. It is the particular case of the above-considered Justesen code for a very particular Wonzencraft ensemble:
Let R be a Reed-Solomon code of length N = 2m − 1, rank K and minimum weight N − K + 1.
The symbols of R are elements of F = GF(2m) and the codewords are obtained by taking every polynomial ƒ over F of degree less than K and listing the values of ƒ on the non-zero elements of F in some predetermined order.
Let α be a primitive element of F. For a codeword a = (a1, ..., aN) from R, let b be the vector of length 2N over F given by
and let c be the vector of length 2N m obtained from b by expressing each element of F as a binary vector of length m. The Justesen code is the linear code containing all such c.
The parameters of this code are length 2m N, dimension m K and minimum distance at least
where 



ℓ


{\displaystyle \ell }

 is the greatest integer satisfying 




∑

i
=
1


ℓ





(



2
m

i


)



≤
N
−
K
+
1


{\displaystyle \sum _{i=1}^{\ell }{\binom {2m}{i}}\leq N-K+1}

. (See MacWilliams/MacWilliams for a proof.)