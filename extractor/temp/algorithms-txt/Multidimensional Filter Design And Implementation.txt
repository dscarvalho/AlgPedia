ABOUT
Many concepts in one–dimensional signal processing are similar to concepts in multidimensional signal processing. However, many familiar one–dimensional procedures do not readily generalize to the multidimensional case and some important issues associated with multidimensional signals and systems do not appear in the one–dimensional special case.
FULL TEXT
Many concepts in one–dimensional signal processing are similar to concepts in multidimensional signal processing. However, many familiar one–dimensional procedures do not readily generalize to the multidimensional case and some important issues associated with multidimensional signals and systems do not appear in the one–dimensional special case.


Most of the signals we witness in real life exist in more than one dimension, be they image, video or sound among many others. A multidimensional (M-D) signal can be modeled as a function of 



M


{\displaystyle M}

 independent variables, where 



M


{\displaystyle M}

 is greater than or equal to 2. Certain concepts for multidimensional signal processing vary from one dimensional signal processing. For example, The computational complexity for multi-dimensional case is higher as it involves more dimensions. Also, assumptions of causality do not hold good for the multi-dimensional case.
A multidimensional (M-D) signal can be modeled as a function of 



M


{\displaystyle M}

 independent variables, where 



M


{\displaystyle M}

 is greater than or equal to 2. These signals may be categorized as continuous, discrete, or mixed. A continuous signal can be modeled as a function of independent variables which range over a continuum of values, example – an audio wave traveling in space.A continuous signal in the multi-dimensional case can be represented in the time domain as 



x
(

t

1


,

t

2


,
.
.
.

t

M


)


{\displaystyle x(t_{1},t_{2},...t_{M})}

.The number of arguments within the parenthesis indicates the number of dimensions of the signal.The signal in this case is of n dimensions. A discrete signal, on the other hand, can be modeled as a function defined only on a set of points, such as the set of integers.A discrete signal of 



M


{\displaystyle M}

-dimensions can be represented in the spatial domain as 



x
(

n

1


,

n

2


,
.
.
.

n

M


)


{\displaystyle x(n_{1},n_{2},...n_{M})}

. A mixed signal is a multidimensional signal that is modeled as a function of some continuous variables and some discrete ones, for example an ensemble of time waveforms recorded from an array of electrical transducers is a mixed signal. The ensemble can be modeled with one continuous variable, time, and one or more discrete variables to index the transducers.
Filtering is an application that is performed on signals whenever certain frequencies are to be removed so as to suppress interfering signals and reduce background noise. A MixeD filter is a kind of filter that is different from the traditional Finite Impulse Response(FIR) and Infinite impulse response(IIR) filters and these three filters are explained here in detail. We can combine the M-D Discrete Fourier transform(DFT) method and the M-D linear difference equation(LDE) method to filter the M-D signals. This results in the so-called combined DFT/LDE filtering technique in which the Discrete Fourier Transform is performed in some of the dimensions prior to Linear Difference Equation filtering which is performed later in the remaining dimensions. Such kind of filtering of M-D signals is referred to as Mixed domain(MixeD) filtering and the filters that perform such kind of filtering are referred to as MixeD Multidimensional Filters.[1]
Combining Discrete Transforms with Linear Difference Equations and implementing the Multidimensional filters proves to be computationally efficient and straightforward to design with low memory requirements for spatio-temporal applications such as video processing. Also the Linear Difference equations of the MixeD filters are of lower dimensionality as compared to normal multidimensional filters which results in simplification of the design and increase in the stability.[2]
Multidimensional Digital filters are finding applications in many fields such as image processing, video processing, seismic tomography, magnetic data processing, Computed tomography (CT), RADAR, Sonar and many more.[3] There is a difference between 1-D and M-D digital filter design problems. In the 1-D case, the filter design and filter implementation issues are distinct and decoupled. The 1-D filter can first be designed and then particular network structure can be determined through the appropriate manipulation of the transfer function. In the case of M-D filter design, the multidimensional polynomials cannot be factored in general. This means that an arbitrary transfer function can generally not be manipulated into a form required by a particular implementation. This makes the design and implementation of M-D filters more complex than the 1-D filters.
Multidimensional filters not unlike their one dimensional counterparts can be categorized as
In order to understand these concepts,it is necessary to understand what an impulse response means.An impulse response is basically the response of the system when the input to that system is a Unit impulse function.An impulse response in the spatial domain can be represented as 



h
(

n

1


,

n

2


,
.
.
.
.

n

n


)


{\displaystyle h(n_{1},n_{2},....n_{n})}

.
A Finite Impulse Response (FIR), or non-recursive filter has an impulse response with a finite number of non-zero samples. This makes their impulse response always absolutely summable and thus FIR filters are always stable. 



x

(


n
_


)



{\displaystyle x\left({\underline {n}}\right)}

 is the multidimensional input signal and 



y

(


n
_


)



{\displaystyle y\left({\underline {n}}\right)}

 is the multidimensional output signal. For a 



m


{\displaystyle m}

 dimensional spatial domain, the output 



y


{\displaystyle y}

 can be represented as




y

(

n

1


,

n

2


,
.
.
.
,

n

m


)

=

∑


l

1


=
0



L

1


−
1



∑


l

2


=
0



L

2


−
1


.
.
.

∑


l

m


=
0



L

m


−
1


a
(

l

1


,

l

2


,
.
.
.
,

l

m


)
x
(

n

1


−

l

1


,

n

2


−

l

2


,
.
.
.
,

n

m


−

l

m


)


{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)=\sum _{l_{1}=0}^{L_{1}-1}\sum _{l_{2}=0}^{L_{2}-1}...\sum _{l_{m}=0}^{L_{m}-1}a(l_{1},l_{2},...,l_{m})x(n_{1}-l_{1},n_{2}-l_{2},...,n_{m}-l_{m})}


The above difference equation can be represented in the Z-domain as follows




Y
(

z

1


,

z

2


,
.
.
.
.

z

m


)
=

∑


l

1


=
0



L

1


−
1



∑


l

2


=
0



L

2


−
1


.
.
.

∑


l

m


=
0



L

m


−
1


a
(

l

1


,

l

2


,
.
.
.
.

l

m


)
X
(

z

1


,

z

2


,
.
.
.

z

m


)

z

1


−

l

1





z

2


−

l

2




.
.
.
.
.
.

z

m


−

l

m






{\displaystyle Y(z_{1},z_{2},....z_{m})=\sum _{l_{1}=0}^{L_{1}-1}\sum _{l_{2}=0}^{L_{2}-1}...\sum _{l_{m}=0}^{L_{m}-1}a(l_{1},l_{2},....l_{m})X(z_{1},z_{2},...z_{m})z_{1}^{-l_{1}}z_{2}^{-l_{2}}......z_{m}^{-l_{m}}}

,
where 



X
(

z

1


,

z

2


,
.
.
.

z

m


)


{\displaystyle X(z_{1},z_{2},...z_{m})}

 and 



Y
(

z

1


,

z

2


,
.
.
.
.

z

m


)


{\displaystyle Y(z_{1},z_{2},....z_{m})}

 are the Z-transform of 



x
(

n

1


,

n

2


,
.
.
.

n

m


)


{\displaystyle x(n_{1},n_{2},...n_{m})}

, and 



y
(

n

1


,

n

2


,
.
.
.

n

m


)


{\displaystyle y(n_{1},n_{2},...n_{m})}

 respectively.
The transfer function 



H
(

z

1


,

z

2


,
.
.
.

z

m


)


{\displaystyle H(z_{1},z_{2},...z_{m})}

 is given by,




H
(

z

1


,

z

2


,
.
.
.
.

z

m


)
=
Y
(

z

1


,

z

2


,
.
.
.

z

m


)

/

X
(

z

1


,

z

2


,
.
.
.
.

z

m


)


{\displaystyle H(z_{1},z_{2},....z_{m})=Y(z_{1},z_{2},...z_{m})/X(z_{1},z_{2},....z_{m})}


In the case of FIR filters the transfer function consists of only numerator terms as the denominator is unity due to the absence of feedback.
An Infinite Impulse Response (IIR), or recursive filter (due to feedback) has infinite-extent impulse response. Its input and output satisfy a multidimensional difference equation of finite order. IIR filters may or may not be stable and in many cases are less complex to realize when compared to FIR filters. The promise of IIR filters is a potential reduction in computation compared to FIR filters when performing comparable filtering operations. by, feeding back output samples, we can use a filter with fewer coefficients (hence less computations) to implement a desired operation. On the other hand, IIR filters pose some potentially significant implementation and stabilization problems not encountered with FIR filters. The design of an M-D recursive filter is quite different from the design of a 1-D filter which is due to the increased difficulty of assuring stability. For a 



m


{\displaystyle m}

 dimensional domain, the output 



y


{\displaystyle y}

 can be represented as




y

(

n

1


,

n

2


,
.
.
.
,

n

m


)

=

∑


l

1


=
0



L

1


−
1



∑


l

2


=
0



L

2


−
1


.
.
.

∑


l

m


=
0



L

m


−
1


a
(

l

1


,

l

2


,
.
.
.
,

l

m


)
x
(

n

1


−

l

1


,

n

2


−

l

2


,
.
.
.
,

n

m


−

l

m


)
−

∑


m

1


=
0



M

1


−
1



∑


m

2


=
0



M

2


−
1


.
.
.

∑


m

m


=
0



M

m


−
1


b
(

m

1


,

m

2


,
.
.
.
,

m

m


)
y
(

n

1


−

m

1


,

n

2


−

m

2


,
.
.
.
,

n

m


−

m

m


)


{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)=\sum _{l_{1}=0}^{L_{1}-1}\sum _{l_{2}=0}^{L_{2}-1}...\sum _{l_{m}=0}^{L_{m}-1}a(l_{1},l_{2},...,l_{m})x(n_{1}-l_{1},n_{2}-l_{2},...,n_{m}-l_{m})-\sum _{m_{1}=0}^{M_{1}-1}\sum _{m_{2}=0}^{M_{2}-1}...\sum _{m_{m}=0}^{M_{m}-1}b(m_{1},m_{2},...,m_{m})y(n_{1}-m_{1},n_{2}-m_{2},...,n_{m}-m_{m})}






Y
(

z

1


,

z

2


,
.
.
.
.

z

m


)
=

∑


l

1


=
0



L

1


−
1



∑


l

2


=
0



L

2


−
1


.
.
.

∑


l

m


=
0



L

m


−
1


a
(

l

1


,

l

2


,
.
.
.
.

l

m


)
X
(

z

1


,

z

2


,
.
.
.

z

m


)

z

1


−

l

1





z

2


−

l

2




.
.
.
.
.
.

z

m


−

l

m




−

∑


m

1


=
0



M

1


−
1



∑


m

2


=
0



M

2


−
1


.
.
.

∑


m

m


=
0



M

m


−
1


b
(

m

1


,

m

2


,
.
.
.
.

m

m


)
Y
(

z

1


,

z

2


,
.
.
.

z

m


)

z

1


−

m

1





z

2


−

m

2




.
.
.
.
.
.

z

m


−

m

m






{\displaystyle Y(z_{1},z_{2},....z_{m})=\sum _{l_{1}=0}^{L_{1}-1}\sum _{l_{2}=0}^{L_{2}-1}...\sum _{l_{m}=0}^{L_{m}-1}a(l_{1},l_{2},....l_{m})X(z_{1},z_{2},...z_{m})z_{1}^{-l_{1}}z_{2}^{-l_{2}}......z_{m}^{-l_{m}}-\sum _{m_{1}=0}^{M_{1}-1}\sum _{m_{2}=0}^{M_{2}-1}...\sum _{m_{m}=0}^{M_{m}-1}b(m_{1},m_{2},....m_{m})Y(z_{1},z_{2},...z_{m})z_{1}^{-m_{1}}z_{2}^{-m_{2}}......z_{m}^{-m_{m}}}


The transfer function in this case will have both numerator and denominator terms due to the presence of feedback.
Although multidimensional difference equations represent a generalization of 1-D difference equations, they are considerably more complex and quite different. A number of important issues associated with multidimensional difference equations, such as the direction of recursion and the ordering relation, are really not an issue in the 1-D case. Other issues such as stability, although present in the 1-D case, are far more difficult to understand for multidimensional systems
Multidimensional(M-D) filtering may also be achieved by carrying out the P-dimensional Discrete Fourier transform (DFT) over P of the dimensions where (P<M) and spatio-temporal (M - P) dimensional Linear Difference Equation (LDE) filtering over the remaining dimensions. This is referred to as the combined DFT/LDE method. Such an implementation is referred to as mixed filter implementation. Instead of using Discrete Fourier Transform(DFT), other transforms such as Discrete Cosine Transform(DCT) and Discrete Hartley Transform(DHT) can also be used, depending on the application. The Discrete Cosine Transform(DCT) is often preferred for the transform coding of images because of its superior energy-compaction property while Discrete Hartley Transform(DHT) is useful when a real-valued sequence is to be mapped onto a real-valued spectrum.
In general, the M-D Linear Difference Equation (LDE) filter method convolves a real M-D input sequence x(n(M)) with a M-D unit impulse sequence h(n(M))to obtain a desired M-D output sequence y(n(M)).
y(n(M)) = x(n(M)) 



∗


⋯
M


∗


{\displaystyle *{\overset {M}{\cdots }}*}

 h(n(M)),
where 



∗


⋯
M


∗


{\displaystyle *{\overset {M}{\cdots }}*}

 refers to the M-D convolutional(convolution) operator and (n(M)) refers to the M-D signal domain index vector.
If a sequence is zero for some i and for all 




n

i




{\displaystyle n_{i}}

 > 




L

i




{\displaystyle L_{i}}

, where 




L

i


<


{\displaystyle L_{i}<}

 



∞


{\displaystyle \infty }

, that sequence is said to be duration bounded in the ith dimension. A multiplicative operator (R(M)) may be used to obtain from (x(M)) a M-D sequence that is duration bounded. An M-D sequence, 






x
¯



 


{\displaystyle {\bar {x}}\ }

(n(M)) = x(n(M))R(n(M)) is duration bounded in the first P dimensions if R(n(M)) = 1.
The MixeD filter method requires that the M-D input sequence be duration bounded in P of the M dimensions. The index (n(M)) is then ordered so that 




(

n

1


,

n

2


,
.
.
.
,

n

p


)



{\displaystyle \left(n_{1},n_{2},...,n_{p}\right)}

 corresponds to the duration-bounded dimensions. The MixeD filtering method involves a P-dimensional(P-D) discrete forward transform operation F(k(P))[.] on 






x
¯



 


{\displaystyle {\bar {x}}\ }

(n(M)) over the first P variables 




(

n

1


,

n

2


,
.
.
.
,

n

p


)



{\displaystyle \left(n_{1},n_{2},...,n_{p}\right)}

 , which we can write as X(k(P),n(M-P)) = F(k(P))[






x
¯



 


{\displaystyle {\bar {x}}\ }

(n(M))]. Examples of F(k(P))[.] are the P-Dimensional DFT, DCT and DHT. According to the MixeD filter method, each complex sequence is filtered by a (M - P)-dimensional LDE. The LDE filters have unit impulse responses h(k(P),n(M-P)). Finally the complex output sequences of the LDE filters, i.e. Y(k(P),n(M-P)) are inverse transformed using the operator F-1(k(P))[.], to give the final M-D filtered output signal, 






y
¯



 


{\displaystyle {\bar {y}}\ }

(n(M)).
The three step process can be summarized as follows,[1]
Step 1. X(k(P),n(M-P)) = F(k(P))[






x
¯



 


{\displaystyle {\bar {x}}\ }

(n(M))]
Step 2. Y(k(P),n(M-P)) = X(k(P),n(M-P)) 



∗


⋯

M
−
P



∗


{\displaystyle *{\overset {M-P}{\cdots }}*}

 h(k(P),n(M-P))
Step 3. 






y
¯



 


{\displaystyle {\bar {y}}\ }

(n(M)) = F-1(k(P))[Y(k(P),n(M-P))]
The crucial step in the MixeD filter design is the 2nd step. This is because filtering takes place in this step. Since there is no filtering involved in Steps 1 and 3, there is no need to weigh the transform coefficients.
The block diagram which shows the MixeD filter method can be seen below. 
Output of any Linear Shift Invariant (LSI) filter can be determined from its input by means of the convolution sum. There are a finite number of non-zero samples and the limits of summation are finite for a FIR filter. The convolution sum serves as an algorithm that enables us to compute the successive output samples of the filter. As an example, let is assume that the filter has support over the region {(




n

1




{\displaystyle n_{1}}

,




n

2




{\displaystyle n_{2}}

,...,




n

m




{\displaystyle n_{m}}

): 



0


{\displaystyle 0}

 ≤ 




n

1




{\displaystyle n_{1}}

 < 




N

1




{\displaystyle N_{1}}

 , 



0


{\displaystyle 0}

 ≤ 




n

2




{\displaystyle n_{2}}

 < 




N

2




{\displaystyle N_{2}}

,...,



0


{\displaystyle 0}

 ≤ 




n

m




{\displaystyle n_{m}}

 < 




N

m




{\displaystyle N_{m}}

 }, the output samples can be computed using[4]




y

(

n

1


,

n

2


,
.
.
.
,

n

m


)

=

∑


k

1


=
0



N

1


−
1



∑


k

2


=
0



N

2


−
1


.
.
.

∑


k

m


=
0



N

m


−
1


h
(

k

1


,

k

2


,
.
.
.
,

k

m


)
x
(

n

1


−

k

1


,

n

2


−

k

2


,
.
.
.
,

n

m


−

k

m


)


{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)=\sum _{k_{1}=0}^{N_{1}-1}\sum _{k_{2}=0}^{N_{2}-1}...\sum _{k_{m}=0}^{N_{m}-1}h(k_{1},k_{2},...,k_{m})x(n_{1}-k_{1},n_{2}-k_{2},...,n_{m}-k_{m})}


If all input samples are available, the output samples can be computed in any order or can also be computed simultaneously. However, if only selected samples of the output are desired, only those samples need to be computed. The number of multiplications and additions for one desired output sample is (




N

1




{\displaystyle N_{1}}

.




N

2




{\displaystyle N_{2}}

...




N

m




{\displaystyle N_{m}}

) and (




N

1




{\displaystyle N_{1}}

.




N

2




{\displaystyle N_{2}}

...




N

m




{\displaystyle N_{m}}

)–



1


{\displaystyle 1}

 respectively.
For the 2D case, the computation of 



y

(

n

1


,

n

2


)



{\displaystyle y\left(n_{1},n_{2}\right)}

 depends on input samples from (




N

1




{\displaystyle N_{1}}

 – 



1


{\displaystyle 1}

) previous columns of the input and the (




N

2




{\displaystyle N_{2}}

 – 



1


{\displaystyle 1}

) previous rows. If the input samples arrive row by row, we need sufficient storage to store 




N

2




{\displaystyle N_{2}}

 rows of the input sequence. If the input is available column by column instead, we need to store 




N

1




{\displaystyle N_{1}}

 columns of the input. A zero phase filter with a real impulse response satisfies 



h

(

n

1


,

n

2


)



{\displaystyle h\left(n_{1},n_{2}\right)}

 = 



h

(
−

n

1


,
−

n

2


)



{\displaystyle h\left(-n_{1},-n_{2}\right)}

, which means that each sample can be paired with another of identical value. In this case we can use the arithmetic distributive law to interchange some of the multiplications and additions, to reduce the number of multiplications necessary to implement the filter, but the number of multiplications is still proportional to the filter order. Specifically, if the region of support for the filter is assumed to be rectangular and centered at the origin, we have




y

(

n

1


,

n

2


)

=

∑


k

1


=
−

N

1





N

1





∑


k

2


=
−

N

2





N

2




h
(

k

1


,

k

2


)
x
(

n

1


−

k

1


,

n

2


−

k

2


)


{\displaystyle y\left(n_{1},n_{2}\right)=\sum _{k_{1}=-N_{1}}^{N_{1}}\sum _{k_{2}=-N_{2}}^{N_{2}}h(k_{1},k_{2})x(n_{1}-k_{1},n_{2}-k_{2})}






y

(

n

1


,

n

2


)

=

∑


k

1


=
−

N

1





N

1





∑


k

2


=
1



N

2




h
(

k

1


,

k

2


)
[
x
(

n

1


−

k

1


,

n

2


−

k

2


)
+
x
(

n

1


+

k

1


,

n

2


+

k

2


)
]
+

∑


k

1


=
1



N

1




h
(

k

1


,
0
)
[
x
(

n

1


−

k

1


,

n

2


)
+
x
(

n

1


+

k

1


,

n

2


)
]
+
h
(
0
,
0
)
x
(

n

1


,

n

2


)


{\displaystyle y\left(n_{1},n_{2}\right)=\sum _{k_{1}=-N_{1}}^{N_{1}}\sum _{k_{2}=1}^{N_{2}}h(k_{1},k_{2})[x(n_{1}-k_{1},n_{2}-k_{2})+x(n_{1}+k_{1},n_{2}+k_{2})]+\sum _{k_{1}=1}^{N_{1}}h(k_{1},0)[x(n_{1}-k_{1},n_{2})+x(n_{1}+k_{1},n_{2})]+h(0,0)x(n_{1},n_{2})}


Using the above equation to implement an FIR filter requires roughly one-half the number of multiplications of an implementation, although both implementations require the same number of additions and the same amount of storage. If the impulse response of an FIR filter possess other symmetries, they can be exploited in a similar fashion to reduce further the number of required multiplications.
The FIR filter can also be implemented by means of the Discrete Fourier transform (DFT). This can be particularly appealing for high-order filters because the various Fast Fourier transform algorithms permit the efficient evaluation of the DFT. The general form of DFT for multidimensional signals can be seen below, where 



N


{\displaystyle N}

 is periodicity matrix, 



x
(


n
_


)


{\displaystyle x({\underline {n}})}

 is the multidimensional signal in the space domain, 



X
(


k
_


)


{\displaystyle X({\underline {k}})}

 is the DFT of 



x
(


n
_


)


{\displaystyle x({\underline {n}})}

 in frequency domain, 




I

N




{\displaystyle I_{N}}

 is a region containing |



d
e
t
N


{\displaystyle detN}

| samples in 



n


{\displaystyle n}

 domain, and 




J

N




{\displaystyle J_{N}}

 is a region containing |



d
e
t

N

T




{\displaystyle detN^{T}}

| (



=
d
e
t
N


{\displaystyle =detN}

) frequency samples.[4]




X

(


k
_


)

=

∑

n
ϵ

I

n




x

(


n
_


)


e

−
j



k
_



T



(
2
π



N
_



−
1


)



n
_






{\displaystyle X\left({\underline {k}}\right)=\sum _{n\epsilon I_{n}}x\left({\underline {n}}\right)e^{-j{\underline {k}}^{T}\left(2\pi {\underline {N}}^{-1}\right){\underline {n}}}}


Let 



y

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)}

 be the linear convolution of a finite-extent sequence 



x

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle x\left(n_{1},n_{2},...,n_{m}\right)}

 with the impulse response 



h

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle h\left(n_{1},n_{2},...,n_{m}\right)}

 of an FIR filter.




y

(

n

1


,

n

2


,
.
.
.
,

n

m


)

=
x

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗
h

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)=x\left(n_{1},n_{2},...,n_{m}\right)*h\left(n_{1},n_{2},...,n_{m}\right)}


On computing Fourier Transform of both sides of this expression, we get




Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)

=
X

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle Y\left(w_{1},w_{2},...,w_{m}\right)=X\left(w_{1},w_{2},...,w_{m}\right)}





H

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle H\left(w_{1},w_{2},...,w_{m}\right)}


There are many possible definitions of the M-D discrete Fourier transform, and that all of these correspond to sets of samples of the M-D Fourier transform; these DFT's can be used to perform convolutions as long their assumed region of support contains the support for 



y

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)}

. Let us assume that 



Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle Y\left(w_{1},w_{2},...,w_{m}\right)}

 is sampled on a 




N

1




{\displaystyle N_{1}}

x




N

2




{\displaystyle N_{2}}

x...x




N

m




{\displaystyle N_{m}}

 rectangular lattice of samples, and let




Y

(

k

1


,

k

2


,
.
.
.
,

k

m


)

=
Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)


|


w

1


=



2
π

k

1




N

1




;

w

2


=



2
π

k

2




N

2




;
.
.
.
;

w

m


=



2
π

k

m




N

m






{\displaystyle Y\left(k_{1},k_{2},...,k_{m}\right)=Y\left(w_{1},w_{2},...,w_{m}\right)|w_{1}={\frac {2\pi k_{1}}{N_{1}}};w_{2}={\frac {2\pi k_{2}}{N_{2}}};...;w_{m}={\frac {2\pi k_{m}}{N_{m}}}}


Therefore, 



Y

(

k

1


,

k

2


,
.
.
.
,

k

m


)

=
X

(

k

1


,

k

2


,
.
.
.
,

k

m


)



{\displaystyle Y\left(k_{1},k_{2},...,k_{m}\right)=X\left(k_{1},k_{2},...,k_{m}\right)}





H

(

k

1


,

k

2


,
.
.
.
,

k

m


)



{\displaystyle H\left(k_{1},k_{2},...,k_{m}\right)}

.
To compute (




N

1




{\displaystyle N_{1}}

x




N

2




{\displaystyle N_{2}}

x...x




N

m




{\displaystyle N_{m}}

)-point DFT's of 



x


{\displaystyle x}

 and 



h


{\displaystyle h}

 requires that both sequences have their regions of support extended with samples of value zero. If 






y
^




(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle {\hat {y}}\left(n_{1},n_{2},...,n_{m}\right)}

 results from the inverse DFT of the product 



X

(

k

1


,

k

2


,
.
.
.
,

k

m


)



{\displaystyle X\left(k_{1},k_{2},...,k_{m}\right)}

.



H

(

k

1


,

k

2


,
.
.
.
,

k

m


)



{\displaystyle H\left(k_{1},k_{2},...,k_{m}\right)}

 , then 






y
^




(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle {\hat {y}}\left(n_{1},n_{2},...,n_{m}\right)}

 will be the circular convolution of 



h

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle h\left(n_{1},n_{2},...,n_{m}\right)}

 and 



x

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle x\left(n_{1},n_{2},...,n_{m}\right)}

. If 




N

1




{\displaystyle N_{1}}

, 




N

2




{\displaystyle N_{2}}

,..., 




N

m




{\displaystyle N_{m}}

 are chosen to be at least equal to the size of 



y

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)}

, then 






y
^




(

n

1


,

n

2


,
.
.
.
,

n

m


)

=
y

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle {\hat {y}}\left(n_{1},n_{2},...,n_{m}\right)=y\left(n_{1},n_{2},...,n_{m}\right)}

. This implementation technique is efficient with respect to computation, however it is prodigal with respect to storage as this method requires sufficient storage to contain all 




N

1




{\displaystyle N_{1}}

x




N

2




{\displaystyle N_{2}}

x...x




N

m




{\displaystyle N_{m}}

 points of the signal 



x

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle x\left(n_{1},n_{2},...,n_{m}\right)}

. In addition, we must store the filter response coefficients 



H

(

k

1


,

k

2


,
.
.
.
,

k

m


)



{\displaystyle H\left(k_{1},k_{2},...,k_{m}\right)}

. By direct convolution the number of rows of the input that needs to be stored depends on the order of the filter. However, with the DFT the whole input must be stored regardless of the filter order.
For the 2D case, and assuming that 



H

(

k

1


,

k

2


)



{\displaystyle H\left(k_{1},k_{2}\right)}

 is pre-computed, the number of real multiplications needed to compute 



y

(

n

1


,

n

2


)



{\displaystyle y\left(n_{1},n_{2}\right)}

 is




2


{\displaystyle 2}

x




N

1




{\displaystyle N_{1}}

x




N

2




{\displaystyle N_{2}}

x




log

2




{\displaystyle \log _{2}}






N

1




{\displaystyle N_{1}}

x




N

2




{\displaystyle N_{2}}

 



+


{\displaystyle +}

 



2


{\displaystyle 2}

x




N

1




{\displaystyle N_{1}}

x




N

2




{\displaystyle N_{2}}

; 




N

1




{\displaystyle N_{1}}

 and 




N

2




{\displaystyle N_{2}}

 are powers of 2
The arithmetic complexity of the DFT implementation of an FIR filter is effectively independent of the order of the filter, while the complexity of a direct convolution implementation is proportional to the filter order. So, the convolution implementation would be more efficient for the lower filter order. As, the filter order increases, the DFT implementation would eventually become more efficient.[4]
The problem with the DFT implementation is that it requires a large storage. The block convolution method offers a compromise. With these approaches the convolutions are performed on sections or blocks of data using DFT methods. Limiting the size of these blocks limits the amount of storage required and using transform methods maintains the efficiency of the procedure.
The simplest block convolution method is called the overlap-add technique. We begin by partitioning 2-D array, 



x

(

n

1


,

n

2


)



{\displaystyle x\left(n_{1},n_{2}\right)}

, into (




N

1




{\displaystyle N_{1}}

x




N

2




{\displaystyle N_{2}}

) point sections, where the section indexed by the pair (




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

) is defined as below:





x


k

1



k

2





(

n

1


,

n

2


)

=
x

(

n

1


,

n

2


)


if 


k

1



N

1


≤

n

1


<
(

k

1


+
1
)

N

1



and 


k

2



N

2


≤

n

2


<
(

k

2


+
1
)

N

2




{\displaystyle x_{k_{1}k_{2}}\left(n_{1},n_{2}\right)=x\left(n_{1},n_{2}\right){\text{if }}k_{1}N_{1}\leq n_{1}<(k_{1}+1)N_{1}{\text{and }}k_{2}N_{2}\leq n_{2}<(k_{2}+1)N_{2}}


The regions of support for the different sections do not overlap, and collectively they cover the entire region of support of the array 



x

(

n

1


,

n

2


)



{\displaystyle x\left(n_{1},n_{2}\right)}

. Thus,




x

(

n

1


,

n

2


)

=

∑


k

1





∑


k

2





x


k

1



k

2





(

n

1


,

n

2


)



{\displaystyle x\left(n_{1},n_{2}\right)=\sum _{k_{1}}\sum _{k_{2}}x_{k_{1}k_{2}}\left(n_{1},n_{2}\right)}


Because the operation of discrete convolution distributes with respect to addition, 



y

(

n

1


,

n

2


)



{\displaystyle y\left(n_{1},n_{2}\right)}

 can be written as follows:




y

(

n

1


,

n

2


)

=
x

(

n

1


,

n

2


)

∗
∗
h

(

n

1


,

n

2


)

=

(

∑


k

1





∑


k

2





x


k

1



k

2





(

n

1


,

n

2


)

)

∗
∗
h

(

n

1


,

n

2


)

=

∑


k

1





∑


k

2





(

x


k

1



k

2





(

n

1


,

n

2


)

∗
∗
h

(

n

1


,

n

2


)

)

=

∑


k

1





∑


k

2





y


k

1



k

2





(

n

1


,

n

2


)



{\displaystyle y\left(n_{1},n_{2}\right)=x\left(n_{1},n_{2}\right)**h\left(n_{1},n_{2}\right)=\left(\sum _{k_{1}}\sum _{k_{2}}x_{k_{1}k_{2}}\left(n_{1},n_{2}\right)\right)**h\left(n_{1},n_{2}\right)=\sum _{k_{1}}\sum _{k_{2}}\left(x_{k_{1}k_{2}}\left(n_{1},n_{2}\right)**h\left(n_{1},n_{2}\right)\right)=\sum _{k_{1}}\sum _{k_{2}}y_{k_{1}k_{2}}\left(n_{1},n_{2}\right)}


Figure (a) shows the section of the input array 




x

21



(

n

1


,

n

2


)



{\displaystyle x_{21}\left(n_{1},n_{2}\right)}

. Figure (b) shows the region of support of the convolution of that section with 



h


{\displaystyle h}

 that is 




y

21



(

n

1


,

n

2


)



{\displaystyle y_{21}\left(n_{1},n_{2}\right)}

.
The block output 




y


k

1



k

2





(

n

1


,

n

2


)



{\displaystyle y_{k_{1}k_{2}}\left(n_{1},n_{2}\right)}

 is the convolution of 



h

(

n

1


,

n

2


)



{\displaystyle h\left(n_{1},n_{2}\right)}

 with block 




(

k

1


,

k

2


)



{\displaystyle \left(k_{1},k_{2}\right)}

 of 



x

(

n

1


,

n

2


)



{\displaystyle x\left(n_{1},n_{2}\right)}

. The result of the block convolution must be added together to produce the complete filter output 



y

(

n

1


,

n

2


)



{\displaystyle y\left(n_{1},n_{2}\right)}

. As the support of 




y


k

1



k

2





(

n

1


,

n

2


)



{\displaystyle y_{k_{1}k_{2}}\left(n_{1},n_{2}\right)}

 is greater than the support of 




x


k

1



k

2





(

n

1


,

n

2


)



{\displaystyle x_{k_{1}k_{2}}\left(n_{1},n_{2}\right)}

, the output blocks will of necessity overlap, but the degree of that overlap is limited.
The convolutions of the 




x


k

1



k

2





(

n

1


,

n

2


)



{\displaystyle x_{k_{1}k_{2}}\left(n_{1},n_{2}\right)}

 and 



h
(

n

1


,

n

2


)


{\displaystyle h(n_{1},n_{2})}

 can be evaluated by means of discrete Fourier transforms, provided that the size of the transform is large enough to support 




y


k

1



k

2





(

n

1


,

n

2


)



{\displaystyle y_{k_{1}k_{2}}\left(n_{1},n_{2}\right)}

. By controlling the block size we can limit the size of the DFTs, which reduces the required storage.
The overlap-save method is an alternative block convolution technique. When the block size is considerably larger than the support of 



h


{\displaystyle h}

, the samples of 



y


{\displaystyle y}

 in the center of each block are not overlapped by samples from neighboring blocks. Similarly, when a sequence 



x


{\displaystyle x}

 is circularly convolved with another, 



h


{\displaystyle h}

, which has a much smaller region of support, only a subset of the samples of that circular convolution will show the effects of the spatial aliasing. The remaining samples of the circular convolution will be identical to the samples of the linear convolution. Thus if an 



(

N

1




{\displaystyle (N_{1}}

×




N

2


)


{\displaystyle N_{2})}

 -point section of 



x

(

n

1


,

n

2


)



{\displaystyle x\left(n_{1},n_{2}\right)}

 is circularly convolved with an 



(

M

1




{\displaystyle (M_{1}}

×




M

2


)


{\displaystyle M_{2})}

 -point impulse response using an 



(

N

1




{\displaystyle (N_{1}}

×




N

2


)


{\displaystyle N_{2})}

 -point DFT, the resulting circular convolution will contain a cluster of 




(

N

1


−

M

1


+
1
)



{\displaystyle \left(N_{1}-M_{1}+1\right)}

 ×




(

N

2


−

M

2


+
1
)



{\displaystyle \left(N_{2}-M_{2}+1\right)}

 samples which are identical to samples of the linear convolution, 



y


{\displaystyle y}

. The whole output array can be constructed form these "good" samples by carefully choosing the regions of support for the input sections. If the input sections are allowed to overlap, the "good" samples of the various blocks can be made to abut. The overlap-save method thus involves overlapping input sections, whereas the overlap-add method involves overlapping output sections.
The figure above shows the overlap-save method. The shaded region gives those samples of 



y


{\displaystyle y}

 for which both the 



(

N

1




{\displaystyle (N_{1}}

×




N

2


)


{\displaystyle N_{2})}

 circular convolution and the linear convolution of 



x


{\displaystyle x}

 with 



h


{\displaystyle h}

 are identical.
For both the overlap-add and overlap-save procedures, the choice of block size affects the efficiency of the resulting implementation. It affects the amount of storage needed, and also affects the amount of computation.
The frequency response of a multi-dimensional filter is given by,




H
(

w

1


,

w

2


,
.
.
.

w

n


)
=

∑


n

1


=
0



N

1


−
1



∑


n

2


=
0



N

2


−
1


.
.
.

∑


n

n


=
0



N

n


−
1


h
(

n

1


,

n

2


,
.
.
.
.

n

n


)

e

−
j

w

1



n

1





e

−
j

w

2



n

2




.
.
.
.
.

e

−
j

w

n



n

n






{\displaystyle H(w_{1},w_{2},...w_{n})=\sum _{n_{1}=0}^{N_{1}-1}\sum _{n_{2}=0}^{N_{2}-1}...\sum _{n_{n}=0}^{N_{n}-1}h(n_{1},n_{2},....n_{n})e^{-jw_{1}n_{1}}e^{-jw_{2}n_{2}}.....e^{-jw_{n}n_{n}}}


where 



h
(

n

1


,

n

2


,
.
.
.
.

n

n


)


{\displaystyle h(n_{1},n_{2},....n_{n})}

 is the impulse response of the designed filter for size 




N

1


×

N

2


×
.
.
.
.
.

N

n




{\displaystyle N_{1}\times N_{2}\times .....N_{n}}


The frequency response of the ideal filter is given by




I
(

w

1


,

w

2


,
.
.
.

w

n


)
=

∑


n

1


=
−
∞


∞



∑


n

2


=
−
∞


∞


.
.
.

∑


n

n


=
−
∞


∞


i
(

n

1


,

n

2


,
.
.
.
.

n

n


)

e

−
j

w

1



n

1





e

−
j

w

2



n

2




.
.
.
.
.

e

−
j

w

n



n

n






{\displaystyle I(w_{1},w_{2},...w_{n})=\sum _{n_{1}=-\infty }^{\infty }\sum _{n_{2}=-\infty }^{\infty }...\sum _{n_{n}=-\infty }^{\infty }i(n_{1},n_{2},....n_{n})e^{-jw_{1}n_{1}}e^{-jw_{2}n_{2}}.....e^{-jw_{n}n_{n}}}


where 



i
(

n

1


,

n

2


,
.
.
.

n

n


)


{\displaystyle i(n_{1},n_{2},...n_{n})}

 is the impulse response of the ideal filter.
The error measure is given by subtracting the above two results i.e.




E
(

w

1


,

w

2


,
.
.
.
.

w

n


)
=
H
(

w

1


,

w

2


,
.
.
.
.
.

w

n


)
−
I
(

w

1


,

w

2


,
.
.
.
.
.

w

n


)


{\displaystyle E(w_{1},w_{2},....w_{n})=H(w_{1},w_{2},.....w_{n})-I(w_{1},w_{2},.....w_{n})}


The maximum of this error measure is what needs to be minimized.There are different norms available for minimizing the error namely:





L

2


n
o
r
m


{\displaystyle L_{2}norm}

 given by the formula





E

2


=
[
1

/

(
2
π

)

n



∫

−
π


π



∫

−
π


π


.
.
.

∫

−
π


π




|
E
(

w

1


,

w

2


,
.
.
.

w

n


)
|


2


d

w

1


d

w

2


.
.
.
d

w

n



]

1

/

2




{\displaystyle E_{2}=[1/(2\pi )^{n}\int \limits _{-\pi }^{\pi }\int \limits _{-\pi }^{\pi }...\int \limits _{-\pi }^{\pi }\left\vert E(w_{1},w_{2},...w_{n})\right\vert ^{2}dw_{1}dw_{2}...dw_{n}]^{1/2}}







L

p


n
o
r
m


{\displaystyle L_{p}norm}

 given by the formula





E

p


=
[
1

/

(
2
π

)

n



∫

−
π


π



∫

−
π


π


.
.
.

∫

−
π


π




|
E
(

w

1


,

w

2


,
.
.
.

w

n


)
|


p


d

w

1


d

w

2


.
.
.
d

w

n



]

1

/

p




{\displaystyle E_{p}=[1/(2\pi )^{n}\int \limits _{-\pi }^{\pi }\int \limits _{-\pi }^{\pi }...\int \limits _{-\pi }^{\pi }\left\vert E(w_{1},w_{2},...w_{n})\right\vert ^{p}dw_{1}dw_{2}...dw_{n}]^{1/p}}


if p =2 we get the 




L

2


n
o
r
m


{\displaystyle L_{2}norm}

 and if p tends to 



∞


{\displaystyle \infty }

 we get the 




L

∞




{\displaystyle L_{\infty }}

 norm.The 




L

∞




{\displaystyle L_{\infty }}

 norm is given by,





E

∞


=

max

(

w

1


,

w

2


,
.
.
.

w

n


∈
B
)



|
E
(

w

1


,

w

2


,
.
.
.

w

n


)
|



{\displaystyle E_{\infty }=\max _{(w_{1},w_{2},...w_{n}\in B)}\left\vert E(w_{1},w_{2},...w_{n})\right\vert }


When we say minimax design the 




L

∞




{\displaystyle L_{\infty }}

 norm is what comes to mind.
Another method to design a multidimensional FIR filter is by the transformation from 1-D filters. This method was first developed by McClellan as other methods were time consuming and cumbersome. The first successful implementation was achieved by Mecklenbrauker and Mersereau[5][6] and was later revised by McClellan and Chan.[7] For a zero phase filter the one phase impulse response is given by[4]




h
(
 


n
_


)
=

h

∗


(
−
 


n
_


)


{\displaystyle h(\ {\underline {n}})=h^{*}(-\ {\underline {n}})}


where 




h

∗


(
−
 


n
_


)


{\displaystyle h^{*}(-\ {\underline {n}})}

 represents the complex conjugate of 



h
(
 


n
_


)


{\displaystyle h(\ {\underline {n}})}

.
Let 



H
(
 


w
_


)


{\displaystyle H(\ {\underline {w}})}

 be the frequency response of 



h
(
 


n
_


)


{\displaystyle h(\ {\underline {n}})}

.Assuming 



h
(
 


n
_


)


{\displaystyle h(\ {\underline {n}})}

 is even,we can write




H
(
w
)
=

∑

n
=
0


N



a

n


c
o
s
(
w
n
)


{\displaystyle H(w)=\sum _{n=0}^{N}a_{n}cos(wn)}


where 




a

n




{\displaystyle a_{n}}

 is defined as 




a

n


=
h
(
0
)


{\displaystyle a_{n}=h(0)}

 if n=0 and 




a

n


=
2
h
(
n
)


{\displaystyle a_{n}=2h(n)}

 if n



≠


{\displaystyle \neq }

0.Also 



c
o
s
(
w
n
)


{\displaystyle cos(wn)}

 is a polynomial of degree n known as the Chebyshev polynomial.
The variable is 



c
o
s
(
w
)


{\displaystyle cos(w)}

 and the polynomial can be represented by 




T

n


(
c
o
s
(
w
)
)


{\displaystyle T_{n}(cos(w))}

.
Thus 



H
(
w
)
=

∑

n
=
0


N


a
(
n
)

T

n


(
c
o
s
(
w
)
)


{\displaystyle H(w)=\sum _{n=0}^{N}a(n)T_{n}(cos(w))}

 is the required 1-D frequency response in terms of Chebyshev polynomial 




T

n


(
c
o
s
(
w
)
)


{\displaystyle T_{n}(cos(w))}

.
If we consider 



F
(

w

1


,

w

2


,
.
.
.

w

n


)


{\displaystyle F(w_{1},w_{2},...w_{n})}

 to be a transformation function where



F
(

w

1


,

w

2


,
.
.
.

w

n


)


{\displaystyle F(w_{1},w_{2},...w_{n})}

 maps to 



c
o
s
(
w
)


{\displaystyle cos(w)}

,then we get,




H
(

w

1


,

w

2


,
.
.
.
.

w

n


)
=

∑

n
=
0


N



a

n



T

n


[
F
(

w

1


,

w

2


,
.
.
.

w

n


)
]


{\displaystyle H(w_{1},w_{2},....w_{n})=\sum _{n=0}^{N}a_{n}T_{n}[F(w_{1},w_{2},...w_{n})]}


The contours and the symmetry of 



H
(

w

1


,

w

2


,
.
.
.
.
.

w

n


)


{\displaystyle H(w_{1},w_{2},.....w_{n})}

 depend on that of 



F
(

w

1


,

w

2


,
.
.
.
.

w

n


)


{\displaystyle F(w_{1},w_{2},....w_{n})}

. 



F
(

w

1


,

w

2


,
.
.
.
.

w

n


)


{\displaystyle F(w_{1},w_{2},....w_{n})}

 is also called the mapping function.
The values of 



H
(

w

1


,

w

2


,
.
.
.

w

n


)


{\displaystyle H(w_{1},w_{2},...w_{n})}

 can be obtained from the values of the 1_D prototype 



H
(
w
)


{\displaystyle H(w)}

.
The conditions for choosing the mapping function are
Considering a two dimensional case to compute the size of 



H
(

w

1


,

w

2


)


{\displaystyle H(w_{1},w_{2})}

, If the 1-D prototype has size 



(
2
N
+
1
)


{\displaystyle (2N+1)}

 and the mapping function has size 



(
2
Q
+
1
)
∗
(
2
Q
+
1
)


{\displaystyle (2Q+1)*(2Q+1)}

,then the size of the desired 



H
(

w

1


,

w

2


)


{\displaystyle H(w_{1},w_{2})}

 will be 



(
2
N
Q
+
1
)
∗
(
2
N
Q
+
1
)


{\displaystyle (2NQ+1)*(2NQ+1)}


The main advantages of this method are
Methods such as Convolution or implementation using the DFT can be used for the implementation of FIR filters. However, for filters of moderate order another method can be used which justifies the design using transformation.Consider the equation for a 2-dimensional case,




H
(

w

1


,

w

2


)
=

∑

n
=
0


N



a

n



T

n


[
F
(

w

1


,

w

2


)
]


{\displaystyle H(w_{1},w_{2})=\sum _{n=0}^{N}a_{n}T_{n}[F(w_{1},w_{2})]}


where,




T

n


[
F
(

w

1


,

w

2


)
]


{\displaystyle T_{n}[F(w_{1},w_{2})]}

 is a Chebyshev polynomial.These polynomials are defined as,





T

0


[
x
]
=
1


{\displaystyle T_{0}[x]=1}







T

1


[
x
]
=
x


{\displaystyle T_{1}[x]=x}







T

n


[
x
]
=
2
x

T

n
−
1


[
x
]
−

T

n
−
2


[
x
]
.


{\displaystyle T_{n}[x]=2xT_{n-1}[x]-T_{n-2}[x].}


Using this we can form a digital network to realize the 2-D frequency response as shown in the figure below.Replacing x by 



F
(

w

1


,

w

2


)


{\displaystyle F(w_{1},w_{2})}

 we get,





T

n


[
F
(

w

1


,

w

2


)
]
=
2
F
(

w

1


,

w

2


)

T

n
−
1


[
F
(

w

1


,

w

2


)
]
−

T

n
−
2


[
F
(

w

1


,

w

2


)
]


{\displaystyle T_{n}[F(w_{1},w_{2})]=2F(w_{1},w_{2})T_{n-1}[F(w_{1},w_{2})]-T_{n-2}[F(w_{1},w_{2})]}


Since each of these signals can be generated from two lower order signals, a ladder network of N outputs can be formed such that frequency response between the input and nth output is 




T

n


[
F
(

w

1


,

w

2


)


{\displaystyle T_{n}[F(w_{1},w_{2})}

 .By weighting these outputs according to the equation mentioned below, The filter 



H
(

w

1


,

w

2


)


{\displaystyle H(w_{1},w_{2})}

 can be realized.




H
(

w

1


,

w

2


)
=

∑

n
=
0


N



a

n



T

n


[
F
(

w

1


,

w

2


)
]


{\displaystyle H(w_{1},w_{2})=\sum _{n=0}^{N}a_{n}T_{n}[F(w_{1},w_{2})]}


This realization is as shown in the figure below.
In the figure,the filters F define the transformation function and h(n) is the impulse response of the 1-D prototype filter .
Here we discuss a method for multidimensional FIR filter design via sum-of-squares formulations of spectral mask constraints. The sum-of-squares optimization problem is expressed as a semidefinite program with low-rank structure, by sampling the constraints using discrete sine and cosine transforms. The resulting semidefinite program is then solved by a customized primal-dual interior-point method that exploits low-rank structure. This leads to substantial reduction in the computational complexity, compared to general-purpose semidefinite programming methods that exploit sparsity.[8]
A variety of one-dimensional FIR filter design problems can be expressed as convex optimization problems over real trigonometric polynomials, subject to spectral mask constraints. These optimization problems can be formulated as semidefinite programs (SDPs) using classical sum-of-squares (SOS) characterizations of nonnegative polynomials, and solved efficiently via interior-point methods for semidefinite programming.

For the figure above, FIR filter in frequency domain with d=2; n1=n2=5 and has 61 sampling points. The extension of these techniques to multidimensional filter design poses several difficulties. First, SOS characterization of multivariate positive trigonometric polynomials may require factors of arbitrarily high degree. Second, difficulty stems from the large size of the semidefinite programming problems obtained from multivariate SOS programs. Most recent research on exploiting structure in semidefinite programming has focused on exploiting sparsity of the coefficient matrices. This technique is very useful for SDPs derived from SOS programs and are included in several general purpose semidefinite programming packages.
Let 




Z

d




{\displaystyle Z_{d}}

 and 




N

d




{\displaystyle N_{d}}

 denote the sets of d-vectors of integers and natural numbers, respectively. For a vector 



x


{\displaystyle x}

, we define 



d
i
a
g

(
x
)



{\displaystyle diag\left(x\right)}

 as the diagonal matrix with 




x

i




{\displaystyle x_{i}}

 as its ith diagonal entry. For a square matrix 



X


{\displaystyle X}

, 



d
i
a
g

(
X
)



{\displaystyle diag\left(X\right)}

 is a vector with the 




i

t
h




{\displaystyle i^{th}}

 entry 



X
i
i


{\displaystyle Xii}

. The matrix inequality 



A
>≥
B


{\displaystyle A>\geq B}

 denotes that 



A
−
B


{\displaystyle A-B}

 is positive definite (semidefinite). 



T
r

(
A
)



{\displaystyle Tr\left(A\right)}

 denotes the trace of a symmetric matrix 



A


{\displaystyle A}

.




R


{\displaystyle R}

 is a 



d


{\displaystyle d}

-variate trigonometric polynomial of degree 



n
ϵ

Z

d




{\displaystyle n\epsilon Z_{d}}

, with real symmetric coefficients 




x

k




{\displaystyle x_{k}}

 = 




x

−
k




{\displaystyle x_{-k}}






R

(
w
)

=

∑

k
=
−
n


n



x

k



e

−
j

k

T


w




{\displaystyle R\left(w\right)=\sum _{k=-n}^{n}x_{k}e^{-jk^{T}w}}


The above summation is over all integer vectors 



k


{\displaystyle k}

 that satisfy 



−
n
≤
k
≤
n


{\displaystyle -n\leq k\leq n}

, where the inequalities between the vectors are interpreted element-wise. 



R


{\displaystyle R}

 is positive on 



[
−
π
,
π

]

d




{\displaystyle [-\pi ,\pi ]^{d}}

, then it can be expressed as sum of squares of trigonometric polynomials





H

l



(
w
)

=

∑

l
=
1


r



|


H

l



(
w
)



|


2




{\displaystyle H_{l}\left(w\right)=\sum _{l=1}^{r}|H_{l}\left(w\right)|^{2}}







H

l



(
w
)

=

∑

k
=
0



n

l





h

l
,
k



e

−
j

k

T


w




{\displaystyle H_{l}\left(w\right)=\sum _{k=0}^{n_{l}}h_{l,k}e^{-jk^{T}w}}


2-D FIR Filter Design as SOS Program: 



H


{\displaystyle H}

 is taken to be the frequency response of a 2-D linear phase FIR filter with filter order 



n
=

(

n

1


,

n

2


)



{\displaystyle n=\left(n_{1},n_{2}\right)}

, with filter coefficients 




h

k




{\displaystyle h_{k}}

 = 




h

−
k




{\displaystyle h_{-k}}

.




H

(
w
)

=

∑

k
=
−
n


n



h

k



e

−
j

k

T


w




{\displaystyle H\left(w\right)=\sum _{k=-n}^{n}h_{k}e^{-jk^{T}w}}


We want to determine the filter coefficients 




h

k




{\displaystyle h_{k}}

 that maximize the attenuation 




δ

s




{\displaystyle \delta _{s}}

 in the stopband 




D

s




{\displaystyle D_{s}}

 for a given maximum allowable ripple (




δ

p




{\displaystyle \delta _{p}}

) in the passband 




D

p




{\displaystyle D_{p}}

. The optimization problem is to minimize 




δ

s




{\displaystyle \delta _{s}}

 by subjecting to the following conditions





|

1
−
H

(
w
)


|

≤

δ

p


,


w
ϵ

D

p




{\displaystyle |1-H\left(w\right)|\leq \delta _{p},\,\,w\epsilon D_{p}}







|

H

(
w
)


|

≤

δ

s


,


w
ϵ

D

s




{\displaystyle |H\left(w\right)|\leq \delta _{s},\,\,w\epsilon D_{s}}


where the scalar 




δ

s




{\displaystyle \delta _{s}}

 and the filter coefficients 




h

k




{\displaystyle h_{k}}

 are the problem variables. These constraints are as shown below





R

1



(
w
)

=
H

(
w
)

−
1
+

δ

p


≥
0
,


w
ϵ

D

p




{\displaystyle R_{1}\left(w\right)=H\left(w\right)-1+\delta _{p}\geq 0,\,\,w\epsilon D_{p}}







R

2



(
w
)

=
1
−
H

(
w
)

+

δ

p


≥
0
,


w
ϵ

D

p




{\displaystyle R_{2}\left(w\right)=1-H\left(w\right)+\delta _{p}\geq 0,\,\,w\epsilon D_{p}}







R

3



(
w
)

=
H

(
w
)

+

δ

s


≥
0
,


w
ϵ

D

s




{\displaystyle R_{3}\left(w\right)=H\left(w\right)+\delta _{s}\geq 0,\,\,w\epsilon D_{s}}







R

4



(
w
)

=
H

(
w
)

−

δ

s


≥
0
,


w
ϵ

D

s




{\displaystyle R_{4}\left(w\right)=H\left(w\right)-\delta _{s}\geq 0,\,\,w\epsilon D_{s}}


If the passband and stopband are defined, then we can replace each positive polynomial 




R

i




{\displaystyle R_{i}}

 by a weighted sum of squares expression. Limiting the degrees of the sum-of-squares polynomials to 



n


{\displaystyle n}

 then gives sufficient conditions for feasibility. We call the resulting optimization problem a sum-of-squares program and can be solved via semidefinite programming.
In some applications, where access to all values of signal is available (i.e. where entire signal is stored in memory and is available for processing), the concept of "feedback" can be realized. The iterative approach uses the previous output as feedback to generate successively better approximations to the desired output signal.[4]
In general, the IIR frequency response can be expressed as




H

(

w

1


,

w

2


,
.
.
.
,

w

m


)

=



A

(

w

1


,

w

2


,
.
.
.
,

w

m


)



B

(

w

1


,

w

2


,
.
.
.
,

w

m


)




=




∑


l

1





∑


l

2




.
.
.

∑


l

m




a

(

l

1


,

l

2


,
.
.
.
,

l

m


)


e

−
j

(

w

1



l

1


+

w

2



l

2


+
.
.
.
+

w

m



l

m


)






∑


k

1





∑


k

2




.
.
.

∑


k

m




b

(

k

1


,

k

2


,
.
.
.
,

k

m


)


e

−
j

(

w

1



k

1


+

w

2



k

2


+
.
.
.
+

w

m



k

m


)








{\displaystyle H\left(w_{1},w_{2},...,w_{m}\right)={\frac {A\left(w_{1},w_{2},...,w_{m}\right)}{B\left(w_{1},w_{2},...,w_{m}\right)}}={\frac {\sum _{l_{1}}\sum _{l_{2}}...\sum _{l_{m}}a\left(l_{1},l_{2},...,l_{m}\right)e^{-j\left(w_{1}l_{1}+w_{2}l_{2}+...+w_{m}l_{m}\right)}}{\sum _{k_{1}}\sum _{k_{2}}...\sum _{k_{m}}b\left(k_{1},k_{2},...,k_{m}\right)e^{-j\left(w_{1}k_{1}+w_{2}k_{2}+...+w_{m}k_{m}\right)}}}}


where 



a

(

l

1


,

l

2


,
.
.
.
,

l

m


)



{\displaystyle a\left(l_{1},l_{2},...,l_{m}\right)}

 and 



b

(

k

1


,

k

2


,
.
.
.
,

k

m


)



{\displaystyle b\left(k_{1},k_{2},...,k_{m}\right)}

 are M-D finite extent coefficient arrays. The ratio is normalized so that 



b

(
0
,
0
,
.
.
.
,
0
)

=
1


{\displaystyle b\left(0,0,...,0\right)=1}


Now, let 



X

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle X\left(w_{1},w_{2},...,w_{m}\right)}

 represent the spectrum of a M-D input signal 



x

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle x\left(n_{1},n_{2},...,n_{m}\right)}

 and 



Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle Y\left(w_{1},w_{2},...,w_{m}\right)}

 represent the spectrum of a M-D output signal 



y

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)}

.




Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)

=
A

(

w

1


,

w

2


,
.
.
.
,

w

m


)

X

(

w

1


,

w

2


,
.
.
.
,

w

m


)

+
C

(

w

1


,

w

2


,
.
.
.
,

w

m


)

Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle Y\left(w_{1},w_{2},...,w_{m}\right)=A\left(w_{1},w_{2},...,w_{m}\right)X\left(w_{1},w_{2},...,w_{m}\right)+C\left(w_{1},w_{2},...,w_{m}\right)Y\left(w_{1},w_{2},...,w_{m}\right)}


where 



C

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle C\left(w_{1},w_{2},...,w_{m}\right)}

 is a trigonometric polynomial defined as 



C

(

w

1


,

w

2


,
.
.
.
,

w

m


)

=
1
−
B

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle C\left(w_{1},w_{2},...,w_{m}\right)=1-B\left(w_{1},w_{2},...,w_{m}\right)}


In the signal domain, the equation becomes 



y

(

n

1


,

n

2


,
.
.
.
,

n

m


)

=
a

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗
x

(

n

1


,

n

2


,
.
.
.
,

n

m


)

+
c

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗
y

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)=a\left(n_{1},n_{2},...,n_{m}\right)*x\left(n_{1},n_{2},...,n_{m}\right)+c\left(n_{1},n_{2},...,n_{m}\right)*y\left(n_{1},n_{2},...,n_{m}\right)}


After making an initial guess, and then substituting the guess in the above equation iteratively, a better approximation of 



y

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y\left(n_{1},n_{2},...,n_{m}\right)}

 can be obtained – 




y

i



(

n

1


,

n

2


,
.
.
.
,

n

m


)

=
a

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗
x

(

n

1


,

n

2


,
.
.
.
,

n

m


)

+
c

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗

y

i
−
1



(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle y_{i}\left(n_{1},n_{2},...,n_{m}\right)=a\left(n_{1},n_{2},...,n_{m}\right)*x\left(n_{1},n_{2},...,n_{m}\right)+c\left(n_{1},n_{2},...,n_{m}\right)*y_{i-1}\left(n_{1},n_{2},...,n_{m}\right)}


where 



i


{\displaystyle i}

 denotes the iteration index
In the frequency domain, the above equation becomes 




Y

i



(

w

1


,

w

2


,
.
.
.
,

w

m


)

=
A

(

w

1


,

w

2


,
.
.
.
,

w

m


)

X

(

w

1


,

w

2


,
.
.
.
,

w

m


)

+
C

(

w

1


,

w

2


,
.
.
.
,

w

m


)


Y

i
−
1



(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle Y_{i}\left(w_{1},w_{2},...,w_{m}\right)=A\left(w_{1},w_{2},...,w_{m}\right)X\left(w_{1},w_{2},...,w_{m}\right)+C\left(w_{1},w_{2},...,w_{m}\right)Y_{i-1}\left(w_{1},w_{2},...,w_{m}\right)}


An IIR filter is BIBO stable if 



C

(

w

1


,

w

2


,
.
.
.
,

w

m


)

≠
0


{\displaystyle C\left(w_{1},w_{2},...,w_{m}\right)\neq 0}


If we assume that 




|

C

(

w

1


,

w

2


,
.
.
.
,

w

m


)


|

<
1


{\displaystyle |C\left(w_{1},w_{2},...,w_{m}\right)|<1}

 then





lim

I
→
∞



Y

I



(

w

1


,

w

2


,
.
.
.
,

w

m


)

=



A

(

w

1


,

w

2


,
.
.
.
,

w

m


)

X

(

w

1


,

w

2


,
.
.
.
,

w

m


)



1
−
C

(

w

1


,

w

2


,
.
.
.
,

w

m


)




=
Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle \lim _{I\to \infty }Y_{I}\left(w_{1},w_{2},...,w_{m}\right)={\frac {A\left(w_{1},w_{2},...,w_{m}\right)X\left(w_{1},w_{2},...,w_{m}\right)}{1-C\left(w_{1},w_{2},...,w_{m}\right)}}=Y\left(w_{1},w_{2},...,w_{m}\right)}



Thus, it can be said that, the frequency response 



H

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle H\left(w_{1},w_{2},...,w_{m}\right)}

 of a M-D IIR filter can be obtained by infinite number of M-D FIR filtering operations. The store operator stores the result of the previous iteration.
To be practical, an iterative IIR filter should require fewer computations, counting all iterations to achieve an acceptable error, compared to an FIR filter with similar performance.
Similar to its 1-D special case, M-D IIR filters can have dramatically lower order than FIR filters with similar performance. This motivates the development of design techniques for M-D IIR filtering algorithms. This section presents brief overview of approaches for designing M-D IIR filters.
This technique is based on minimizing the error functionals in the space domain. The coefficient arrays 



a

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle a\left(n_{1},n_{2},...,n_{m}\right)}

 and 



b

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle b\left(n_{1},n_{2},...,n_{m}\right)}

 are determined such that the output response 



y

(

n

1


,

n

2


)



{\displaystyle y\left(n_{1},n_{2}\right)}

 of a filter matches the desired response 



d

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle d\left(n_{1},n_{2},...,n_{m}\right)}

.[4]
Let us denote the error signal as




e

(

n

1


,

n

2


,
.
.
.
,

n

m


)

=
y

(

n

1


,

n

2


,
.
.
.
,

n

m


)

−
d

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle e\left(n_{1},n_{2},...,n_{m}\right)=y\left(n_{1},n_{2},...,n_{m}\right)-d\left(n_{1},n_{2},...,n_{m}\right)}


And let 



E

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle E\left(w_{1},w_{2},...,w_{m}\right)}

 denote it's the Fourier transform




E

(

w

1


,

w

2


,
.
.
.
,

w

m


)

=



A

(

w

1


,

w

2


,
.
.
.
,

w

m


)

X

(

w

1


,

w

2


,
.
.
.
,

w

m


)



B

(

w

1


,

w

2


,
.
.
.
,

w

m


)




−
D

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle E\left(w_{1},w_{2},...,w_{m}\right)={\frac {A\left(w_{1},w_{2},...,w_{m}\right)X\left(w_{1},w_{2},...,w_{m}\right)}{B\left(w_{1},w_{2},...,w_{m}\right)}}-D\left(w_{1},w_{2},...,w_{m}\right)}


By multiplying both sides by 



B

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle B\left(w_{1},w_{2},...,w_{m}\right)}

, we get the modified error spectrum, converted in discrete domain as





e
′


(

n

1


,

n

2


,
.
.
.
,

n

m


)

=
a

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗
x

(

n

1


,

n

2


,
.
.
.
,

n

m


)

−
b

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗
d

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle e'\left(n_{1},n_{2},...,n_{m}\right)=a\left(n_{1},n_{2},...,n_{m}\right)*x\left(n_{1},n_{2},...,n_{m}\right)-b\left(n_{1},n_{2},...,n_{m}\right)*d\left(n_{1},n_{2},...,n_{m}\right)}


The total mean-squared error is obtained as





e

2

′


(

n

1


,

n

2


,
.
.
.
,

n

m


)

=

∑


n

1





∑


n

2




.
.
.

∑


n

m




[

e
′


(

n

1


,

n

2


,
.
.
.
,

n

m


)


]

2




{\displaystyle e'_{2}\left(n_{1},n_{2},...,n_{m}\right)=\sum _{n_{1}}\sum _{n_{2}}...\sum _{n_{m}}[e'\left(n_{1},n_{2},...,n_{m}\right)]^{2}}


Let the input signal be 



δ

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle \delta \left(n_{1},n_{2},...,n_{m}\right)}

. Now, the numerator coefficient 



a

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle a\left(n_{1},n_{2},...,n_{m}\right)}

 is zero outside region 



0
≤

n

1


≤

N

1


−
1

&

0
≤

n

2


≤

N

2


−
1...
,
0
≤

n

m


≤

N

m


−
1


{\displaystyle 0\leq n_{1}\leq N_{1}-1\,\&\,0\leq n_{2}\leq N_{2}-1...,0\leq n_{m}\leq N_{m}-1}

 because of the ROS of input signal.Then equation becomes





e
′


(

n

1


,

n

2


,
.
.
.
,

n

m


)

=
−

∑


q

1


=
0



M

1


−
1



∑


q

2


=
0



M

2


−
1


.
.
.

∑


q

m


=
0



M

m


−
1


b

(

q

1


,

q

2


,
.
.
,

q

m


)

d

(

n

1


−

q

1


,

n

2


−

q

2


)


;



{\displaystyle e'\left(n_{1},n_{2},...,n_{m}\right)=-\sum _{q_{1}=0}^{M_{1}-1}\sum _{q_{2}=0}^{M_{2}-1}...\sum _{q_{m}=0}^{M_{m}-1}b\left(q_{1},q_{2},..,q_{m}\right)d\left(n_{1}-q_{1},n_{2}-q_{2}\right)\,;\,}

 for 




n

1


≥

N

1


−
1


{\displaystyle n_{1}\geq N_{1}-1}

 or 




n

2


≥

N

2


−
1


{\displaystyle n_{2}\geq N_{2}-1}

 or ... 




n

m


≥

N

m


−
1


{\displaystyle n_{m}\geq N_{m}-1}


Substituting the result 




e
′



{\displaystyle e'}

 into 




e

2

′



{\displaystyle e_{2}'}

 and differentiating 




e

2

′



{\displaystyle e'_{2}}

 with respect to denominator coefficients 



b

(

q

1


,

q

2


,
.
.
.
,

q

n


)



{\displaystyle b\left(q_{1},q_{2},...,q_{n}\right)}

, the linear set of equations is obtained as





∑


m

1


=
0



M

1


−
1



∑


m

2


=
0



M

2


−
1


.
.
.

∑


m

m


=
0



M

m


−
1


b

(

m

1


,

m

2


,
.
.
.
,

m

m


)

r

(

m

1


,

m

2


,
.
.
.
,

m

m


;

q

1


,

q

2


,
.
.
.
,

q

m


)

=
0

;



{\displaystyle \sum _{m_{1}=0}^{M_{1}-1}\sum _{m_{2}=0}^{M_{2}-1}...\sum _{m_{m}=0}^{M_{m}-1}b\left(m_{1},m_{2},...,m_{m}\right)r\left(m_{1},m_{2},...,m_{m};q_{1},q_{2},...,q_{m}\right)=0\,;\,}

 for 



0
≤

m

1


<

M

1


;
0
≤

m

2


<

M

2


;
.
.
.
;
0
≤

m

m


<

M

m




{\displaystyle 0\leq m_{1}<M_{1};0\leq m_{2}<M_{2};...;0\leq m_{m}<M_{m}}



Now, taking the double summation for the region "R" i.e. for 




n

1


≥

N

1


−
1


{\displaystyle n_{1}\geq N_{1}-1}

 and 




n

2


≥

N

2


−
1


{\displaystyle n_{2}\geq N_{2}-1}

 and ... 




n

m


≥

N

m


−
1


{\displaystyle n_{m}\geq N_{m}-1}

 shown in figure (shown for 2-D case), the coefficients 



b

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle b\left(n_{1},n_{2},...,n_{m}\right)}

 are obtained.
The coefficients 



a

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle a\left(n_{1},n_{2},...,n_{m}\right)}

 can be obtained from




a

(

n

1


,

n

2


,
.
.
.
,

n

m


)

≈
b

(

n

1


,

n

2


,
.
.
.
,

n

m


)

∗
d

(

n

1


,

n

2


,
.
.
.
,

n

m


)



{\displaystyle a\left(n_{1},n_{2},...,n_{m}\right)\approx b\left(n_{1},n_{2},...,n_{m}\right)*d\left(n_{1},n_{2},...,n_{m}\right)}


The major advantage of Shank's method is that IIR filter coefficients can be obtained by solving linear equations. The disadvantage is that the mean squared error between 



y


{\displaystyle y}

 and 



d


{\displaystyle d}

 is not minimized. Also, the stability is not certain.
Shank's method is a spatial-domain design method. It is also possible to design IIR filters in the frequency domain. Here our aim would be to minimize the error in the frequency domain and not the spatial domain.Due to Parseval's theorem we observe that the mean squared error will be identical to that in the spatial domain.Parseval's theorem states that[4]





∑


n

1





∑


n

2




.
.
.

∑


n

n




[
y
(

n

1


,

n

2


,
.
.
.
.

n

n


)
−
d
(

n

1


,

n

2


,
.
.
.
.

n

n


)

]

2


=
1

/

(
2
π

)

n



∫

−
π


π



∫

−
π


π


.
.
.
.

∫

−
π


π




|
Y
(

w

1


,

w

2


,
.
.
.

w

n


)
−
D
(

w

1


,

w

2


,
.
.
.

w

n


)
|


2


d

w

1


d

w

2


.
.
d

w

n




{\displaystyle \sum _{n_{1}}\sum _{n_{2}}...\sum _{n_{n}}[y(n_{1},n_{2},....n_{n})-d(n_{1},n_{2},....n_{n})]^{2}=1/(2\pi )^{n}\int \limits _{-\pi }^{\pi }\int \limits _{-\pi }^{\pi }....\int \limits _{-\pi }^{\pi }\left\vert Y(w_{1},w_{2},...w_{n})-D(w_{1},w_{2},...w_{n})\right\vert ^{2}dw_{1}dw_{2}..dw_{n}}


Also the different norms that are used for FIR filter design such as 




L

2




{\displaystyle L_{2}}

,




L

p




{\displaystyle L_{p}}

 and 




L

∞




{\displaystyle L_{\infty }}

 can also be used for the design of IIR filters





E

p


=
[
1

/

(
2
π

)

n



∫

−
π


π



∫

−
π


π


.
.
.

∫

−
π


π




|
E
(

w

1


,

w

2


,
.
.
.

w

n


)
|


p


d

w

1


d

w

2


.
.
.
d

w

n



]

1

/

p




{\displaystyle E_{p}=[1/(2\pi )^{n}\int \limits _{-\pi }^{\pi }\int \limits _{-\pi }^{\pi }...\int \limits _{-\pi }^{\pi }\left\vert E(w_{1},w_{2},...w_{n})\right\vert ^{p}dw_{1}dw_{2}...dw_{n}]^{1/p}}


is the required equation for the 




L

p




{\displaystyle L_{p}}

 norm and when p tends to 



∞


{\displaystyle \infty }

 we get the 




L

∞




{\displaystyle L_{\infty }}

 norm as explained above





E

∞


=

max

(

w

1


,

w

2


,
.
.
.

w

n


∈
B
)



|
E
(

w

1


,

w

2


,
.
.
.

w

n


)
|



{\displaystyle E_{\infty }=\max _{(w_{1},w_{2},...w_{n}\in B)}\left\vert E(w_{1},w_{2},...w_{n})\right\vert }


The main advantages of design in the frequency domain are
The main disadvantage of this technique is that there is no guarantee for stability.
General minimization techniques as seen in the design of IIR filters in the spatial domain can be used in the frequency domain too.
One popular method for frequency domain design is the Magnitude and magnitude squared algorithms.
In this section, we examine the technique for designing 2-D IIR filters based on minimizing error functionals in the frequency domain. The mean-squared error is given as






1


(
2
π
)


m





∫

−
π


π



∫

−
π


π


.
.
.

∫

−
π


π



|

Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)

−
D

(

w

1


,

w

2


,
.
.
.
,

w

m


)



|


2


d

w

1


d

w

2


.
.
.
d

w

m




{\displaystyle {\frac {1}{\left(2\pi \right)^{m}}}\int _{-\pi }^{\pi }\int _{-\pi }^{\pi }...\int _{-\pi }^{\pi }|Y\left(w_{1},w_{2},...,w_{m}\right)-D\left(w_{1},w_{2},...,w_{m}\right)|^{2}dw_{1}dw_{2}...dw_{m}}


The below function 




J

a




{\displaystyle J_{a}}

 is the measure of difference between two complex functions - the desired response 



D

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle D\left(w_{1},w_{2},...,w_{m}\right)}

 and the actual response 



Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle Y\left(w_{1},w_{2},...,w_{m}\right)}

. Generally, we can define a complex function 



f


{\displaystyle f}

 of 



Y


{\displaystyle Y}

 to approximate the desired response 



D


{\displaystyle D}

. Hence, the optimization task boils down to the task of minimizing 



f
(
Y
)
−
D


{\displaystyle f(Y)-D}

.





J

a


=

∑

k


W

(

w

1
k


,

w

2
k


,
.
.
.
,

w

m
k


)

[
f

(



A

(

w

1
k


,

w

2
k


,
.
.
.
,

w

m
k


)



B

(

w

1
k


,

w

2
k


,
.
.
.
,

w

m
k


)




)

−
D

(

w

1
k


,

w

2
k


,
.
.
.
,

w

m
k


)


]

2




{\displaystyle J_{a}=\sum _{k}W\left(w_{1k},w_{2k},...,w_{mk}\right)[f\left({\frac {A\left(w_{1k},w_{2k},...,w_{mk}\right)}{B\left(w_{1k},w_{2k},...,w_{mk}\right)}}\right)-D\left(w_{1k},w_{2k},...,w_{mk}\right)]^{2}}


where 



W

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle W\left(w_{1},w_{2},...,w_{m}\right)}

 is the weighting function and 




(

w

1
k


,

w

2
k


,
.
.
.

w

m
k


)



{\displaystyle \left(w_{1k},w_{2k},...w_{mk}\right)}

 are frequency domain samples selected for minimization. Now, consider a case, where we ignore the phase response of the filter i.e. we concentrate on only matching the magnitude (or square of magnitude) of the desired and actual filter response. Linearization can be used to find out the coefficients 



{
a

(

n

1


,

n

2


,
.
.
.
,

w

m


)


b

(

n

1


,

n

2


,
.
.
.
,

w

m


)

}


{\displaystyle \{a\left(n_{1},n_{2},...,w_{m}\right)\,b\left(n_{1},n_{2},...,w_{m}\right)\}}

 that results in minimum value of 




J

a




{\displaystyle J_{a}}

. This will ensure that the filter form can be represented by a finite order difference equation. The stability of the filter depends on the function



Y

(

w

1


,

w

2


,
.
.
.
,

w

m


)



{\displaystyle Y\left(w_{1},w_{2},...,w_{m}\right)}

.
The disadvantages of this method are,
This design procedure includes a stability error 




J

s




{\displaystyle J_{s}}

, which is to be minimized together with the usual approximation error 




J

a




{\displaystyle J_{a}}

.[9] The stability error is a crude measure of how unstable a filter is. It is a type of penalty function. It should be zero for stable filters and large for the unstable filters. The filters can be designed by minimizing[4]




J
=

J

a


+
a

J

s




{\displaystyle J=J_{a}+aJ_{s}}






a


{\displaystyle a}

 is a positive constraint which weights the relative importance of 




J

a




{\displaystyle J_{a}}

 and 




J

s




{\displaystyle J_{s}}

. Ekstrom et al.[9] used the nonlinear optimization techniques to minimize 



J


{\displaystyle J}

. Their stability error was based on the difference between the denominator coefficient array and the minimum-phase array with the same autocorrelation function.
The minimum phase array can be determined by first computing the autocorrelation function of the denominator coefficient array 



b

(

n

1


,

n

2


)



{\displaystyle b\left(n_{1},n_{2}\right)}

.





r

b



(

n

1


,

n

2


)

=

∑


q

1





∑


q

2




b

(

q

1


,

q

2


)

b

(

q

1


+

n

1


,

q

2


+

n

2


)



{\displaystyle r_{b}\left(n_{1},n_{2}\right)=\sum _{q_{1}}\sum _{q_{2}}b\left(q_{1},q_{2}\right)b\left(q_{1}+n_{1},q_{2}+n_{2}\right)}


After computing 




r

b




{\displaystyle r_{b}}

, its Fourier transform 




R

b



(

w

1


,

w

2


)



{\displaystyle R_{b}\left(w_{1},w_{2}\right)}

 must be split into its minimum- and maximum-phase components. This is accomplished by spectral factorization using the complex cepstrum.
We form the cepstrum 




r

b



(

n

1


,

n

2


)



{\displaystyle r_{b}\left(n_{1},n_{2}\right)}

 of the autocorrelation function is formed and multiplied by a non symmetric half-plane window 



w

(

n

1


,

n

2


)



{\displaystyle w\left(n_{1},n_{2}\right)}

 to obtain the cepstrum,





b

m
p



(

n

1


,

n

2


)

=

r

b



(

n

1


,

n

2


)

w

(

n

1


,

n

2


)



{\displaystyle b_{mp}\left(n_{1},n_{2}\right)=r_{b}\left(n_{1},n_{2}\right)w\left(n_{1},n_{2}\right)}


The subscript "mp" denotes that this cepstrum corresponds to a minimum phase sequence 




b

m
p



(

n

1


,

n

2


)



{\displaystyle b_{mp}\left(n_{1},n_{2}\right)}

.
If the designed filter is stable, its denominator coefficient array 



b
(

n

1


,

n

2


)


{\displaystyle b(n_{1},n_{2})}

 is a minimum-phase sequence with non symmetric half-plane support. In this case, 



b
(

n

1


,

n

2


)


{\displaystyle b(n_{1},n_{2})}

 is equal to 




b

m
p


(

n

1


,

n

2


)


{\displaystyle b_{mp}(n_{1},n_{2})}

; otherwise it is not.





J

s




{\displaystyle J_{s}}

 can be denoted as,





J

s


=

∑


n

1





∑


n

2




[
b
(

n

1


,

n

2


)
−

b

m
p


(

n

1


,

n

2


)

]

2




{\displaystyle J_{s}=\sum _{n_{1}}\sum _{n_{2}}[b(n_{1},n_{2})-b_{mp}(n_{1},n_{2})]^{2}}


In practice, 




J

s




{\displaystyle J_{s}}

 is rarely driven to zero because of numerical errors in computing the cepstrum 




r

b



(

n

1


,

n

2


)



{\displaystyle r_{b}\left(n_{1},n_{2}\right)}

. In general, 




r

b



(

n

1


,

n

2


)



{\displaystyle r_{b}\left(n_{1},n_{2}\right)}

 has infinite extent, and spatial aliasing results when the FFT is used to compute it. The degree of aliasing can be controlled by increasing the size of the FFT.
Often, especially in applications such as image processing, one may be required to design a filter with symmetric impulse response. Such filters will have a real-valued, or zero-phase, frequency response. Zero-phase IIR filter could be implemented in two ways, cascade or parallel.[4]
In the cascade approach, a filter whose impulse response is 



h

(

n

1


,

n

2


)



{\displaystyle h\left(n_{1},n_{2}\right)}

 is cascaded with a filter whose impulse response is 



h

(
−

n

1


,
−

n

2


)



{\displaystyle h\left(-n_{1},-n_{2}\right)}

. The overall impulse response of the cascade is 



h

(

n

1


,

n

2


)

∗
∗
h

(
−

n

1


,
−

n

2


)



{\displaystyle h\left(n_{1},n_{2}\right)**h\left(-n_{1},-n_{2}\right)}

. The overall frequency response is a real and non-negative function,




C

(

w

1


,

w

2


)

=


|
H

(

w

1


,

w

2


)

|


2




{\displaystyle C\left(w_{1},w_{2}\right)=\left\vert H\left(w_{1},w_{2}\right)\right\vert ^{2}}


The cascade approach suffers from some computational problems due to transient effects. The output samples of the second filter in the cascade are computed by a recursion which runs in the opposite direction from that of the first filter. For an IIR filter, its output has infinite extent, and theoretically an infinite number of its output samples must be evaluated before filtering with the 



h

(
−

n

1


,
−

n

2


)



{\displaystyle h\left(-n_{1},-n_{2}\right)}

 can begin, even if the ultimate output is desired only over a limited region. Truncating the computations from the first filter can introduce errors. As a practical approach, the output form the first filter must be computed far enough out in space depending on the region-of-support of the numerator coefficient array 



a

(

n

1


,

n

2


)



{\displaystyle a\left(n_{1},n_{2}\right)}

 and on the location of the to-be-computed second filter's output sample, so that any initial transient from the second filter will have effectively died out in the region of interest of the final output.
In the parallel approach, the outputs of two non symmetric half-plane (OR four non-symmetric quarter-plane) IIR filters are added to form the final output signal. As in the cascade approach, the second filter is a space-reserved version of the first. The overall frequency response is given by,




P

(

w

1


,

w

2


)

=
H

(

w

1


,

w

2


)

+

H

∗



(

w

1


,

w

2


)

=
2

 Re

[
H

(

w

1


,

w

2


)

]


{\displaystyle P\left(w_{1},w_{2}\right)=H\left(w_{1},w_{2}\right)+H^{*}\left(w_{1},w_{2}\right)=2{\text{ Re}}[H\left(w_{1},w_{2}\right)]}


This approach avoids the problems of the cascade approach for zero-phase implementation. But, this approach is best suited for the 2-D IIR filters designed in the space domain, where the desired filter response 



d

(

n

1


,

n

2


)



{\displaystyle d\left(n_{1},n_{2}\right)}

 can be partitioned into the proper regions of support.
For a symmetric zero-phase 2-D IIR filter, the denominator has a real positive frequency response.




H

(

w

1


,

w

2


,
.
.
.
,

w

m


)

=



A

(

w

1


,

w

2


,
.
.
.
,

w

m


)



B

(

w

1


,

w

2


,
.
.
.
,

w

m


)






{\displaystyle H\left(w_{1},w_{2},...,w_{m}\right)={\frac {A\left(w_{1},w_{2},...,w_{m}\right)}{B\left(w_{1},w_{2},...,w_{m}\right)}}}


For 2-D zero-phase IIR filter, since




a

(

n

1


,

n

2


)

=
a

(
−

n

1


,
−

n

2


)



{\displaystyle a\left(n_{1},n_{2}\right)=a\left(-n_{1},-n_{2}\right)}






b

(

n

1


,

n

2


)

=
b

(
−

n

1


,
−

n

2


)



{\displaystyle b\left(n_{1},n_{2}\right)=b\left(-n_{1},-n_{2}\right)}


We can write,




A

(

w

1


,

w

2


)

=

∑


n

1





∑


n

2





a
′


(

n

1


,

n

2


)

c
o
s
(

w

1



n

1


+

w

2



n

2


)


{\displaystyle A\left(w_{1},w_{2}\right)=\sum _{n_{1}}\sum _{n_{2}}a'\left(n_{1},n_{2}\right)cos(w_{1}n_{1}+w_{2}n_{2})}






B

(

w

1


,

w

2


)

=

∑


n

1





∑


n

2





b
′


(

m

1


,

m

2


)

c
o
s
(

w

1



m

1


+

w

2



m

2


)


{\displaystyle B\left(w_{1},w_{2}\right)=\sum _{n_{1}}\sum _{n_{2}}b'\left(m_{1},m_{2}\right)cos(w_{1}m_{1}+w_{2}m_{2})}


We can formulate the mean-squared error functional that could be minimized by various techniques. The result of the minimization would yield the zero-phase filter coefficients 





a
′


(

n

1


,

n

2


)

,

b
′


(

n

1


,

n

2


)




{\displaystyle {a'\left(n_{1},n_{2}\right),b'\left(n_{1},n_{2}\right)}}

. We can use these coefficients to implement the designed filter then.
If the M-D transform transfer function, H(n(M)) = Y(n(M))/X(n(M)) for a particular class of inputs x(n(M)) and a particular transform is known, the design approximation problem becomes simple and we then have to find the (M-P) dimensional LDE's, one for each P-tuple that help in approximating all the complex (M-P) dimensional transform transfer functions, H(k(P),k(M-P)). But as the multidimensional approximation theory for dimensions greater than 2 is not well developed, the (M-P) dimensional approximation maybe a problem. The input and output sequences of each (M-P) dimensional LDE are complex and are given by X(k(P),k(M-P)) and Y(k(P),k(M-P)) respectively. The main design objective is to choose coefficients of the LDE in such a way that the complex (M-P) dimensional transform transfer function of the sequences X(k(P),k(M-P)) and Y(k(P),k(M-P)), are approximately in the ratio of H(k(P),k(M-P)) = H(n(M)). This can be very difficult unless certain transforms such as DFT, DCT and DHT are used. For the above-mentioned transforms, it is possible to find the (M-P) dimensional impulse response, h(k(P),n(M-P)) by approximating the Linear Difference Equations. We know that the three step process to design Mixed Multidimensional filters can be summarized as follows,[1]
Step 1. X(k(P),n(M-P)) = F(k(P))[






x
¯



 


{\displaystyle {\bar {x}}\ }

(n(M))]
Step 2. Y(k(P),n(M-P)) = X(k(P),n(M-P)) 



∗


⋯

M
−
P



∗


{\displaystyle *{\overset {M-P}{\cdots }}*}

 h(k(P),n(M-P))
Step 3. 






y
¯



 


{\displaystyle {\bar {y}}\ }

(n(M)) = F-1(k(P))[Y(k(P),n(M-P))]
The following approaches can be used to design Mixed Multidimensional filters:
For a multidimensional array 




x


n

1


,

n

2


,
…
,

n

p






{\displaystyle x_{n_{1},n_{2},\dots ,n_{p}}}

 that is a function of p discrete variables 




n

ℓ


=
0
,
1
,
…
,

N

ℓ


−
1


{\displaystyle n_{\ell }=0,1,\dots ,N_{\ell }-1}

 for 



ℓ


{\displaystyle \ell }

 in 



1
,
2
,
…
,
p


{\displaystyle 1,2,\dots ,p}

, the P-Dimensional Discrete Forward Fourier Transform is defined by:
F(k(P)) = 




∑


n

1


=
0



N

1


−
1



(

ω


N

1




 

k

1



n

1





∑


n

2


=
0



N

2


−
1



(

ω


N

2




 

k

2



n

2




⋯

∑


n

p


=
0



N

p


−
1



ω


N

p




 

k

p



n

p




⋅

x


n

1


,

n

2


,
…
,

n

p




)

)


,


{\displaystyle \sum _{n_{1}=0}^{N_{1}-1}\left(\omega _{N_{1}}^{~k_{1}n_{1}}\sum _{n_{2}=0}^{N_{2}-1}\left(\omega _{N_{2}}^{~k_{2}n_{2}}\cdots \sum _{n_{p}=0}^{N_{p}-1}\omega _{N_{p}}^{~k_{p}n_{p}}\cdot x_{n_{1},n_{2},\dots ,n_{p}}\right)\right)\,,}

,
where 




ω


N

ℓ




=
exp
⁡
(
−
2
π
i

/


N

ℓ


)


{\displaystyle \omega _{N_{\ell }}=\exp(-2\pi i/N_{\ell })}

 as shown above and the p output indices run from 




k

ℓ


=
0
,
1
,
…
,

N

ℓ


−
1


{\displaystyle k_{\ell }=0,1,\dots ,N_{\ell }-1}

. If we want to express it in vector notation, where 




n

=
(

n

1


,

n

2


,
…
,

n

p


)


{\displaystyle \mathbf {n} =(n_{1},n_{2},\dots ,n_{p})}

 and 




k

=
(

k

1


,

k

2


,
…
,

k

p


)


{\displaystyle \mathbf {k} =(k_{1},k_{2},\dots ,k_{p})}

 are p-dimensional vectors of indices from 0 to 




N

−
1


{\displaystyle \mathbf {N} -1}

, where 




N

−
1
=
(

N

1


−
1
,

N

2


−
1
,
…
,

N

p


−
1
)


{\displaystyle \mathbf {N} -1=(N_{1}-1,N_{2}-1,\dots ,N_{p}-1)}

, the P-Dimensional Discrete Forward Fourier Transform is given by :
F(k(P)) = 




∑


n

=

0




N

−
1



e

−
2
π
i

k

⋅
(

n


/


N

)



x


n




,


{\displaystyle \sum _{\mathbf {n} =\mathbf {0} }^{\mathbf {N} -1}e^{-2\pi i\mathbf {k} \cdot (\mathbf {n} /\mathbf {N} )}x_{\mathbf {n} }\,,}

,
where the division 




n


/


N



{\displaystyle \mathbf {n} /\mathbf {N} }

 is defined as 




n


/


N

=
(

n

1



/


N

1


,
…
,

n

p



/


N

p


)


{\displaystyle \mathbf {n} /\mathbf {N} =(n_{1}/N_{1},\dots ,n_{p}/N_{p})}

 to be performed element-wise, and the sum denotes the set of nested summations above.
To find the P-Dimensional inverse Discrete Fourier Transform, we can use the following:
F-1(k(P)) = 





1


∏

ℓ
=
1


p



N

ℓ






∑


k

=

0




N

−
1



e

2
π
i

n

⋅
(

k


/


N

)



.


{\displaystyle {\frac {1}{\prod _{\ell =1}^{p}N_{\ell }}}\sum _{\mathbf {k} =\mathbf {0} }^{\mathbf {N} -1}e^{2\pi i\mathbf {n} \cdot (\mathbf {k} /\mathbf {N} )}\,.}

 F(k(P)).
The Discrete Fourier Transform is useful for certain applications such as Data Compression, Spectral Analysis, Polynomial Multiplication, etc. The DFT is also used as a building block for techniques that take advantage of properties of signals frequency-domain representation, such as the overlap-save and overlap-add fast convolution algorithms. However the computational complexity increases if Discrete Fourier Transform is used as the Discrete Transform. The computational complexity of the DFT is way higher than the other Discrete Transforms and is given by O(N2). Therefore, other Discrete Transforms are preferred over the DFT.
For a multidimensional array 




x


n

1


,

n

2


,
…
,

n

p






{\displaystyle x_{n_{1},n_{2},\dots ,n_{p}}}

 that is a function of p discrete variables 




n

ℓ


=
0
,
1
,
…
,

N

ℓ


−
1


{\displaystyle n_{\ell }=0,1,\dots ,N_{\ell }-1}

 for 



ℓ


{\displaystyle \ell }

 in 



1
,
2
,
…
,
p


{\displaystyle 1,2,\dots ,p}

, the P-Dimensional Discrete Forward Cosine Transform is defined by:
F(k(P)) 







=

∑


n

1


=
0



N

1


−
1



∑


n

2


=
0



N

2


−
1


⋯

∑


n

p


=
0



N

p


−
1



x


n

1


,

n

2


,
⋯

n

p




cos
⁡

[


π

N

1





(

n

1


+


1
2


)


k

1


]

cos
⁡

[


π

N

2





(

n

2


+


1
2


)


k

2


]

⋯
cos
⁡

[


π

N

p





(

n

p


+


1
2


)


k

p


]

,

k

1


,

k

2


,
⋯

k

p


=
0
,
1
,
2
,
3....
N
−
1.






{\displaystyle {\begin{aligned}=\sum _{n_{1}=0}^{N_{1}-1}\sum _{n_{2}=0}^{N_{2}-1}\cdots \sum _{n_{p}=0}^{N_{p}-1}x_{n_{1},n_{2},\cdots n_{p}}\cos \left[{\frac {\pi }{N_{1}}}\left(n_{1}+{\frac {1}{2}}\right)k_{1}\right]\cos \left[{\frac {\pi }{N_{2}}}\left(n_{2}+{\frac {1}{2}}\right)k_{2}\right]\cdots \cos \left[{\frac {\pi }{N_{p}}}\left(n_{p}+{\frac {1}{2}}\right)k_{p}\right],k_{1},k_{2},\cdots k_{p}=0,1,2,3....N-1.\end{aligned}}}

 The P-Dimensional inverse Discrete Cosine Transform is given by:
F-1(k(P)) 







=

∑


k

1


=
0



N

1


−
1



∑


k

2


=
0



N

2


−
1


⋯

∑


k

p


=
0


N
−
p
−
1



X


k

1


,

k

2


,
⋯

k

p




cos
⁡

[


π

N

1





(

n

1


+


1
2


)


k

1


]

cos
⁡

[


π

N

2





(

n

2


+


1
2


)


k

2


]

⋯
cos
⁡

[


π

N

p





(

n

p


+


1
2


)


k

p


]

,

n

1


,

n

2


,
⋯

n

p


=
0
,
1
,
2
,
3....
N
−
1.






{\displaystyle {\begin{aligned}=\sum _{k_{1}=0}^{N_{1}-1}\sum _{k_{2}=0}^{N_{2}-1}\cdots \sum _{k_{p}=0}^{N-p-1}X_{k_{1},k_{2},\cdots k_{p}}\cos \left[{\frac {\pi }{N_{1}}}\left(n_{1}+{\frac {1}{2}}\right)k_{1}\right]\cos \left[{\frac {\pi }{N_{2}}}\left(n_{2}+{\frac {1}{2}}\right)k_{2}\right]\cdots \cos \left[{\frac {\pi }{N_{p}}}\left(n_{p}+{\frac {1}{2}}\right)k_{p}\right],n_{1},n_{2},\cdots n_{p}=0,1,2,3....N-1.\end{aligned}}}


The DCT finds its use in data compression applications such as the JPEG image format. The DCT has high degree of spectral compaction at a qualitative level, which makes it very suitable for various compression applications. A signal's DCT representation tends to have more of its energy concentrated in a small number of coefficients when compared to other transforms like the DFT. Thus you can reduce your data storage requirement by only storing the DCT outputs that contain significant amounts of energy. The computational complexity of DCT goes by O(NLogN). Since the number of operations required to compute the DCT is less, the DCT's are also called as Fast Cosine Transforms(FCT).
The below graph shows how the computational complexity varies with N for DFT and DCT

For a multidimensional array 




x


n

1


,

n

2


,
…
,

n

p






{\displaystyle x_{n_{1},n_{2},\dots ,n_{p}}}

 that is a function of p discrete variables 




n

ℓ


=
0
,
1
,
…
,

N

ℓ


−
1


{\displaystyle n_{\ell }=0,1,\dots ,N_{\ell }-1}

 for 



ℓ


{\displaystyle \ell }

 in 



1
,
2
,
…
,
p


{\displaystyle 1,2,\dots ,p}

, the P-Dimensional Discrete Forward Hartley Transform is defined by:
F(k(P)) 



=

∑


n

1


=
0



N

1


−
1



∑


n

2


=
0



N

2


−
1


…

∑


n

p


=
0



N

p


−
1


x
(

n

1


,

n

2


,
.
.
.
,

n

p


)
c
a
s
(



2
π

n

1



k

1




N

1




+
⋯
+



2
π

n

p



k

p




N

p




)
,


{\displaystyle =\sum _{n_{1}=0}^{N_{1}-1}\sum _{n_{2}=0}^{N_{2}-1}\dots \sum _{n_{p}=0}^{N_{p}-1}x(n_{1},n_{2},...,n_{p})cas({\frac {2\pi n_{1}k_{1}}{N_{1}}}+\dots +{\frac {2\pi n_{p}k_{p}}{N_{p}}}),}

 where, 




k

i


=
0
,
1
,
…
,

N

i


−
1


{\displaystyle k_{i}=0,1,\ldots ,N_{i}-1}

 and where 



c
a
s
(
x
)
=
c
o
s
(
x
)
+
s
i
n
(
x
)
.


{\displaystyle cas(x)=cos(x)+sin(x).}

 It should also be noted that, if Discrete Hartley Transform is used, the computational complexity of complex numbers can be avoided. The overall computational complexity of Discrete Hartley Transform is given by O(NLogN), if algorithms similar to the FFT are used and thus the DHT is also referred to as the Fast Hartley Transform(FHT).
The Discrete Hartley Transform is used in various applications in communications and signal processing areas. Some of these applications include multidimensional filtering, multidimensional spectral analysis, error control coding, adaptive digital filters, image processing etc.
Mixed 3-D filters can be used for enhancement of 3-D spatially planar signals. A 3-D MixeD Cone filter can be designed using 2-D DHT and is shown below.
An M-D signal, x(n(M)) is considered to be spatially-planar(SP) if it is constant on all surfaces, i.e. 




α

1





{\displaystyle \alpha _{1}\!}






n

1




{\displaystyle n_{1}}

 + 




α

2





{\displaystyle \alpha _{2}\!}






n

2




{\displaystyle n_{2}}

 +



⋯


{\displaystyle \cdots }

 + 




α

M





{\displaystyle \alpha _{M}\!}






n

M




{\displaystyle n_{M}}

 = d, for 



∀


{\displaystyle \forall }

d 



∈


{\displaystyle \in }

R where R is the set of real numbers.
Therefore, a 3-D spatially planar signal, x(n(3)) is constant on 3 surfaces and is given by 




α

1





{\displaystyle \alpha _{1}\!}






n

1




{\displaystyle n_{1}}

 + 




α

2





{\displaystyle \alpha _{2}\!}






n

2




{\displaystyle n_{2}}

 + 




α

3





{\displaystyle \alpha _{3}\!}






n

3




{\displaystyle n_{3}}

 = d, for 



∀


{\displaystyle \forall }

d 



∈


{\displaystyle \in }

R
It may been shown that the 3-D DFT of a SP x(n(M)) yields 3-D DFT frequency domain coefficients, X(k(3)), which are zero everywhere except on the line L(k(3)) where (k(3)) 



∈


{\displaystyle \in }

 



{


{\displaystyle \{}

 Z



|


{\displaystyle \vert }

 




k

1




{\displaystyle k_{1}}

/




α

1





{\displaystyle \alpha _{1}\!}

=




k

2




{\displaystyle k_{2}}

/




α

2





{\displaystyle \alpha _{2}\!}

=




k

3




{\displaystyle k_{3}}

/




α

3





{\displaystyle \alpha _{3}\!}

 



}


{\displaystyle \}}

.
A 3-D signal input sequence will be selectively enhanced by a 3-D passband enclosing this line. Thus we make use of a cone filter having a thin pyramidal shaped passband which is approximated using Mixed filter constructed using 2-D DHT.
Firstly, we have to select the passband regions on {k1,k2}. The close examination of DFT and DHT, shows that the 3-D DHT of 




X

H




{\displaystyle X_{H}}

(k(3)) of a spatially-planar signal x(n(3)) is zero outside the straight line 




L

H




{\displaystyle L_{H}}

(k(3)) passing through the origin of 3-D DHT (k(3)) space. Therefore, (k(3)) 



∈


{\displaystyle \in }

 



{


{\displaystyle \{}

 Z



|


{\displaystyle \vert }

 




k

1




{\displaystyle k_{1}}

/




α

1





{\displaystyle \alpha _{1}\!}

=




k

2




{\displaystyle k_{2}}

/




α

2





{\displaystyle \alpha _{2}\!}

}. All the LDE's that correspond to 2-tuples {




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

}, that lie outide the fan shaped projection of the thin pyramidal passband on the 




k

1




{\displaystyle k_{1}}

-




k

2




{\displaystyle k_{2}}

 plane have to be omitted. The half angle will determine the k1-k2 plane bandwidth of the MixeD filter.
Secondly, we have to find the characteristics of the LDE Input sequences 




X

H




{\displaystyle X_{H}}

(




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

,



n
3


{\displaystyle n3}

). The LDE input sequences computed for the 2-D DHT of a S-P signal x(n(3)), are real and sinusoidal in the steady-state. Since a spatially planar signal is also a linear trajectory signal, it maybe written in the form, x(n(3)) = x(




n

1




{\displaystyle n_{1}}

 - 




p

1




{\displaystyle p_{1}}






n

3




{\displaystyle n_{3}}

, 




n

2




{\displaystyle n_{2}}

 - 




p

2




{\displaystyle p_{2}}






n

3




{\displaystyle n_{3}}

,




n

3




{\displaystyle n_{3}}

 ), where 




p

1




{\displaystyle p_{1}}

 = 




α

3





{\displaystyle \alpha _{3}\!}

/




α

1





{\displaystyle \alpha _{1}\!}

 and 




p

2




{\displaystyle p_{2}}

 = 




α

3





{\displaystyle \alpha _{3}\!}

/




α

2





{\displaystyle \alpha _{2}\!}

.
Now, using the shift property of 2-D DHT, we get, 




X

H




{\displaystyle X_{H}}

(




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

,




n

3




{\displaystyle n_{3}}

) = 




X

H




{\displaystyle X_{H}}

(




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

,0)cos



{


{\displaystyle \{}

W



}


{\displaystyle \}}

 + 




X

H




{\displaystyle X_{H}}

(N - 




k

1




{\displaystyle k_{1}}

, N - 




k

2




{\displaystyle k_{2}}

,0)cos



{


{\displaystyle \{}

W



}


{\displaystyle \}}

, where W = cos



{


{\displaystyle \{}

2(




p

1




{\displaystyle p_{1}}






k

1




{\displaystyle k_{1}}

 + 




p

2




{\displaystyle p_{2}}






k

2




{\displaystyle k_{2}}

)(




n

3




{\displaystyle n_{3}}





π


{\displaystyle \pi }

)/N



}


{\displaystyle \}}

. This equation implies that the passband sequences, 




X

H




{\displaystyle X_{H}}

(




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

,



n
3


{\displaystyle n3}

) at each tuple {




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

} are real sampled sinusoids that may be selectively transmitted by employing LDE's that are characterized by narrowband bandpass magnitude frequency respone having Normalized frequencies given by,
v = 2(




p

1




{\displaystyle p_{1}}






k

1




{\displaystyle k_{1}}

 + 




p

2




{\displaystyle p_{2}}






k

2




{\displaystyle k_{2}}

)/N. If we choose the bandwidths B{




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

} of these narrowband bandpass LDEs to be proportional to the centre frequencies v, so that B{




k

1




{\displaystyle k_{1}}

,




k

2




{\displaystyle k_{2}}

} = Kv, K > 0, and K constant, the required 3D pyramidal passband is realized. Thus it has been proved that 2-D DHT helped in the constructing a MixeD 3-D filter.