ABOUT
Grover's algorithm is a quantum algorithm that finds with high probability the unique input to a black box function that produces a particular output value, using just 



O
(


N


)


{\displaystyle O({\sqrt {N}})}

 evaluations of the function, where N is the size of the function's domain. It was devised by Lov Grover in 1996.
FULL TEXT
Grover's algorithm is a quantum algorithm that finds with high probability the unique input to a black box function that produces a particular output value, using just 



O
(


N


)


{\displaystyle O({\sqrt {N}})}

 evaluations of the function, where N is the size of the function's domain. It was devised by Lov Grover in 1996.
The analogous problem in classical computation cannot be solved in fewer than 



O
(
N
)


{\displaystyle O(N)}

 evaluations (because, in the worst case, the N-th member of the domain might be the correct member). At roughly the same time that Grover published his algorithm, Bennett, Bernstein, Brassard, and Vazirani proved that no quantum solution to the problem can evaluate the function fewer than 



O
(


N


)


{\displaystyle O({\sqrt {N}})}

 times, so Grover's algorithm is asymptotically optimal.[1]
Unlike other quantum algorithms, which may provide exponential speedup over their classical counterparts, Grover's algorithm provides only a quadratic speedup. However, even quadratic speedup is considerable when 



N


{\displaystyle N}

 is large. Grover's algorithm could brute-force a 128-bit symmetric cryptographic key in roughly 264 iterations, or a 256-bit key in roughly 2128 iterations. As a result, it is sometimes suggested[citation needed] that symmetric key lengths be doubled to protect against future quantum attacks.
Like many quantum algorithms, Grover's algorithm is probabilistic in the sense that it gives the correct answer with a probability of less than 1. Though there is technically no upper bound on the number of repetitions that might be needed before the correct answer is obtained, the expected number of repetitions is a constant factor that does not grow with 



N


{\displaystyle N}

.
Grover's original paper described the algorithm as a database search algorithm, and this description is still common. The database in this analogy is a table of all of the function's outputs, indexed by the corresponding input.


Although the purpose of Grover's algorithm is usually described as "searching a database", it may be more accurate to describe it as "inverting a function". Roughly speaking, if we have a function 



y
=
f
(
x
)


{\displaystyle y=f(x)}

 that can be evaluated on a quantum computer, Grover's algorithm allows us to calculate 



x


{\displaystyle x}

 when given 



y


{\displaystyle y}

. Inverting a function is related to the searching of a database because we could come up with a function that produces one particular value of 



y


{\displaystyle y}

 ("true", for instance) if 



x


{\displaystyle x}

 matches a desired entry in a database, and another value of 



y


{\displaystyle y}

 ("false") for other values of 



x


{\displaystyle x}

.
Grover's algorithm can also be used for estimating the mean and median of a set of numbers, and for solving the collision problem. The algorithm can be further optimized if there is more than one matching entry and the number of matches is known beforehand. Grover's algorithm can be used to crack passwords as well.
Consider an unsorted database with N entries. The algorithm requires an N-dimensional state space H, which can be supplied by n = log2 N qubits. Consider the problem of determining the index of the database entry that satisfies some search criterion. Let f be the function that maps database entries to 0 or 1, where f(x) = 1 if and only if x satisfies the search criterion (x = ω). We are provided with (quantum black box) access to a subroutine in the form of a unitary operator Uω that acts as follows:
An alternative definition of Uω may be encountered assuming the presence of an ancillary qubit system (like in the quantum circuit depicted below). The operation then represents a conditional inversion (NOT gate) conditioned by the value of f(x) on the main system:
or briefly,
This is a natural way to realize a binary operation using the method of uncomputation. Note that if the ancillary qubit is prepared in the state 




|

−
⟩
=


1

2





(



|

0
⟩
−

|

1
⟩


)


=
H

|

1
⟩


{\displaystyle |-\rangle ={\frac {1}{\sqrt {2}}}{\big (}|0\rangle -|1\rangle {\big )}=H|1\rangle }

, the effective operation of this controlled NOT gate becomes equivalent to the original form, leaving the ancillary system disentangled from the main system:
In either setting, our goal is to identify the index 




|

ω
⟩


{\displaystyle |\omega \rangle }

.
The steps of Grover's algorithm are given as follows. Let 




|

s
⟩


{\displaystyle |s\rangle }

 denote the uniform superposition over all states
Then the operator
is known as the Grover diffusion operator.
Here is the algorithm:
A preliminary observation, in parallel with our definition
is that 




U

ω




{\displaystyle U_{\omega }}

 can be expressed in an alternate way:
To prove this it suffices to check how 




U

ω




{\displaystyle U_{\omega }}

 acts on basis states:
The following computations show what happens in the first iteration:
It is worth noting the special case of N = 4 with a single marked state. This has 




U

s



U

w



|

s
⟩
=

|

ω
⟩


{\displaystyle U_{s}U_{w}|s\rangle =|\omega \rangle }

, meaning that in a single application of the Grover iterator the marked state is returned.
After application of the operators 




U

ω




{\displaystyle U_{\omega }}

 and 




U

s




{\displaystyle U_{s}}

, amplitude of the queried element has increased from 





|
⟨
ω

|

s
⟩
|


2


=



1
N





{\displaystyle \left|\langle \omega |s\rangle \right|^{2}={\tfrac {1}{N}}}

 to 





|
⟨
ω

|


U

s



U

ω



|

s
⟩
|


2


=




(
3
N
−
4

)

2




N

3







{\displaystyle \left|\langle \omega |U_{s}U_{\omega }|s\rangle \right|^{2}={\tfrac {(3N-4)^{2}}{N^{3}}}}

.
Grover's algorithm requires a "quantum oracle" operator 




U

ω




{\displaystyle U_{\omega }}

, which can recognize solutions to the search problem and give them a negative sign. In order to keep the search algorithm general, we will leave the inner workings of the oracle as a black box, but will explain how the sign is flipped. The oracle contains a function 



f


{\displaystyle f}

 that returns 



f
(
x
)
=
1


{\displaystyle f(x)=1}

 if 




|

x
⟩


{\displaystyle |x\rangle }

 is a solution to the search problem and 



f
(
x
)
=
0


{\displaystyle f(x)=0}

 otherwise. The oracle is a unitary operator operating on two qubits:
where 




|

x
⟩


{\displaystyle |x\rangle }

 is the index qubit and 




|

q
⟩


{\displaystyle |q\rangle }

 is the oracle qubit.
As usual, 



⊕


{\displaystyle \oplus }

 denotes addition modulo 2. The operation flips the oracle qubit if 



f
(
x
)
=
1


{\displaystyle f(x)=1}

 and leaves it unchanged otherwise. In Grover's algorithm we want to flip the sign of the state 




|

x
⟩


{\displaystyle |x\rangle }

 if it labels a solution. This is achieved by setting the oracle qubit in the state 



(

|

0
⟩
−

|

1
⟩
)

/



2




{\displaystyle (|0\rangle -|1\rangle )/{\sqrt {2}}}

, which is flipped to 



(

|

1
⟩
−

|

0
⟩
)

/



2




{\displaystyle (|1\rangle -|0\rangle )/{\sqrt {2}}}

 if 




|

x
⟩


{\displaystyle |x\rangle }

 is a solution:
We regard 




|

x
⟩


{\displaystyle |x\rangle }

 as flipped, thus the oracle qubit is not changed, so by convention the oracle qubits are usually not mentioned in the specification of Grover's algorithm. Thus the operation of the oracle 




U

ω




{\displaystyle U_{\omega }}

 is simply written as
Consider the plane spanned by 




|

s
⟩


{\displaystyle |s\rangle }

 and 




|

ω
⟩


{\displaystyle |\omega \rangle }

; equivalently, the plane spanned by 




|

ω
⟩


{\displaystyle |\omega \rangle }

 and the perpendicular ket 





|


s
′

⟩
=


1

N
−
1




∑

x
≠
ω



|

x
⟩



{\displaystyle \textstyle |s'\rangle ={\frac {1}{\sqrt {N-1}}}\sum _{x\neq \omega }|x\rangle }

. We will consider the first iteration, acting on the initial ket 




|

s
⟩


{\displaystyle |s\rangle }

. Since 




|

ω
⟩


{\displaystyle |\omega \rangle }

 is one of the basis vectors in 




|

s
⟩


{\displaystyle |s\rangle }

 the overlap is
In geometric terms, the angle 



θ

/

2


{\displaystyle \theta /2}

 between 




|

s
⟩


{\displaystyle |s\rangle }

 and 




|


s
′

⟩


{\displaystyle |s'\rangle }

 is given by
The operator 




U

ω




{\displaystyle U_{\omega }}

 is a reflection at the hyperplane orthogonal to 




|

ω
⟩


{\displaystyle |\omega \rangle }

 for vectors in the plane spanned by 




|


s
′

⟩


{\displaystyle |s'\rangle }

 and 




|

ω
⟩


{\displaystyle |\omega \rangle }

, i.e. it acts as a reflection across 




|


s
′

⟩


{\displaystyle |s'\rangle }

. The operator 




U

s




{\displaystyle U_{s}}

 is a reflection through 




|

s
⟩


{\displaystyle |s\rangle }

. Therefore, the state vector remains in the plane spanned by 




|


s
′

⟩


{\displaystyle |s'\rangle }

 and 




|

ω
⟩


{\displaystyle |\omega \rangle }

 after each application of the operators 




U

s




{\displaystyle U_{s}}

 and 




U

ω




{\displaystyle U_{\omega }}

, and it is straightforward to check that the operator 




U

s



U

ω




{\displaystyle U_{s}U_{\omega }}

 of each Grover iteration step rotates the state vector by an angle of 



θ
=
2
arcsin
⁡



1

N






{\displaystyle \theta =2\arcsin {\tfrac {1}{\sqrt {N}}}}

.
We need to stop when the state vector passes close to 




|

ω
⟩


{\displaystyle |\omega \rangle }

; after this, subsequent iterations rotate the state vector away from 




|

ω
⟩


{\displaystyle |\omega \rangle }

, reducing the probability of obtaining the correct answer. The exact probability of measuring the correct answer is
where r is the (integer) number of Grover iterations. The earliest time that we get a near-optimal measurement is therefore 



r
≈
π


N



/

4


{\displaystyle r\approx \pi {\sqrt {N}}/4}

.
To complete the algebraic analysis, we need to find out what happens when we repeatedly apply 




U

s



U

ω




{\displaystyle U_{s}U_{\omega }}

. A natural way to do this is by eigenvalue analysis of a matrix. Notice that during the entire computation, the state of the algorithm is a linear combination of 



s


{\displaystyle s}

 and 



ω


{\displaystyle \omega }

. We can write the action of 




U

s




{\displaystyle U_{s}}

 and 




U

ω




{\displaystyle U_{\omega }}

 in the space spanned by 



{

|

s
⟩
,

|

ω
⟩
}


{\displaystyle \{|s\rangle ,|\omega \rangle \}}

 as:
So in the basis 



{

|

ω
⟩
,

|

s
⟩
}


{\displaystyle \{|\omega \rangle ,|s\rangle \}}

 (which is neither orthogonal nor a basis of the whole space) the action 




U

s



U

ω




{\displaystyle U_{s}U_{\omega }}

 of applying 




U

ω




{\displaystyle U_{\omega }}

 followed by 




U

s




{\displaystyle U_{s}}

 is given by the matrix
This matrix happens to have a very convenient Jordan form. If we define 



t
=
arcsin
⁡
(
1

/



N


)


{\displaystyle t=\arcsin(1/{\sqrt {N}})}

, it is
It follows that r-th power of the matrix (corresponding to r iterations) is
Using this form, we can use trigonometric identities to compute the probability of observing ω after r iterations mentioned in the previous section,
Alternatively, one might reasonably imagine that a near-optimal time to distinguish would be when the angles 2rt and −2rt are as far apart as possible, which corresponds to 



2
r
t
≈
π

/

2


{\displaystyle 2rt\approx \pi /2}

, or 



r
=
π

/

4
t
=
π

/

4
arcsin
⁡
(
1

/



N


)
≈
π


N



/

4


{\displaystyle r=\pi /4t=\pi /4\arcsin(1/{\sqrt {N}})\approx \pi {\sqrt {N}}/4}

. Then the system is in state
A short calculation now shows that the observation yields the correct answer ω with error O(1/N).
If, instead of 1 matching entry, there are k matching entries, the same algorithm works, but the number of iterations must be π(N/k)1/2/4 instead of πN1/2/4. There are several ways to handle the case if k is unknown. For example, one could run Grover's algorithm several times, with
iterations. For any k, one of the iterations will find a matching entry with a sufficiently high probability. The total number of iterations is at most
which is still O(N1/2). It can be shown that this can be improved. If the number of marked items is k, where k is unknown, there is an algorithm that finds the solution in 





N

/

k




{\displaystyle {\sqrt {N/k}}}

 queries. This fact is used in order to solve the collision problem.[2][3]
A modification of Grover's algorithm called quantum partial search was described by Grover and Radhakrishnan in 2004.[4] In partial search, one is not interested in finding the exact address of the target item, only the first few digits of the address. Equivalently, we can think of "chunking" the search space into blocks, and then asking "in which block is the target item?". In many applications, such a search yields enough information if the target address contains the information wanted. For instance, to use the example given by L. K. Grover, if one has a list of students organized by class rank, we may only be interested in whether a student is in the lower 25%, 25–50%, 50–75% or 75–100% percentile.
To describe partial search, we consider a database separated into 



K


{\displaystyle K}

 blocks, each of size 



b
=
N

/

K


{\displaystyle b=N/K}

. Obviously, the partial search problem is easier. Consider the approach we would take classically – we pick one block at random, and then perform a normal search through the rest of the blocks (in set theory language, the complement). If we don't find the target, then we know it's in the block we didn't search. The average number of iterations drops from 



N

/

2


{\displaystyle N/2}

 to 



(
N
−
b
)

/

2


{\displaystyle (N-b)/2}

.
Grover's algorithm requires 



π

/

4


N




{\displaystyle \pi /4{\sqrt {N}}}

 iterations. Partial search will be faster by a numerical factor that depends on the number of blocks 



K


{\displaystyle K}

. Partial search uses 




n

1




{\displaystyle n_{1}}

 global iterations and 




n

2




{\displaystyle n_{2}}

 local iterations. The global Grover operator is designated 




G

1




{\displaystyle G_{1}}

 and the local Grover operator is designated 




G

2




{\displaystyle G_{2}}

.
The global Grover operator acts on the blocks. Essentially, it is given as follows:
The optimal values of 




j

1




{\displaystyle j_{1}}

 and 




j

2




{\displaystyle j_{2}}

 are discussed in the paper by Grover and Radhakrishnan. One might also wonder what happens if one applies successive partial searches at different levels of "resolution". This idea was studied in detail by Korepin and Xu, who called it binary quantum search. They proved that it is not in fact any faster than performing a single partial search.
It is known that Grover's algorithm is optimal. That is, any algorithm that accesses the database only by using the operator Uω must apply Uω at least as many times as Grover's algorithm.[1] This result is important in understanding the limits of quantum computation.
If the Grover's search problem was solvable with logc N applications of Uω, that would imply that NP is contained in BQP, by transforming problems in NP into Grover-type search problems. The optimality of Grover's algorithm suggests (but does not prove) that NP is not contained in BQP.
The number of iterations for k matching entries, π(N/k)1/2/4, is also optimal.[2]
When applications of Grover's algorithm are considered, it should be emphasized that the database is not represented explicitly. Instead, an oracle is invoked to evaluate an item by its index. Reading a full data-base item by item and converting it into such a representation may take a lot longer than Grover's search. To account for such effects, Grover's algorithm can be viewed as solving an equation or satisfying a constraint. In such applications, the oracle is a way to check the constraint and is not related to the search algorithm. This separation usually prevents algorithmic optimizations, whereas conventional search algorithms often rely on such optimizations and avoid exhaustive search. These and other considerations about using Grover's algorithm are discussed in a paper by Viamontes, Markov and Hayes.[5]