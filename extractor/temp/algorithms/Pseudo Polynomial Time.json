{
    "about": "In computational complexity theory, a numeric algorithm runs in pseudo-polynomial time if its running time is polynomial in the numeric value of the input, but is exponential in the length of the input\u00a0\u2013 the number of bits required to represent it.", 
    "classification": "Pseudo-Polynomial Time Algorithms", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Pseudo-polynomial_time\n", 
    "full_text": "In computational complexity theory, a numeric algorithm runs in pseudo-polynomial time if its running time is polynomial in the numeric value of the input, but is exponential in the length of the input\u00a0\u2013 the number of bits required to represent it.\nAn NP-complete problem with known pseudo-polynomial time algorithms is called weakly NP-complete. An NP-complete problem is called strongly NP-complete if it is proven that it cannot be solved by a pseudo-polynomial time algorithm unless P=NP. The strong/weak kinds of NP-hardness are defined analogously.\n\n\nConsider the problem of testing whether a number n is prime, by naively checking whether no number in \n\n\n\n{\n2\n,\n3\n,\n\u2026\n,\n\n\nn\n\n\n}\n\n\n{\\displaystyle \\{2,3,\\dots ,{\\sqrt {n}}\\}}\n\n divides \n\n\n\nn\n\n\n{\\displaystyle n}\n\n evenly. This approach can take up to \n\n\n\n\n\nn\n\n\n\u2212\n1\n\n\n{\\displaystyle {\\sqrt {n}}-1}\n\n divisions, which is sub-linear in the value of n but exponential in the length of n (which is about \n\n\n\nlog\n\u2061\n(\nn\n)\n\n\n{\\displaystyle \\log(n)}\n\n). For example, a number n slightly less than 10,000,000,000 would require up to approximately 100,000 divisions, even though the length of n is only 10 digits. Moreover one can easily write down an input (say, a 300-digit number) for which this algorithm is impractical. Since computational complexity measures difficulty with respect to the length of the (encoded) input, this naive algorithm is actually exponential. It is, however, pseudo-polynomial time.\nContrast this algorithm with a true polynomial numeric algorithm \u2014 say, the straightforward algorithm for addition: Adding two 9-digit numbers takes around 9 simple steps, and in general the algorithm is truly linear in the length of the input. Compared with the actual numbers being added (in the billions), the algorithm could be called \"pseudo-logarithmic time\", though such a term is not standard. Thus, adding 300-digit numbers is not impractical. Similarly, long division is quadratic: an m-digit number can be divided by a n-digit number in \n\n\n\nO\n(\nm\nn\n)\n\n\n{\\displaystyle O(mn)}\n\n steps (see Big O notation.)\nIn the case of primality, it turns out there is a different algorithm for testing whether n is prime (discovered in 2002), which runs in time \n\n\n\nO\n(\n(\nlog\n\u2061\n\nn\n\n\n)\n\n6\n\n\n)\n\n\n{\\displaystyle O((\\log {n})^{6})}\n\n.\nAnother example of a problem that, generally, can only be solved in pseudo-polynomial time is the Knapsack problem\u2013unless P=NP.\nAlthough the notion of pseudo-polynomial time is used almost exclusively for numeric problems, the concept can be generalized: The function m is pseudo-polynomial if m(n) is no greater than a polynomial function of the problem size n and an additional property of the input, k(n). (Presumably, k is chosen to be something relevant to the problem.) This makes numeric polynomial problems a special case by taking k to be the numeric value of the input.\nThe distinction between the value of a number and its length is one of encoding: if numeric inputs are always encoded in unary, then pseudo-polynomial would coincide with polynomial.", 
    "name": "Pseudo Polynomial Time"
}