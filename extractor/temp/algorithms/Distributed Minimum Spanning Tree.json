{
    "about": "The distributed minimum spanning tree (MST) problem involves the construction of a minimum spanning tree by a distributed algorithm, in a network where nodes communicate by message passing. It is radically different from the classical sequential problem, although the most basic approach resembles Bor\u016fvka's algorithm. One important application of this problem is to find a tree that can be used for broadcasting. In particular, if the cost for a message to pass through an edge in a graph is significant, a MST can minimize the total cost for a source process to communicate with all the other processes in the network.", 
    "name": "Distributed Minimum Spanning Tree", 
    "classification": "Distributed Algorithms", 
    "full_text": "The distributed minimum spanning tree (MST) problem involves the construction of a minimum spanning tree by a distributed algorithm, in a network where nodes communicate by message passing. It is radically different from the classical sequential problem, although the most basic approach resembles Bor\u016fvka's algorithm. One important application of this problem is to find a tree that can be used for broadcasting. In particular, if the cost for a message to pass through an edge in a graph is significant, a MST can minimize the total cost for a source process to communicate with all the other processes in the network.\nThe problem was first suggested and solved in \n\n\n\nO\n(\nV\nlog\n\u2061\nV\n)\n\n\n{\\displaystyle O(V\\log V)}\n\n time in 1983 by Gallager et al.,[1] where \n\n\n\nV\n\n\n{\\displaystyle V}\n\n is the number of vertices in the graph. Later, the solution was improved to \n\n\n\nO\n(\nV\n)\n\n\n{\\displaystyle O(V)}\n\n[2] and finally[3][4] \n\n\n\nO\n(\n\n\nV\n\n\n\nlog\n\n\u2217\n\n\n\u2061\nV\n+\nD\n)\n\n\n{\\displaystyle O({\\sqrt {V}}\\log ^{*}V+D)}\n\n where D is the network, or graph diameter. A lower bound on the time complexity of the solution has been eventually shown to be[5] \n\n\n\n\u03a9\n\n(\n\n\n\n\nV\n\n\nlog\n\u2061\nV\n\n\n\n+\nD\n\n)\n\n.\n\n\n{\\displaystyle \\Omega \\left({{\\frac {\\sqrt {V}}{\\log V}}+D}\\right).}\n\n\n\n\nThe input graph \n\n\n\nG\n(\nV\n,\nE\n)\n\n\n{\\displaystyle G(V,E)}\n\n is considered to be a network, where vertices \n\n\n\nV\n\n\n{\\displaystyle V}\n\n are independent computing nodes and edges \n\n\n\nE\n\n\n{\\displaystyle E}\n\n are communication links. Links are weighted as in the classical problem.\nAt the beginning of the algorithm, nodes know only the weights of the links which are connected to them. (It is possible to consider models in which they know more, for example their neighbors' links.)\nAs the output of the algorithm, every node knows which of its links belong to the Minimum Spanning Tree and which do not.\nThe message-passing model is one of the most commonly used models in distributed computing. In this model, each process is modeled as a node of a graph. The communication channel between two processes is an edge of the graph.\nTwo commonly used algorithms for the classical minimum spanning tree problem are Prim\u2019s algorithm and Kruskal\u2019s algorithm. However, it is difficult to apply these two algorithms in the distributed message-passing model. The main challenges are:\nDue to these difficulties, new techniques were needed for distributed MST algorithms in the message-passing model. Some bear similarities to Bor\u016fvka's algorithm for the classical MST problem.\nThe GHS algorithm of Gallager, Humblet and Spira is one of the best-known algorithms in distributed computing theory. This algorithm can construct the MST in asynchronous Message-passing model.\nDefine fragment of a MST T to be a sub-tree of T, that is, a connected set of nodes and edges of T. There are two properties of MSTs:\nThese two properties form the basis for proving correctness of the GHS algorithm. In general, the GHS algorithm is a bottom-up algorithm in the sense that it starts by letting each individual node be a fragment and joining fragments in a certain way to form new fragments. This process of joining fragments repeats until there is only one fragment left and property 1 and 2 imply the resulting fragment is a MST.\nThe GHS algorithm assigns a level to each fragment, which is a non-decreasing integer with initial value 0. Each non-zero level fragment has an ID, which is the ID of the core edge in the fragment, which is selected when the fragment is constructed. During the execution of the algorithm, each node can classify each of its incident edges into three categories:[1][6]\nFor level-0 fragments, each awakened node will do the following:\nThe edge chosen by both nodes it connects becomes the core with level 1.\nFor a non-zero level fragment, an execution of the algorithm can be separated into three stages in each level:\nThe two nodes adjacent to the core broadcast messages to the rest of the nodes in the fragment. The messages are sent via the branch edge but not via the core. Each broadcast message contains the ID and level of the fragment. At the end of this stage, each node has received the new fragment ID and level.\nIn this stage, all nodes in the fragment cooperate to find the minimum weight outgoing edge of the fragment. Outgoing edges are edges connecting to other fragments. The messages sent in this stage are in the opposite direction of the broadcast stage. Initialized by all the leaves (the nodes that have only one branch edge), a message is sent through the branch edge. The message contains the minimum weight of the incident outgoing edge it found (or infinity if no such edge was found). The way to find the minimum outgoing edge will be discussed later. For each non-leaf node, (let the number of its branch edges be n) after receiving n-1 convergecast messages, it will pick the minimum weight from the messages and compare it to the weights of its incident outgoing edges. The smallest weight will be sent toward the branch it received the broadcast from.\nAfter the completion of the previous stage, the two nodes connected by the core can inform each other of the best edges they received. Then they can identify the minimum outgoing edge from the entire fragment. A message will be sent from the core to the minimum outgoing edge via a path of branch edges. Finally, a message will be sent out via the chosen outgoing edge to request to combine the two fragments that the edge connects. Depending on the levels of those two fragments, one of two combined operations are performed to form a new fragment (details discussed below).\nAs discussed above, every node needs to find its minimum weight outgoing incident edge after the receipt of a broadcast message from the core. If node n receives a broadcast, it will pick its minimum weight basic edge and send a message to the node n\u2019 on the other side with its fragment\u2019s ID and level. Then, node n\u2019 will decide whether the edge is an outgoing edge and send back a message to notify node n of the result. The decision is made according to the following:\nCase 1: Fragment_ID(n) = Fragment_ID(n\u2019).\nThen, node n and n\u2019 belongs to same fragment (so the edge is not outgoing).\nCase 2: Fragment_ID(n)\u00a0!= Fragment_ID(n\u2019) and Level(n) <= Level(n\u2019).\nThen, node n and n\u2019 belongs to the different fragments (so the edge is outgoing).\nCase 3: Fragment_ID(n)\u00a0!= Fragment_ID(n\u2019) and Level(n) > Level(n\u2019).\nWe cannot make any conclusion. The reason is the two nodes may belong to the same fragment already but node n\u2019 has not discovered this fact yet due to the delay of a broadcast message. In this case, the algorithm lets node n\u2019 postpone the response until its level becomes higher than or equal to the level it received from node n.\nLet F and F\u2019 be the two fragments that need to be combined. There are two ways to do this:[1][6]\nFurthermore, when an \"Absorb\" operation occurs, F must be in the stage of changing the core while F\u2019 can be in arbitrary stage. Therefore, \"Absorb\" operations may be done differently depending on the state of F\u2019. Let e be the edge that F and F\u2019 want to combine with and let n and n\u2019 be the two nodes connected by e in F and F\u2019, respectively. There are two cases to consider:\nCase 1: Node n\u2019 has received broadcast message but it has not sent a convergecast message back to the core.\nIn this case, fragment F can simply join the broadcast process of F\u2019. Specifically, we image F and F\u2019 have already combined to form a new fragment F\u2019\u2019, so we want to find the minimum weight outgoing edge of F\u2019\u2019. In order to do that, node n\u2019 can initiate a broadcast to F to update the fragment ID of each node in F and collect minimum weight outgoing edge in F.\nCase 2: Node n\u2019 has already sent a convergecast message back to the core.\nBefore node n\u2019 sent a convergecast message, it must have picked a minimum weight outgoing edge. As we discussed above, n\u2019 does that by choosing its minimum weight basic edge, sending a test message to the other side of the chosen edge, and waiting for the response. Suppose e\u2019 is the chosen edge, we can conclude the following:\nThe second statement follows if the first one holds. For the first statement, suppose n\u2019 chose the edge e and sent a test message to n via edge e. Then, node n will delay the response (according to case 3 of \"How to find minimum weight incident outgoing edge?\"). Then, it is impossible that n\u2019 has already sent its convergecast message. By 1 and 2, we can conclude it is safe to absorb F into F' since e\u2019 is still the minimum outgoing edge to report after F is absorbed.\nAs mentioned above, fragments are combined by either \"Merge\" or \"Absorb\" operation. \"Absorb\" operation doesn't change the maximum level among all fragments. \"Merge\" operation may increase the maximum level by 1. In the worst case, all fragments are combined with \"Merge\" operations, so the number of fragments decreases by half in each level. Therefore, the maximum number of levels is \n\n\n\nO\n(\nlog\n\u2061\nV\n)\n\n\n{\\displaystyle O(\\log V)}\n\n, where V is the number of nodes.\nThis algorithm has a nice property that the lowest level fragments will not be blocked, although some operations in non-lowest level fragments may be blocked. This property implies the algorithm will eventually terminate with a minimum spanning tree.\nAn \n\n\n\nO\n(\nlog\n\u2061\nn\n)\n\n\n{\\displaystyle O(\\log n)}\n\n-approximation algorithm was developed by Maleq Khan and Gopal Pandurangan.[7] This algorithm runs in \n\n\n\nO\n(\nD\n+\nL\nlog\n\u2061\nn\n)\n\n\n{\\displaystyle O(D+L\\log n)}\n\n time, where \n\n\n\nL\n\n\n{\\displaystyle L}\n\n is the local shortest path diameter[7] of the graph.", 
    "dbpedia_url": "http://dbpedia.org/resource/Distributed_minimum_spanning_tree", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Distributed_minimum_spanning_tree\n"
}