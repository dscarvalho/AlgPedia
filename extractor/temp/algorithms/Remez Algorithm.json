{
    "about": "The Remez algorithm or Remez exchange algorithm, published by Evgeny Yakovlevich Remez in 1934,[1] is an iterative algorithm used to find simple approximations to functions, specifically, approximations by functions in a Chebyshev space that are the best in the uniform norm L\u221e sense.", 
    "name": "Remez Algorithm", 
    "classification": "Numerical Analysis", 
    "full_text": "The Remez algorithm or Remez exchange algorithm, published by Evgeny Yakovlevich Remez in 1934,[1] is an iterative algorithm used to find simple approximations to functions, specifically, approximations by functions in a Chebyshev space that are the best in the uniform norm L\u221e sense.\nA typical example of a Chebyshev space is the subspace of Chebyshev polynomials of order n in the space of real continuous functions on an interval, C[a, b]. The polynomial of best approximation within a given subspace is defined to be the one that minimizes the maximum absolute difference between the polynomial and the function. In this case, the form of the solution is precised by the equioscillation theorem.\n\n\nThe Remez algorithm starts with the function f to be approximated and a set X of \n\n\n\nn\n+\n2\n\n\n{\\displaystyle n+2}\n\n sample points \n\n\n\n\nx\n\n1\n\n\n,\n\nx\n\n2\n\n\n,\n.\n.\n.\n,\n\nx\n\nn\n+\n2\n\n\n\n\n{\\displaystyle x_{1},x_{2},...,x_{n+2}}\n\n in the approximation interval, usually the Chebyshev nodes linearly mapped to the interval. The steps are:\nThe result is called the polynomial of best approximation or the minimax approximation.\nA review of technicalities in implementing the Remez algorithm is given by W. Fraser.[2]\nThe Chebyshev nodes are a common choice for the initial approximation because of their role in the theory of polynomial interpolation. For the initialization of the optimization problem for function f by the Lagrange interpolant Ln(f), it can be shown that this initial approximation is bounded by\nwith the norm or Lebesgue constant of the Lagrange interpolation operator Ln of the nodes (t1, ..., tn\u00a0+\u00a01) being\nT being the zeros of the Chebyshev polynomials, and the Lebesgue functions being\nTheodore A. Kilgore,[3] Carl de Boor, and Allan Pinkus[4] proved that there exists a unique ti for each Ln, although not known explicitly for (ordinary) polynomials. Similarly, \n\n\n\n\n\n\n\u039b\n_\n\n\n\nn\n\n\n(\nT\n)\n=\n\nmin\n\n\u2212\n1\n\u2264\nx\n\u2264\n1\n\n\n\n\u03bb\n\nn\n\n\n(\nT\n;\nx\n)\n\n\n{\\displaystyle {\\underline {\\Lambda }}_{n}(T)=\\min _{-1\\leq x\\leq 1}\\lambda _{n}(T;x)}\n\n, and the optimality of a choice of nodes can be expressed as \n\n\n\n\n\n\n\u039b\n\u00af\n\n\n\nn\n\n\n\u2212\n\n\n\n\u039b\n_\n\n\n\nn\n\n\n\u2265\n0.\n\n\n{\\displaystyle {\\overline {\\Lambda }}_{n}-{\\underline {\\Lambda }}_{n}\\geq 0.}\n\n\nFor Chebyshev nodes, which provides a suboptimal, but analytically explicit choice, the asymptotic behavior is known as[5]\n(\u03b3 being the Euler-Mascheroni constant) with\nand upper bound[6]\nLev Brutman[7] obtained the bound for \n\n\n\nn\n\u2265\n3\n\n\n{\\displaystyle n\\geq 3}\n\n, and \n\n\n\n\n\n\nT\n^\n\n\n\n\n\n{\\displaystyle {\\hat {T}}}\n\n being the zeros of the expanded Chebyshev polynomials:\nR\u00fcdiger G\u00fcnttner[8] obtained from a sharper estimate for \n\n\n\nn\n\u2265\n40\n\n\n{\\displaystyle n\\geq 40}\n\n\nThis section provides more information on the steps outlined above. In this section, the index i runs from 0 to n+1.\nStep 1: Given \n\n\n\n\nx\n\n0\n\n\n,\n\nx\n\n1\n\n\n,\n.\n.\n.\n\nx\n\nn\n+\n1\n\n\n\n\n{\\displaystyle x_{0},x_{1},...x_{n+1}}\n\n, solve the linear system of n+2 equations\nIt should be clear that \n\n\n\n(\n\u2212\n1\n\n)\n\ni\n\n\nE\n\n\n{\\displaystyle (-1)^{i}E}\n\n in this equation makes sense only if the nodes \n\n\n\n\nx\n\n0\n\n\n,\n.\n.\n.\n,\n\nx\n\nn\n+\n1\n\n\n\n\n{\\displaystyle x_{0},...,x_{n+1}}\n\n are ordered, either strictly increasing or strictly decreasing. Then this linear system has a unique solution. (As is well known, not every linear system has a solution.) Also, the solution can be obtained with only \n\n\n\nO\n(\n\nn\n\n2\n\n\n)\n\n\n{\\displaystyle O(n^{2})}\n\n arithmetic operations while a standard solver from the library would take \n\n\n\nO\n(\n\nn\n\n3\n\n\n)\n\n\n{\\displaystyle O(n^{3})}\n\n operations. Here is the simple proof:\nCompute the standard n-th degree interpolant \n\n\n\n\np\n\n1\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{1}(x)}\n\n to \n\n\n\nf\n(\nx\n)\n\n\n{\\displaystyle f(x)}\n\n at the first n+1 nodes and also the standard n-th degree interpolant \n\n\n\n\np\n\n2\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{2}(x)}\n\n to the ordinates \n\n\n\n(\n\u2212\n1\n\n)\n\ni\n\n\n\n\n{\\displaystyle (-1)^{i}}\n\n\nTo this end, use each time Newton's interpolation formula with the divided differences of order \n\n\n\n0\n,\n.\n.\n.\n,\nn\n\n\n{\\displaystyle 0,...,n}\n\n and \n\n\n\nO\n(\n\nn\n\n2\n\n\n)\n\n\n{\\displaystyle O(n^{2})}\n\n arithmetic operations.\nThe polynomial \n\n\n\n\np\n\n2\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{2}(x)}\n\n has its i-th zero between \n\n\n\n\nx\n\ni\n\u2212\n1\n\n\n\n\n{\\displaystyle x_{i-1}}\n\n and \n\n\n\n\nx\n\ni\n\n\n,\n\u00a0\ni\n=\n1\n,\n.\n.\n.\n,\nn\n\n\n{\\displaystyle x_{i},\\ i=1,...,n}\n\n, and thus no further zeroes between \n\n\n\n\nx\n\nn\n\n\n\n\n{\\displaystyle x_{n}}\n\n and \n\n\n\n\nx\n\nn\n+\n1\n\n\n\n\n{\\displaystyle x_{n+1}}\n\n: \n\n\n\n\np\n\n2\n\n\n(\n\nx\n\nn\n\n\n)\n\n\n{\\displaystyle p_{2}(x_{n})}\n\n and \n\n\n\n\np\n\n2\n\n\n(\n\nx\n\nn\n+\n1\n\n\n)\n\n\n{\\displaystyle p_{2}(x_{n+1})}\n\n have the same sign \n\n\n\n(\n\u2212\n1\n\n)\n\nn\n\n\n\n\n{\\displaystyle (-1)^{n}}\n\n.\nThe linear combination \n\n\n\np\n(\nx\n)\n:=\n\np\n\n1\n\n\n(\nx\n)\n\u2212\n\np\n\n2\n\n\n(\nx\n)\n\n\u22c5\n\nE\n\n\n{\\displaystyle p(x):=p_{1}(x)-p_{2}(x)\\!\\cdot \\!E}\n\n is also a polynomial of degree n and\nThis is the same as the equation above for \n\n\n\ni\n=\n0\n,\n.\n.\n.\n,\nn\n\n\n{\\displaystyle i=0,...,n}\n\n and for any choice of E. The same equation for i = n+1 is\nAs mentioned above, the two terms in the denominator have same sign: E and thus \n\n\n\np\n(\nx\n)\n\u2261\n\nb\n\n0\n\n\n+\n\nb\n\n1\n\n\nx\n+\n\u2026\n+\n\nb\n\nn\n\n\n\nx\n\nn\n\n\n\n\n{\\displaystyle p(x)\\equiv b_{0}+b_{1}x+\\ldots +b_{n}x^{n}}\n\n are always well-defined.\nThe error at the given n+2 ordered nodes is positive and negative in turn because\nThe theorem of de La Vall\u00e9e Poussin states that under this condition no polynomial of degree n exists with error less than E. Indeed, if such a polynomial existed, call it \n\n\n\n\n\n\np\n~\n\n\n\n(\nx\n)\n\n\n{\\displaystyle {\\tilde {p}}(x)}\n\n, then the difference \n\n\n\np\n(\nx\n)\n\u2212\n\n\n\np\n~\n\n\n\n(\nx\n)\n=\n(\np\n(\nx\n)\n\u2212\nf\n(\nx\n)\n)\n\u2212\n(\n\n\n\np\n~\n\n\n\n(\nx\n)\n\u2212\nf\n(\nx\n)\n)\n\n\n{\\displaystyle p(x)-{\\tilde {p}}(x)=(p(x)-f(x))-({\\tilde {p}}(x)-f(x))}\n\n would still be positive/negative at the n+2 nodes \n\n\n\n\nx\n\ni\n\n\n\n\n{\\displaystyle x_{i}}\n\n and therefore have at least n+1 zeros which is impossible for a polynomial of degree n. Thus, this E is a lower bound for the minimum error which can be achieved with polynomials of degree n.\nStep 2 changes the notation from \n\n\n\n\nb\n\n0\n\n\n+\n\nb\n\n1\n\n\nx\n+\n.\n.\n.\n+\n\nb\n\nn\n\n\n\nx\n\nn\n\n\n\n\n{\\displaystyle b_{0}+b_{1}x+...+b_{n}x^{n}}\n\n to \n\n\n\np\n(\nx\n)\n\n\n{\\displaystyle p(x)}\n\n.\nStep 3 improves upon the input nodes \n\n\n\n\nx\n\n0\n\n\n,\n.\n.\n.\n,\n\nx\n\nn\n+\n1\n\n\n\n\n{\\displaystyle x_{0},...,x_{n+1}}\n\n and their errors \n\n\n\n\u00b1\nE\n\n\n{\\displaystyle \\pm E}\n\n as follows.\nIn each P-region, the current node \n\n\n\n\nx\n\ni\n\n\n\n\n{\\displaystyle x_{i}}\n\n is replaced with the local maximizer \n\n\n\n\n\n\n\nx\n\u00af\n\n\n\n\ni\n\n\n\n\n{\\displaystyle {\\bar {x}}_{i}}\n\n and in each N-region \n\n\n\n\nx\n\ni\n\n\n\n\n{\\displaystyle x_{i}}\n\n is replaced with the local minimizer. (Expect \n\n\n\n\n\n\n\nx\n\u00af\n\n\n\n\n0\n\n\n\n\n{\\displaystyle {\\bar {x}}_{0}}\n\n at A, the \n\n\n\n\n\n\n\nx\n\u00af\n\n\n\n\ni\n\n\n\n\n{\\displaystyle {\\bar {x}}_{i}}\n\n near \n\n\n\n\nx\n\ni\n\n\n\n\n{\\displaystyle x_{i}}\n\n, and \n\n\n\n\n\n\n\nx\n\u00af\n\n\n\n\nn\n+\n1\n\n\n\n\n{\\displaystyle {\\bar {x}}_{n+1}}\n\n at B.) No high precision is required here, the standard line search with a couple of quadratic fits should suffice. (See [9])\nLet \n\n\n\n\nz\n\ni\n\n\n:=\np\n(\n\n\n\n\nx\n\u00af\n\n\n\n\ni\n\n\n)\n\u2212\nf\n(\n\n\n\n\nx\n\u00af\n\n\n\n\ni\n\n\n)\n\n\n{\\displaystyle z_{i}:=p({\\bar {x}}_{i})-f({\\bar {x}}_{i})}\n\n. Each amplitude \n\n\n\n\n|\n\n\nz\n\ni\n\n\n\n|\n\n\n\n{\\displaystyle |z_{i}|}\n\n is greater than or equal to E. The Theorem of de La Vall\u00e9e Poussin and its proof also apply to \n\n\n\n\nz\n\n0\n\n\n,\n.\n.\n.\n,\n\nz\n\nn\n+\n1\n\n\n\n\n{\\displaystyle z_{0},...,z_{n+1}}\n\n with \n\n\n\nmin\n{\n\n|\n\n\nz\n\ni\n\n\n\n|\n\n}\n\u2265\nE\n\n\n{\\displaystyle \\min\\{|z_{i}|\\}\\geq E}\n\n as the new lower bound for the best error possible with polynomials of degree n.\nMoreover, \n\n\n\nmax\n{\n\n|\n\n\nz\n\ni\n\n\n\n|\n\n}\n\n\n{\\displaystyle \\max\\{|z_{i}|\\}}\n\n comes in handy as an obvious upper bound for that best possible error.\nStep 4: With \n\n\n\nmin\n\n{\n\n|\n\n\nz\n\ni\n\n\n\n|\n\n}\n\n\n{\\displaystyle \\min \\,\\{|z_{i}|\\}}\n\n and \n\n\n\nmax\n\n{\n\n|\n\n\nz\n\ni\n\n\n\n|\n\n}\n\n\n{\\displaystyle \\max \\,\\{|z_{i}|\\}}\n\n as lower and upper bound for the best possible approximation error, one has a reliable stopping criterion: repeat the steps until \n\n\n\nmax\n{\n\n|\n\n\nz\n\ni\n\n\n\n|\n\n}\n\u2212\nmin\n{\n\n|\n\n\nz\n\ni\n\n\n\n|\n\n}\n\n\n{\\displaystyle \\max\\{|z_{i}|\\}-\\min\\{|z_{i}|\\}}\n\n is sufficiently small or no longer decreases. These bounds indicate the progress.\nSometimes more than one sample point is replaced at the same time with the locations of nearby maximum absolute differences.\nSometimes relative error is used to measure the difference between the approximation and the function, especially if the approximation will be used to compute the function on a computer which uses floating point arithmetic.", 
    "dbpedia_url": "http://dbpedia.org/resource/Remez_algorithm", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Remez_algorithm\n"
}