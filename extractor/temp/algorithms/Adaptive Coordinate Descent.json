{
    "about": "Adaptive coordinate descent[1] is an improvement of the coordinate descent algorithm to non-separable optimization by the use of adaptive encoding.[2] The adaptive coordinate descent approach gradually builds a transformation of the coordinate system such that the new coordinates are as decorrelated as possible with respect to the objective function. The adaptive coordinate descent was shown to be competitive to the state-of-the-art evolutionary algorithms and has the following invariance properties:", 
    "name": "Adaptive Coordinate Descent", 
    "classification": "Optimization Algorithms And Methods", 
    "full_text": "Adaptive coordinate descent[1] is an improvement of the coordinate descent algorithm to non-separable optimization by the use of adaptive encoding.[2] The adaptive coordinate descent approach gradually builds a transformation of the coordinate system such that the new coordinates are as decorrelated as possible with respect to the objective function. The adaptive coordinate descent was shown to be competitive to the state-of-the-art evolutionary algorithms and has the following invariance properties:\nCMA-like Adaptive Encoding Update (b) mostly based on principal component analysis (a) is used to extend the coordinate descent method (c) to the optimization of non-separable problems (d).\nThe adaptation of an appropriate coordinate system allows adaptive coordinate descent to outperform coordinate descent on non-separable functions. The following figure illustrates the convergence of both algorithms on 2-dimensional Rosenbrock function up to a target function value \n\n\n\n\n10\n\n\u2212\n10\n\n\n\n\n{\\displaystyle 10^{-10}}\n\n, starting from the initial point \n\n\n\n\nx\n\n0\n\n\n=\n(\n\u2212\n3\n,\n\u2212\n4\n)\n\n\n{\\displaystyle x_{0}=(-3,-4)}\n\n.\nThe adaptive coordinate descent method reaches the target value after only 325 function evaluations (about 70 times faster than coordinate descent), that is comparable to gradient-based methods. The algorithm has linear time complexity if update coordinate system every D iterations, it is also suitable for large-scale (D>>100) non-linear optimization.\n\n\nFirst approaches to optimization using adaptive coordinate system were proposed already in the 1960s (see, e.g., Rosenbrock's method). PRincipal Axis (PRAXIS) algorithm, also referred to as Brent's algorithm, is an derivative-free algorithm which assumes quadratic form of the optimized function and repeatedly updates a set of conjugate search directions.[3] The algorithm, however, is not invariant to scaling of the objective function and may fail under its certain rank-preserving transformations (e.g., will lead to a non-quadratic shape of the objective function). A recent analysis of PRAXIS can be found in .[4] For practical applications see,[5] where an adaptive coordinate descent approach with step-size adaptation and local coordinate system rotation was proposed for robot-manipulator path planning in 3D space with static polygonal obstacles.", 
    "dbpedia_url": "http://dbpedia.org/resource/Adaptive_coordinate_descent", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Adaptive_coordinate_descent\n"
}