{
    "about": "Pipelining is an important technique used in several applications such as digital signal processing (DSP) systems, microprocessors, etc. It originates from the idea of a water pipe with continuous water sent in without waiting for the water in the pipe to come out. Accordingly, it results in speed enhancement for the critical path in most DSP systems. For example, it can either increase the clock speed or reduce the power consumption at the same speed in a DSP system.", 
    "name": "Pipelining (Dsp Implementation)", 
    "classification": "Digital Signal Processing", 
    "full_text": "Pipelining is an important technique used in several applications such as digital signal processing (DSP) systems, microprocessors, etc. It originates from the idea of a water pipe with continuous water sent in without waiting for the water in the pipe to come out. Accordingly, it results in speed enhancement for the critical path in most DSP systems. For example, it can either increase the clock speed or reduce the power consumption at the same speed in a DSP system.\n\n\nPipelining allows different functional units of a system to run concurrently. Consider an informal example in the following figure. A system includes three sub-function units (F0, F1 and F2). Assume that there are three independent tasks (T0, T1 and T2) being performed by these three function units. The time for each function unit to complete a task is the same and will occupy a slot in the schedule.\nIf we put these three units and tasks in a sequential order, the required time to complete them is five slots.\nHowever, if we pipeline T0 to T2 concurrently, the aggregate time is reduced to three slots.\nTherefore, it is possible for an adequate pipelined design to achieve significant enhancement on speed.\nPipelining cannot decrease the processing time required for a single task. The advantage of pipelining is that it increases the throughput of the system when processing a stream of tasks.\nApplying too many pipelined functions can lead to increased latency - that is, the time required for a single task to propagate through the full pipe is prolonged. A pipelined system may also require more resources (buffers, circuits, processing units, memory etc.), if the reuse of resources across different stages is restricted.\nAnother technique to enhance the efficiency through concurrency is parallel processing. The core difference is that parallel techniques usually duplicate function units and distribute multiple input tasks at once amongst them. Therefore, it can complete more tasks per unit time but may suffer more expensive resource costs.\nFor the previous example, the parallel technique duplicates each function units into another two. Accordingly, all the tasks can be operated upon by the duplicated function units with the same function simultaneously. The time to complete these three tasks is reduced to three slots.\nConsider a 3-tap FIR filter:[1]\nwhich is as shown in the following figure.\nAssume the calculation time for multiplication units is Tm and Ta for add units. The critical path, representing the minimum time required for processing a new sample, is limited by 1 multiplication and 2 add function units. Therefore, the sample period is given by\nHowever, such structure may not be suitable for the design with the requirement of high speed. To reduce the sampling period, we can introduce extra pipelining registers along the critical data path. Then the structure is partitioned into two stages and the data produced in the first stage will be stored in the introduced registers, delaying one clock to the second stage. The data in first three clocks is recorded in the following table. Under such pipelined structure, the sample period is reduced to\n\nBy combining look-ahead techniques and pipelining,[2] we are able to enhance the sample rate of target design. Look-ahead pipelining will add canceling poles and zeroes to the transfer function such that the coefficients of the following terms in the denominator of the transfer function are zero.\nThen, the output sample y(n) can be computed in terms of the inputs and the output sample y(n\u00a0\u2212\u00a0M) such that there are M delay elements in the critical loop. These elements are then used to pipeline the critical loop by M stages so that the sample rate can be increased by a factor M.\nConsider the 1st-order IIR filter transfer function\nThe output y(n) can be computed in terms of the input u(n) and the previous output.\nIn a straightforward structure to design such function, the sample rate of this recursive filter is restricted by the calculation time of one multiply-add operation.\nTo pipeline such design, we observe that H has a pole at\nTherefore, in a 3-stage pipelined equivalent stable filter, the transfer function can be derived by adding poles and zeros at\nand is given by\nTherefore, the corresponding sample rate can be increased by a factor 3.", 
    "dbpedia_url": "http://dbpedia.org/resource/Pipelining_(DSP_implementation)", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Pipelining_(DSP_implementation)\n"
}