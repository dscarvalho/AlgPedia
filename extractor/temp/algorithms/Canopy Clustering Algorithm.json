{
    "about": "The canopy clustering algorithm is an unsupervised pre-clustering algorithm introduced by Andrew McCallum, Kamal Nigam and Lyle Ungar in 2000.[1] It is often used as preprocessing step for the K-means algorithm or the Hierarchical clustering algorithm. It is intended to speed up clustering operations on large data sets, where using another algorithm directly may be impractical due to the size of the data set.", 
    "name": "Canopy Clustering Algorithm", 
    "classification": "Statistical Algorithms", 
    "full_text": "The canopy clustering algorithm is an unsupervised pre-clustering algorithm introduced by Andrew McCallum, Kamal Nigam and Lyle Ungar in 2000.[1] It is often used as preprocessing step for the K-means algorithm or the Hierarchical clustering algorithm. It is intended to speed up clustering operations on large data sets, where using another algorithm directly may be impractical due to the size of the data set.\nThe algorithm proceeds as follows, using two thresholds \n\n\n\n\nT\n\n1\n\n\n\n\n{\\displaystyle T_{1}}\n\n (the loose distance) and \n\n\n\n\nT\n\n2\n\n\n\n\n{\\displaystyle T_{2}}\n\n (the tight distance), where \n\n\n\n\nT\n\n1\n\n\n>\n\nT\n\n2\n\n\n\n\n{\\displaystyle T_{1}>T_{2}}\n\n .[1][2]\nAn important note is that individual data points may be part of several canopies. As an additional speed-up, an approximate and fast distance metric can be used for 3, where a more accurate and slow distance metric can be used for step 4.\nSince the algorithm uses distance functions and requires the specification of distance thresholds, its applicability for high-dimensional data is limited by the curse of dimensionality. Only when a cheap and approximative \u2013 low-dimensional \u2013 distance function is available, the produced canopies will preserve the clusters produced by K-means.\n", 
    "dbpedia_url": "http://dbpedia.org/resource/Canopy_clustering_algorithm", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Canopy_clustering_algorithm\n"
}