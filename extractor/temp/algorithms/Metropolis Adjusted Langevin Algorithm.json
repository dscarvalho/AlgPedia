{
    "about": "In computational statistics, the Metropolis-adjusted Langevin algorithm (MALA) is a Markov chain Monte Carlo (MCMC) method for obtaining random samples \u2013 sequences of random observations \u2013 from a probability distribution for which direct sampling is difficult. As the name suggests, MALA uses a combination of two mechanisms to generate the states of a random walk that has the target probability distribution as an invariant measure:", 
    "classification": "Statistical Algorithms", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Metropolis-adjusted_Langevin_algorithm\n", 
    "full_text": "In computational statistics, the Metropolis-adjusted Langevin algorithm (MALA) is a Markov chain Monte Carlo (MCMC) method for obtaining random samples \u2013 sequences of random observations \u2013 from a probability distribution for which direct sampling is difficult. As the name suggests, MALA uses a combination of two mechanisms to generate the states of a random walk that has the target probability distribution as an invariant measure:\nInformally, the Langevin dynamics drive the random walk towards regions of high probability in the manner of a gradient flow, while the Metropolis\u2013Hastings accept/reject mechanism improves the mixing and convergence properties of this random walk. MALA was originally proposed by Roberts and Rosenthal in 1998,[1] and many variations and refinements have been introduced since then, e.g. the manifold variant of Girolami and Calderhead (2011).[2]\nLet \n\n\n\n\u03c0\n\n\n{\\displaystyle \\pi }\n\n denote a probability density function on \n\n\n\n\n\nR\n\n\nd\n\n\n\n\n{\\displaystyle \\mathbb {R} ^{d}}\n\n, one from which it is desired to draw an ensemble of independent and identically distributed samples. We consider the overdamped Langevin It\u00f4 diffusion\ndriven by the time derivative of a standard Brownian motion \n\n\n\nW\n\n\n{\\displaystyle W}\n\n. (Note that another commonly-used normalisation for this diffusion is\nwhich generates the same dynamics.) In the limit as \n\n\n\nt\n\u2192\n\u221e\n\n\n{\\displaystyle t\\to \\infty }\n\n, this probability distribution \n\n\n\n\u03c1\n(\nt\n)\n\n\n{\\displaystyle \\rho (t)}\n\n of \n\n\n\nX\n(\nt\n)\n\n\n{\\displaystyle X(t)}\n\n approaches a stationary distribution, which is also invariant under the diffusion, which we denote \n\n\n\n\n\u03c1\n\n\u221e\n\n\n\n\n{\\displaystyle \\rho _{\\infty }}\n\n. It turns out that, in fact, \n\n\n\n\n\u03c1\n\n\u221e\n\n\n=\n\u03c0\n\n\n{\\displaystyle \\rho _{\\infty }=\\pi }\n\n.\nApproximate sample paths of the Langevin diffusion can be generated by many discrete-time methods. One of the simplest is the Euler\u2013Maruyama method with a fixed time step \n\n\n\n\u03c4\n>\n0\n\n\n{\\displaystyle \\tau >0}\n\n. We set \n\n\n\n\nX\n\n0\n\n\n:=\n\nx\n\n0\n\n\n\n\n{\\displaystyle X_{0}:=x_{0}}\n\n and then recursively define an approximation \n\n\n\n\nX\n\nk\n\n\n\n\n{\\displaystyle X_{k}}\n\n to the true solution \n\n\n\nX\n(\nk\n\u03c4\n)\n\n\n{\\displaystyle X(k\\tau )}\n\n by\nwhere each \n\n\n\n\n\u03be\n\nk\n\n\n\n\n{\\displaystyle \\xi _{k}}\n\n is an independent draw from a multivariate normal distribution on \n\n\n\n\n\nR\n\n\nd\n\n\n\n\n{\\displaystyle \\mathbb {R} ^{d}}\n\n with mean 0 and covariance matrix equal to the \n\n\n\nd\n\u00d7\nd\n\n\n{\\displaystyle d\\times d}\n\n identity matrix. Note that \n\n\n\n\nX\n\nk\n+\n1\n\n\n\n\n{\\displaystyle X_{k+1}}\n\n is normally distributed with mean \n\n\n\n\nX\n\nk\n\n\n+\n\u03c4\n\u2207\nlog\n\u2061\n\u03c0\n(\n\nX\n\nk\n\n\n)\n\n\n{\\displaystyle X_{k}+\\tau \\nabla \\log \\pi (X_{k})}\n\n and covariance equal to \n\n\n\n2\n\u03c4\n\n\n{\\displaystyle 2\\tau }\n\n times the \n\n\n\nd\n\u00d7\nd\n\n\n{\\displaystyle d\\times d}\n\n identity matrix.\nIn contrast to the Euler\u2013Maruyama method for simulating the Langevin diffusion, which always updates \n\n\n\n\nX\n\nk\n\n\n\n\n{\\displaystyle X_{k}}\n\n according to the update rule\nMALA incorporates an additional step. We consider the above update rule as defining a proposal \n\n\n\n\n\n\n\nX\n~\n\n\n\n\nk\n+\n1\n\n\n\n\n{\\displaystyle {\\tilde {X}}_{k+1}}\n\n for a new state,\nThis proposal is accepted or rejected according to the Metropolis\u2013Hastings algorithm: set\nwhere\nis the transition probability density from \n\n\n\nx\n\n\n{\\displaystyle x}\n\n to \n\n\n\n\nx\n\u2032\n\n\n\n{\\displaystyle x'}\n\n (note that, in general \n\n\n\nq\n(\n\nx\n\u2032\n\n\u2223\nx\n)\n\u2260\nq\n(\nx\n\u2223\n\nx\n\u2032\n\n)\n\n\n{\\displaystyle q(x'\\mid x)\\neq q(x\\mid x')}\n\n). Let \n\n\n\nu\n\n\n{\\displaystyle u}\n\n be drawn from the continuous uniform distribution on the interval \n\n\n\n[\n0\n,\n1\n]\n\n\n{\\displaystyle [0,1]}\n\n. If \n\n\n\nu\n\u2264\n\u03b1\n\n\n{\\displaystyle u\\leq \\alpha }\n\n, then the proposal is accepted, and we set \n\n\n\n\nX\n\nk\n+\n1\n\n\n:=\n\n\n\n\nX\n~\n\n\n\n\nk\n+\n1\n\n\n\n\n{\\displaystyle X_{k+1}:={\\tilde {X}}_{k+1}}\n\n; otherwise, the proposal is rejected, and we set \n\n\n\n\nX\n\nk\n+\n1\n\n\n:=\n\nX\n\nk\n\n\n\n\n{\\displaystyle X_{k+1}:=X_{k}}\n\n.\nThe combined dynamics of the Langevin diffusion and the Metropolis\u2013Hastings algorithm satisfy the detailed balance conditions necessary for the existence of a unique, invariant, stationary distribution \n\n\n\n\n\u03c1\n\n\u221e\n\n\n=\n\u03c0\n\n\n{\\displaystyle \\rho _{\\infty }=\\pi }\n\n. Compared to naive Metropolis\u2013Hastings, MALA has the advantage that it usually proposes moves into regions of higher \n\n\n\n\u03c0\n\n\n{\\displaystyle \\pi }\n\n probability, which are then more likely to be accepted. On the other hand, when \n\n\n\n\u03c0\n\n\n{\\displaystyle \\pi }\n\n is strongly anisotropic (i.e. it varies much more quickly in some directions than others), it is necessary to take \n\n\n\n0\n<\n\u03c4\n\u226a\n1\n\n\n{\\displaystyle 0<\\tau \\ll 1}\n\n in order to properly capture the Langevin dynamics; the use of a positive-definite preconditioning matrix \n\n\n\nA\n\u2208\n\n\nR\n\n\nd\n\u00d7\nd\n\n\n\n\n{\\displaystyle A\\in \\mathbb {R} ^{d\\times d}}\n\n can help to alleviate this problem, by generating proposals according to\nso that \n\n\n\n\n\n\n\nX\n~\n\n\n\n\nk\n+\n1\n\n\n\n\n{\\displaystyle {\\tilde {X}}_{k+1}}\n\n has mean \n\n\n\n\nX\n\nk\n\n\n+\n\u03c4\nA\n\u2207\nlog\n\u2061\n\u03c0\n(\n\nX\n\nk\n\n\n)\n\n\n{\\displaystyle X_{k}+\\tau A\\nabla \\log \\pi (X_{k})}\n\n and covariance \n\n\n\n2\n\u03c4\nA\n\n\n{\\displaystyle 2\\tau A}\n\n.", 
    "name": "Metropolis Adjusted Langevin Algorithm"
}