{
    "about": "Grammatical evolution is a relatively new evolutionary computation technique pioneered by Conor Ryan, JJ Collins and Michael O'Neill in 1998[1] at the BDS Group in the University of Limerick.", 
    "name": "Grammatical Evolution", 
    "classification": "Evolutionary Algorithms", 
    "full_text": "Grammatical evolution is a relatively new evolutionary computation technique pioneered by Conor Ryan, JJ Collins and Michael O'Neill in 1998[1] at the BDS Group in the University of Limerick.\nIt is related to the idea of genetic programming in that the objective is to find an executable program or program fragment, that will achieve a good fitness value for the given objective function. In most published work on Genetic Programming, a LISP-style tree-structured expression is directly manipulated, whereas Grammatical Evolution applies genetic operators to an integer string, subsequently mapped to a program (or similar) through the use of a grammar. One of the benefits of GE is that this mapping simplifies the application of search to different programming languages and other structures.\n\n\nIn type-free, conventional Koza-style GP, the function set must meet the requirement of closure: all functions must be capable of accepting as their arguments the output of all other functions in the function set. Usually, this is implemented by dealing with a single data-type such as double-precision floating point. While modern Genetic Programming frameworks support typing, such type-systems have limitations that Grammatical Evolution does not suffer from.\nGE offers a solution to this[which?] issue by evolving solutions according to a user-specified grammar (usually a grammar in Backus-Naur form). Therefore the search space can be restricted, and domain knowledge of the problem can be incorporated. The inspiration for this approach comes from a desire to separate the \"genotype\" from the \"phenotype\": in GP, the objects the search algorithm operates on and what the fitness evaluation function interprets are one and the same. In contrast, GE's \"genotypes\" are ordered lists of integers which code for selecting rules from the provided context-free grammar. The phenotype, however, is the same as in Koza-style GP: a tree-like structure that is evaluated recursively. This model is more in line with how genetics work in nature, where there is a separation between an organism's genotype and the final expression of phenotype in proteins, etc.\nGE has a modular approach to it. In particular, the search portion of the GE paradigm needn't be carried out by any one particular algorithm or method. Observe that the objects GE performs search on are the same as that used in genetic algorithms. This means, in principle, that any existing genetic algorithm package, such as the popular GAlib, can be used to carry out the search, and a developer implementing a GE system need only worry about carrying out the mapping from list of integers to program tree. It is also in principle possible to perform the search using some other method, such as particle swarm optimization (see the remark below); the modular nature of GE creates many opportunities for hybrids as the problem of interest to be solved dictates.\nBrabazon and O'Neill have successfully applied GE to predicting corporate bankruptcy, forecasting stock indices, bond credit ratings, and other financial applications.[citation needed] GE has also been used with a classic predator-prey model to explore the impact of parameters such as predator efficiency, niche number, and random mutations on ecological stability.[2]\nIt is possible to structure a GE grammar that for a given function/terminal set is equivalent to genetic programming.\nDespite its successes, GE has been the subject of some criticism. One issue is that as a result of its mapping operation, GE's genetic operators do not achieve high locality[3][4] which is a highly regarded property of genetic operators in evolutionary algorithms.[3]\nAlthough GE is fairly new, there are already enhanced versions and variants that have been worked out. GE researchers have experimented with using particle swarm optimization to carry out the searching instead of genetic algorithms with results comparable to that of normal GE; this is referred to as a \"grammatical swarm\"; using only the basic PSO model it has been found that PSO is probably equally capable of carrying out the search process in GE as simple genetic algorithms are. (Although PSO is normally a floating-point search paradigm, it can be discretized, e.g., by simply rounding each vector to the nearest integer, for use with GE.)\nYet another possible variation that has been experimented with in the literature is attempting to encode semantic information in the grammar in order to further bias the search process.", 
    "dbpedia_url": "http://dbpedia.org/resource/Grammatical_evolution", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Grammatical_evolution\n"
}