{
    "about": "The bisection method in mathematics is a root-finding method that repeatedly bisects an interval and then selects a subinterval in which a root must lie for further processing. It is a very simple and robust method, but it is also relatively slow. Because of this, it is often used to obtain a rough approximation to a solution which is then used as a starting point for more rapidly converging methods.[1] The method is also called the interval halving method,[2] the binary search method,[3] or the dichotomy method.[4]", 
    "name": "Bisection Method", 
    "classification": "Root-Finding Algorithms", 
    "full_text": "The bisection method in mathematics is a root-finding method that repeatedly bisects an interval and then selects a subinterval in which a root must lie for further processing. It is a very simple and robust method, but it is also relatively slow. Because of this, it is often used to obtain a rough approximation to a solution which is then used as a starting point for more rapidly converging methods.[1] The method is also called the interval halving method,[2] the binary search method,[3] or the dichotomy method.[4]\n\n\nThe method is applicable for numerically solving the equation f(x)\u00a0=\u00a00 for the real variable x, where f is a continuous function defined on an interval [a,\u00a0b] and where f(a) and f(b) have opposite signs. In this case a and b are said to bracket a root since, by the intermediate value theorem, the continuous function f must have at least one root in the interval (a, b).\nAt each step the method divides the interval in two by computing the midpoint c = (a+b) / 2 of the interval and the value of the function f(c) at that point. Unless c is itself a root (which is very unlikely, but possible) there are now only two possibilities: either f(a) and f(c) have opposite signs and bracket a root, or f(c) and f(b) have opposite signs and bracket a root.[5] The method selects the subinterval that is guaranteed to be a bracket as the new interval to be used in the next step. In this way an interval that contains a zero of f is reduced in width by 50% at each step. The process is continued until the interval is sufficiently small.\nExplicitly, if f(a) and f(c) have opposite signs, then the method sets c as the new value for b, and if f(b) and f(c) have opposite signs then the method sets c as the new a. (If f(c)=0 then c may be taken as the solution and the process stops.) In both cases, the new f(a) and f(b) have opposite signs, so the method is applicable to this smaller interval.[6]\nThe input for the method is a continuous function f, an interval [a, b], and the function values f(a) and f(b). The function values are of opposite sign (there is at least one zero crossing within the interval). Each iteration performs these steps:\nWhen implementing the method on a computer, there can be problems with finite precision, so there are often additional convergence tests or limits to the number of iterations. Although f is continuous, finite precision may preclude a function value ever being zero. For f(x) = x \u2212 \u03c0, there will never be a finite representation of x that gives zero. Floating point representations also have limited precision, so at some point the midpoint of [a,\u00a0b] will be either a or b.\nThe method may be written in pseudocode as follows:[7]\nSuppose that the bisection method is used to find a root of the polynomial\nFirst, two numbers \n\n\n\na\n\n\n{\\displaystyle a}\n\n and \n\n\n\nb\n\n\n{\\displaystyle b}\n\n have to be found such that \n\n\n\nf\n(\na\n)\n\n\n{\\displaystyle f(a)}\n\n and \n\n\n\nf\n(\nb\n)\n\n\n{\\displaystyle f(b)}\n\n have opposite signs. For the above function, \n\n\n\na\n=\n1\n\n\n{\\displaystyle a=1}\n\n and \n\n\n\nb\n=\n2\n\n\n{\\displaystyle b=2}\n\n satisfy this criterion, as\nand\nBecause the function is continuous, there must be a root within the interval [1, 2].\nIn the first iteration, the end points of the interval which brackets the root are \n\n\n\n\na\n\n1\n\n\n=\n1\n\n\n{\\displaystyle a_{1}=1}\n\n and \n\n\n\n\nb\n\n1\n\n\n=\n2\n\n\n{\\displaystyle b_{1}=2}\n\n, so the midpoint is\nThe function value at the midpoint is \n\n\n\nf\n(\n\nc\n\n1\n\n\n)\n=\n(\n1.5\n\n)\n\n3\n\n\n\u2212\n(\n1.5\n)\n\u2212\n2\n=\n\u2212\n0.125\n\n\n{\\displaystyle f(c_{1})=(1.5)^{3}-(1.5)-2=-0.125}\n\n. Because \n\n\n\nf\n(\n\nc\n\n1\n\n\n)\n\n\n{\\displaystyle f(c_{1})}\n\n is negative, \n\n\n\na\n=\n1\n\n\n{\\displaystyle a=1}\n\n is replaced with \n\n\n\na\n=\n1.5\n\n\n{\\displaystyle a=1.5}\n\n for the next iteration to ensure that \n\n\n\nf\n(\na\n)\n\n\n{\\displaystyle f(a)}\n\n and \n\n\n\nf\n(\nb\n)\n\n\n{\\displaystyle f(b)}\n\n have opposite signs. As this continues, the interval between \n\n\n\na\n\n\n{\\displaystyle a}\n\n and \n\n\n\nb\n\n\n{\\displaystyle b}\n\n will become increasingly smaller, converging on the root of the function. See this happen in the table below.\nAfter 13 iterations, it becomes apparent that there is a convergence to about 1.521: a root for the polynomial.\nThe method is guaranteed to converge to a root of f if f is a continuous function on the interval [a, b] and f(a) and f(b) have opposite signs. The absolute error is halved at each step so the method converges linearly, which is comparatively slow.\nSpecifically, if c1 = a+b/2 is the midpoint of the initial interval, and cn is the midpoint of the interval in the nth step, then the difference between cn and a solution c is bounded by[8]\nThis formula can be used to determine in advance the number of iterations that the bisection method would need to converge to a root to within a certain tolerance. The number of iterations needed, n, to achieve a given error (or tolerance), \u03b5, is given by: \n\n\n\nn\n=\n\nlog\n\n2\n\n\n\u2061\n\n(\n\n\n\n\u03f5\n\n0\n\n\n\u03f5\n\n\n)\n\n=\n\n\n\nlog\n\u2061\n\n\u03f5\n\n0\n\n\n\u2212\nlog\n\u2061\n\u03f5\n\n\nlog\n\u2061\n2\n\n\n\n,\n\n\n{\\displaystyle n=\\log _{2}\\left({\\frac {\\epsilon _{0}}{\\epsilon }}\\right)={\\frac {\\log \\epsilon _{0}-\\log \\epsilon }{\\log 2}},}\n\n\nwhere \n\n\n\n\n\u03f5\n\n0\n\n\n=\n\ninitial bracket size\n\n=\nb\n\u2212\na\n.\n\n\n{\\displaystyle \\epsilon _{0}={\\text{initial bracket size}}=b-a.}\n\n\nTherefore, the linear convergence is expressed by \n\n\n\n\n\u03f5\n\nn\n+\n1\n\n\n=\n\nconstant\n\n\u00d7\n\n\u03f5\n\nn\n\n\nm\n\n\n,\n\u00a0\nm\n=\n1.\n\n\n{\\displaystyle \\epsilon _{n+1}={\\text{constant}}\\times \\epsilon _{n}^{m},\\ m=1.}\n\n", 
    "dbpedia_url": "http://dbpedia.org/resource/Bisection_method", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Bisection_method\n"
}