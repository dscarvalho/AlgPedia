{
    "about": "In operations research, the Big M method is a method of solving linear programming problems using the simplex algorithm. The Big M method extends the power of the simplex algorithm to problems that contain \"greater-than\" constraints. It does so by associating the constraints with large negative constants which would not be part of any optimal solution, if it exists.", 
    "name": "Big M Method", 
    "classification": "Optimization Algorithms And Methods", 
    "full_text": "In operations research, the Big M method is a method of solving linear programming problems using the simplex algorithm. The Big M method extends the power of the simplex algorithm to problems that contain \"greater-than\" constraints. It does so by associating the constraints with large negative constants which would not be part of any optimal solution, if it exists.\n\n\nThe simplex algorithm is the original and still one of the most widely used methods for solving linear maximization problems. However, to apply it, the origin (all variables equal to 0) must be a feasible point. This condition is satisfied only when all the constraints (except non-negativity) are less-than constraints with a positive constant on the right-hand side. The Big M method introduces surplus and artificial variables to convert all inequalities into that form. The \"Big M\" refers to a large number associated with the artificial variables, represented by the letter\u00a0M.\nThe steps in the algorithm are as follows:\nFor example x\u00a0+\u00a0y\u00a0\u2264 \u00a0100 becomes x\u00a0+\u00a0y\u00a0+\u00a0s1\u00a0=\u00a0100, whilst x\u00a0+\u00a0y\u00a0\u2265\u00a0100 becomes x\u00a0+\u00a0y\u00a0\u2212\u00a0a1\u00a0=\u00a0100. The artificial variables must be shown to be\u00a00. The function to be maximised is rewritten to include the sum of all the artificial variables. Then row reductions are applied to gain a final solution.\nThe value of M must be chosen sufficiently large so that the artificial variable would not be part of any feasible solution.\nFor a sufficiently large M, the optimal solution contains any artificial variables in the basis (i.e. positive values) if and only if the problem is not feasible.\nWhen used in the objective function, the Big M method sometimes refers to formulations of linear optimization problems in which violations of a constraint or set of constraints are associated with a large positive penalty constant, M.\nWhen used in the constraints themselves, one of the many uses of Big M, for example, refers to ensuring equality of variables only when a certain binary variable takes on one value, but to leave the variables \"open\" if the binary variable takes on its opposite value. One instance of this is as follows: for a sufficiently large M and z binary variable (0 or 1), the constraints\nensure that when \n\n\n\nz\n=\n0\n\n\n{\\displaystyle z=0}\n\n then \n\n\n\nx\n=\ny\n\n\n{\\displaystyle x=y}\n\n. Otherwise, when \n\n\n\nz\n=\n1\n\n\n{\\displaystyle z=1}\n\n, then \n\n\n\n\u2212\nM\n\u2264\nx\n\u2212\ny\n\u2264\nM\n\n\n{\\displaystyle -M\\leq x-y\\leq M}\n\n, indicating that the variables x and y can have any values so long as the absolute value of their difference is bounded by \n\n\n\nM\n\n\n{\\displaystyle M}\n\n (hence the need for M to be \"large enough.\")\nBibliography\nDiscussion", 
    "dbpedia_url": "http://dbpedia.org/resource/Big_M_method", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Big_M_method\n"
}