{
    "about": "Linear time-invariant theory, commonly known as LTI system theory, comes from applied mathematics and has direct applications in NMR spectroscopy, seismology, circuits, signal processing, control theory, and other technical areas. It investigates the response of a linear and time-invariant system to an arbitrary input signal. Trajectories of these systems are commonly measured and tracked as they move through time (e.g., an acoustic waveform), but in applications like image processing and field theory, the LTI systems also have trajectories in spatial dimensions. Thus, these systems are also called linear translation-invariant to give the theory the most general reach. In the case of generic discrete-time (i.e., sampled) systems, linear shift-invariant is the corresponding term. A good example of LTI systems are electrical circuits that can be made up of resistors, capacitors, and inductors.[1]", 
    "name": "Lti System Theory", 
    "classification": "Digital Signal Processing", 
    "full_text": "Linear time-invariant theory, commonly known as LTI system theory, comes from applied mathematics and has direct applications in NMR spectroscopy, seismology, circuits, signal processing, control theory, and other technical areas. It investigates the response of a linear and time-invariant system to an arbitrary input signal. Trajectories of these systems are commonly measured and tracked as they move through time (e.g., an acoustic waveform), but in applications like image processing and field theory, the LTI systems also have trajectories in spatial dimensions. Thus, these systems are also called linear translation-invariant to give the theory the most general reach. In the case of generic discrete-time (i.e., sampled) systems, linear shift-invariant is the corresponding term. A good example of LTI systems are electrical circuits that can be made up of resistors, capacitors, and inductors.[1]\n\n\nThe defining properties of any LTI system are linearity and time invariance.\nInput \u00a0 \n\n\n\n\n\u222b\n\n\u2212\n\u221e\n\n\n\u221e\n\n\n\nc\n\n\u03c9\n\n\n\n\nx\n\n\u03c9\n\n\n(\nt\n)\n\nd\n\u2061\n\u03c9\n\n\n{\\displaystyle \\int _{-\\infty }^{\\infty }c_{\\omega }\\,x_{\\omega }(t)\\,\\operatorname {d} \\omega }\n\n \u00a0 produces output \u00a0 \n\n\n\n\n\u222b\n\n\u2212\n\u221e\n\n\n\u221e\n\n\n\nc\n\n\u03c9\n\n\n\n\ny\n\n\u03c9\n\n\n(\nt\n)\n\nd\n\u2061\n\u03c9\n\n\n\n{\\displaystyle \\int _{-\\infty }^{\\infty }c_{\\omega }\\,y_{\\omega }(t)\\,\\operatorname {d} \\omega \\,}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(Eq.1)\nThe fundamental result in LTI system theory is that any LTI system can be characterized entirely by a single function called the system's impulse response. The output of the system is simply the convolution of the input to the system with the system's impulse response. This method of analysis is often called the time domain point-of-view. The same result is true of discrete-time linear shift-invariant systems in which signals are discrete-time samples, and convolution is defined on sequences.\nEquivalently, any LTI system can be characterized in the frequency domain by the system's transfer function, which is the Laplace transform of the system's impulse response (or Z transform in the case of discrete-time systems). As a result of the properties of these transforms, the output of the system in the frequency domain is the product of the transfer function and the transform of the input. In other words, convolution in the time domain is equivalent to multiplication in the frequency domain.\nFor all LTI systems, the eigenfunctions, and the basis functions of the transforms, are complex exponentials. This is, if the input to a system is the complex waveform \n\n\n\nA\n\ne\n\ns\nt\n\n\n\n\n{\\displaystyle Ae^{st}}\n\n for some complex amplitude \n\n\n\nA\n\n\n{\\displaystyle A}\n\n and complex frequency \n\n\n\ns\n\n\n{\\displaystyle s}\n\n, the output will be some complex constant times the input, say \n\n\n\nB\n\ne\n\ns\nt\n\n\n\n\n{\\displaystyle Be^{st}}\n\n for some new complex amplitude \n\n\n\nB\n\n\n{\\displaystyle B}\n\n. The ratio \n\n\n\nB\n\n/\n\nA\n\n\n{\\displaystyle B/A}\n\n is the transfer function at frequency \n\n\n\ns\n\n\n{\\displaystyle s}\n\n.\nSince sinusoids are a sum of complex exponentials with complex-conjugate frequencies, if the input to the system is a sinusoid, then the output of the system will also be a sinusoid, perhaps with a different amplitude and a different phase, but always with the same frequency upon reaching steady-state. LTI systems cannot produce frequency components that are not in the input.\nLTI system theory is good at describing many important systems. Most LTI systems are considered \"easy\" to analyze, at least compared to the time-varying and/or nonlinear case. Any system that can be modeled as a linear homogeneous differential equation with constant coefficients is an LTI system. Examples of such systems are electrical circuits made up of resistors, inductors, and capacitors (RLC circuits). Ideal spring\u2013mass\u2013damper systems are also LTI systems, and are mathematically equivalent to RLC circuits.\nMost LTI system concepts are similar between the continuous-time and discrete-time (linear shift-invariant) cases. In image processing, the time variable is replaced with two space variables, and the notion of time invariance is replaced by two-dimensional shift invariance. When analyzing filter banks and MIMO systems, it is often useful to consider vectors of signals.\nA linear system that is not time-invariant can be solved using other approaches such as the Green function method. The same method must be used when the initial conditions of the problem are not null.\nThe behavior of a linear, continuous-time, time-invariant system with input signal x(t) and output signal y(t) is described by the convolution integral:[2]\nwhere \n\n\n\n\nh\n(\nt\n)\n\n\n\n{\\displaystyle \\textstyle h(t)}\n\n is the system's response to an impulse: \u00a0\n\n\n\n\nx\n(\n\u03c4\n)\n=\n\u03b4\n(\n\u03c4\n)\n.\n\n\n\n{\\displaystyle \\textstyle x(\\tau )=\\delta (\\tau ).}\n\n \u00a0 \n\n\n\n\ny\n(\nt\n)\n\n\n\n{\\displaystyle \\textstyle y(t)}\n\n is therefore proportional to a weighted average of the input function \n\n\n\n\nx\n(\n\u03c4\n)\n.\n\n\n\n{\\displaystyle \\textstyle x(\\tau ).}\n\n\u00a0 The weighting function is \n\n\n\n\nh\n(\n\u2212\n\u03c4\n)\n,\n\n\n\n{\\displaystyle \\textstyle h(-\\tau ),}\n\n simply shifted by amount \n\n\n\n\nt\n.\n\n\n\n{\\displaystyle \\textstyle t.}\n\n \u00a0 As \n\n\n\n\nt\n\n\n\n{\\displaystyle \\textstyle t}\n\n changes, the weighting function emphasizes different parts of the input function. When \n\n\n\n\nh\n(\n\u03c4\n)\n\n\n\n{\\displaystyle \\textstyle h(\\tau )}\n\n is zero for all negative \n\n\n\n\n\u03c4\n,\n\n\n\n{\\displaystyle \\textstyle \\tau ,}\n\n\u00a0 \n\n\n\n\ny\n(\nt\n)\n\n\n\n{\\displaystyle \\textstyle y(t)}\n\n depends only on values of \n\n\n\n\nx\n\n\n\n{\\displaystyle \\textstyle x}\n\n prior to time \n\n\n\n\nt\n,\n\n\n\n{\\displaystyle \\textstyle t,}\n\n\u00a0 and the system is said to be causal.\nTo understand why the convolution produces the output of an LTI system, let the notation \n\n\n\n\n{\nx\n(\nu\n\u2212\n\u03c4\n)\n;\n\u00a0\nu\n}\n\n\n\n{\\displaystyle \\textstyle \\{x(u-\\tau );\\ u\\}}\n\n represent the function \n\n\n\n\nx\n(\nu\n\u2212\n\u03c4\n)\n\n\n\n{\\displaystyle \\textstyle x(u-\\tau )}\n\n with variable \n\n\n\n\nu\n\n\n\n{\\displaystyle \\textstyle u}\n\n and constant \n\n\n\n\n\u03c4\n.\n\n\n\n{\\displaystyle \\textstyle \\tau .}\n\n\u00a0 And let the shorter notation \n\n\n\n\n{\nx\n}\n\n\n\n\n{\\displaystyle \\textstyle \\{x\\}\\,}\n\n represent \n\n\n\n\n{\nx\n(\nu\n)\n;\n\u00a0\nu\n}\n.\n\n\n\n{\\displaystyle \\textstyle \\{x(u);\\ u\\}.}\n\n Then a continuous-time system transforms an input function, \n\n\n\n\n{\nx\n}\n,\n\n\n\n{\\displaystyle \\textstyle \\{x\\},}\n\n into an output function, \n\n\n\n\n{\ny\n}\n\n\n\n{\\displaystyle \\textstyle \\{y\\}}\n\n. And in general, every value of the output can depend on every value of the input. This concept is represented by:\nwhere \n\n\n\n\n\nO\n\nt\n\n\n\n\n\n{\\displaystyle \\textstyle O_{t}}\n\n is the transformation operator for time \n\n\n\n\nt\n\n\n\n{\\displaystyle \\textstyle t}\n\n. In a typical system, \n\n\n\n\ny\n(\nt\n)\n\n\n\n{\\displaystyle \\textstyle y(t)}\n\n depends most heavily on the values of \n\n\n\n\nx\n\n\n\n{\\displaystyle \\textstyle x}\n\n that occurred near time \n\n\n\n\nt\n.\n\n\n\n{\\displaystyle \\textstyle t.}\n\n\u00a0 Unless the transform itself changes with \n\n\n\n\nt\n,\n\n\n\n{\\displaystyle \\textstyle t,}\n\n the output function is just constant, and the system is uninteresting.\nFor a linear system, \n\n\n\n\nO\n\n\n\n{\\displaystyle \\textstyle O}\n\n must satisfy Eq.1 :\n\n\n\n\n\nO\n\nt\n\n\n\n{\n\n\u222b\n\n\u2212\n\u221e\n\n\n\u221e\n\n\n\nc\n\n\u03c4\n\n\n\u00a0\n\nx\n\n\u03c4\n\n\n(\nu\n)\n\n\nd\n\n\u03c4\n;\n\u00a0\nu\n}\n\n=\n\n\u222b\n\n\u2212\n\u221e\n\n\n\u221e\n\n\n\nc\n\n\u03c4\n\n\n\u00a0\n\n\n\n\n\ny\n\n\u03c4\n\n\n(\nt\n)\n\n\u23df\n\n\n\n\nO\n\nt\n\n\n{\n\nx\n\n\u03c4\n\n\n}\n\n\n\n\nd\n\n\u03c4\n.\n\n\n\n{\\displaystyle O_{t}\\left\\{\\int \\limits _{-\\infty }^{\\infty }c_{\\tau }\\ x_{\\tau }(u)\\,\\mathrm {d} \\tau ;\\ u\\right\\}=\\int \\limits _{-\\infty }^{\\infty }c_{\\tau }\\ \\underbrace {y_{\\tau }(t)} _{O_{t}\\{x_{\\tau }\\}}\\,\\mathrm {d} \\tau .\\,}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(Eq.2)\nAnd the time-invariance requirement is:\n\n\n\n\n\n\n\n\n\nO\n\nt\n\n\n{\nx\n(\nu\n\u2212\n\u03c4\n)\n;\n\u00a0\nu\n}\n\u00a0\n\n\n\n\n\n\n\n=\n\n\n\n\n\n\n\n\u00a0\ny\n(\nt\n\u2212\n\u03c4\n)\n\n\n\n\n\n\n\n\n\n\n=\n\n\ndef\n\n\n\n\n\u00a0\n\nO\n\nt\n\u2212\n\u03c4\n\n\n{\nx\n}\n.\n\n\n\n\n\n\n\n{\\displaystyle {\\begin{aligned}O_{t}\\{x(u-\\tau );\\ u\\}\\ &{\\stackrel {\\quad }{=}}\\ y(t-\\tau )\\\\&{\\stackrel {\\text{def}}{=}}\\ O_{t-\\tau }\\{x\\}.\\,\\end{aligned}}}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(Eq.3)\nIn this notation, we can write the impulse response as \u00a0\n\n\n\n\nh\n(\nt\n)\n\u00a0\n\n\n\n\n=\n\n\ndef\n\n\n\n\n\u00a0\n\nO\n\nt\n\n\n{\n\u03b4\n(\nu\n)\n;\n\u00a0\nu\n}\n.\n\n\n\n{\\displaystyle \\textstyle h(t)\\ {\\stackrel {\\text{def}}{=}}\\ O_{t}\\{\\delta (u);\\ u\\}.}\n\n\nSimilarly:\nSubstituting this result into the convolution integral:\nwhich has the form of the right side of Eq.2 for the case \n\n\n\n\n\nc\n\n\u03c4\n\n\n=\nx\n(\n\u03c4\n)\n\n\n\n{\\displaystyle \\textstyle c_{\\tau }=x(\\tau )}\n\n and \n\n\n\n\n\nx\n\n\u03c4\n\n\n(\nu\n)\n=\n\u03b4\n(\nu\n\u2212\n\u03c4\n)\n.\n\n\n\n{\\displaystyle \\textstyle x_{\\tau }(u)=\\delta (u-\\tau ).}\n\n\nEq.2 then allows this continuation:\nIn summary, the input function, \n\n\n\n\n{\nx\n}\n,\n\n\n\n{\\displaystyle \\textstyle \\{x\\},}\n\n\u00a0 can be represented by a continuum of time-shifted impulse functions, combined \"linearly\", as shown at Eq.1. The system's linearity property allows the system's response to be represented by the corresponding continuum of impulse responses, combined in the same way. \u00a0And the time-invariance property allows that combination to be represented by the convolution integral.\nThe mathematical operations above have a simple graphical simulation.[3]\nAn eigenfunction is a function for which the output of the operator is a scaled version of the same function. That is,\nwhere f is the eigenfunction and \n\n\n\n\u03bb\n\n\n{\\displaystyle \\lambda }\n\n is the eigenvalue, a constant.\nThe exponential functions \n\n\n\nA\n\ne\n\ns\nt\n\n\n\n\n{\\displaystyle Ae^{st}}\n\n, where \n\n\n\nA\n,\ns\n\u2208\n\nC\n\n\n\n{\\displaystyle A,s\\in \\mathbb {C} }\n\n, are eigenfunctions of a linear, time-invariant operator. A simple proof illustrates this concept. Suppose the input is \n\n\n\nx\n(\nt\n)\n=\nA\n\ne\n\ns\nt\n\n\n\n\n{\\displaystyle x(t)=Ae^{st}}\n\n. The output of the system with impulse response \n\n\n\nh\n(\nt\n)\n\n\n{\\displaystyle h(t)}\n\n is then\nwhich, by the commutative property of convolution, is equivalent to\nwhere the scalar\nis dependent only on the parameter s.\nSo the system's response is a scaled version of the input. In particular, for any \n\n\n\nA\n,\ns\n\u2208\n\nC\n\n\n\n{\\displaystyle A,s\\in \\mathbb {C} }\n\n, the system output is the product of the input \n\n\n\nA\n\ne\n\ns\nt\n\n\n\n\n{\\displaystyle Ae^{st}}\n\n and the constant \n\n\n\nH\n(\ns\n)\n\n\n{\\displaystyle H(s)}\n\n. Hence, \n\n\n\nA\n\ne\n\ns\nt\n\n\n\n\n{\\displaystyle Ae^{st}}\n\n is an eigenfunction of an LTI system, and the corresponding eigenvalue is \n\n\n\nH\n(\ns\n)\n\n\n{\\displaystyle H(s)}\n\n.\nIt is also possible to directly derive complex exponentials as eigenfunctions of LTI systems.\nLet's set \n\n\n\nv\n(\nt\n)\n=\n\ne\n\ni\n\u03c9\nt\n\n\n\n\n{\\displaystyle v(t)=e^{i\\omega t}}\n\n some complex exponential and \n\n\n\n\nv\n\na\n\n\n(\nt\n)\n=\n\ne\n\ni\n\u03c9\n(\nt\n+\na\n)\n\n\n\n\n{\\displaystyle v_{a}(t)=e^{i\\omega (t+a)}}\n\n a time-shifted version of it.\n\n\n\n\nH\n[\n\nv\n\na\n\n\n]\n(\nt\n)\n=\n\ne\n\ni\n\u03c9\na\n\n\nH\n[\nv\n]\n(\nt\n)\n\n\n{\\displaystyle H[v_{a}](t)=e^{i\\omega a}H[v](t)}\n\n by linearity with respect to the constant \n\n\n\n\ne\n\ni\n\u03c9\na\n\n\n\n\n{\\displaystyle e^{i\\omega a}}\n\n .\n\n\n\n\nH\n[\n\nv\n\na\n\n\n]\n(\nt\n)\n=\nH\n[\nv\n]\n(\nt\n+\na\n)\n\n\n{\\displaystyle H[v_{a}](t)=H[v](t+a)}\n\n by time invariance of \n\n\n\nH\n\n\n{\\displaystyle H}\n\n .\nSo \n\n\n\nH\n[\nv\n]\n(\nt\n+\na\n)\n=\n\ne\n\ni\n\u03c9\na\n\n\nH\n[\nv\n]\n(\nt\n)\n\n\n{\\displaystyle H[v](t+a)=e^{i\\omega a}H[v](t)}\n\n. Setting \n\n\n\nt\n=\n0\n\n\n{\\displaystyle t=0}\n\n and renaming we get\u00a0:\ni.e. that a complex exponential \n\n\n\n\ne\n\ni\n\u03c9\n\u03c4\n\n\n\n\n{\\displaystyle e^{i\\omega \\tau }}\n\n as input will give a complex exponential of same frequency as output.\nThe eigenfunction property of exponentials is very useful for both analysis and insight into LTI systems. The Laplace transform\nis exactly the way to get the eigenvalues from the impulse response. Of particular interest are pure sinusoids (i.e., exponential functions of the form \n\n\n\n\ne\n\nj\n\u03c9\nt\n\n\n\n\n{\\displaystyle e^{j\\omega t}}\n\n where \n\n\n\n\u03c9\n\u2208\n\nR\n\n\n\n{\\displaystyle \\omega \\in \\mathbb {R} }\n\n and \n\n\n\nj\n\u00a0\n\n\n\n\n=\n\n\ndef\n\n\n\n\n\u00a0\n\n\n\u2212\n1\n\n\n\n\n{\\displaystyle j\\ {\\stackrel {\\text{def}}{=}}\\ {\\sqrt {-1}}}\n\n). These are generally called complex exponentials even though the argument is purely imaginary. The Fourier transform \n\n\n\nH\n(\nj\n\u03c9\n)\n=\n\n\nF\n\n\n{\nh\n(\nt\n)\n}\n\n\n{\\displaystyle H(j\\omega )={\\mathcal {F}}\\{h(t)\\}}\n\n gives the eigenvalues for pure complex sinusoids. Both of \n\n\n\nH\n(\ns\n)\n\n\n{\\displaystyle H(s)}\n\n and \n\n\n\nH\n(\nj\n\u03c9\n)\n\n\n{\\displaystyle H(j\\omega )}\n\n are called the system function, system response, or transfer function.\nThe Laplace transform is usually used in the context of one-sided signals, i.e. signals that are zero for all values of t less than some value. Usually, this \"start time\" is set to zero, for convenience and without loss of generality, with the transform integral being taken from zero to infinity (the transform shown above with lower limit of integration of negative infinity is formally known as the bilateral Laplace transform).\nThe Fourier transform is used for analyzing systems that process signals that are infinite in extent, such as modulated sinusoids, even though it cannot be directly applied to input and output signals that are not square integrable. The Laplace transform actually works directly for these signals if they are zero before a start time, even if they are not square integrable, for stable systems. The Fourier transform is often applied to spectra of infinite signals via the Wiener\u2013Khinchin theorem even when Fourier transforms of the signals do not exist.\nDue to the convolution property of both of these transforms, the convolution that gives the output of the system can be transformed to a multiplication in the transform domain, given signals for which the transforms exist\nNot only is it often easier to do the transforms, multiplication, and inverse transform than the original convolution, but one can also gain insight into the behavior of the system from the system response. One can look at the modulus of the system function |H(s)| to see whether the input \n\n\n\nexp\n\u2061\n(\n\ns\nt\n\n)\n\n\n{\\displaystyle \\exp({st})}\n\n is passed (let through) the system or rejected or attenuated by the system (not let through).\nSome of the most important properties of a system are causality and stability. Causality is a necessity if the independent variable is time, but not all systems have time as an independent variable. For example, a system that processes still images does not need to be causal. Non-causal systems can be built and can be useful in many circumstances. Even non-real systems can be built and are very useful in many contexts.\nA system is causal if the output depends only on present and past, but not future inputs. A necessary and sufficient condition for causality is\nwhere \n\n\n\nh\n(\nt\n)\n\n\n{\\displaystyle h(t)}\n\n is the impulse response. It is not possible in general to determine causality from the Laplace transform, because the inverse transform is not unique. When a region of convergence is specified, then causality can be determined.\nA system is bounded-input, bounded-output stable (BIBO stable) if, for every bounded input, the output is finite. Mathematically, if every input satisfying\nleads to an output satisfying\n(that is, a finite maximum absolute value of \n\n\n\nx\n(\nt\n)\n\n\n{\\displaystyle x(t)}\n\n implies a finite maximum absolute value of \n\n\n\ny\n(\nt\n)\n\n\n{\\displaystyle y(t)}\n\n), then the system is stable. A necessary and sufficient condition is that \n\n\n\nh\n(\nt\n)\n\n\n{\\displaystyle h(t)}\n\n, the impulse response, is in L1 (has a finite L1 norm):\nIn the frequency domain, the region of convergence must contain the imaginary axis \n\n\n\ns\n=\nj\n\u03c9\n\n\n{\\displaystyle s=j\\omega }\n\n.\nAs an example, the ideal low-pass filter with impulse response equal to a sinc function is not BIBO stable, because the sinc function does not have a finite L1 norm. Thus, for some bounded input, the output of the ideal low-pass filter is unbounded. In particular, if the input is zero for \n\n\n\nt\n<\n0\n\n\n\n{\\displaystyle t<0\\,}\n\n and equal to a sinusoid at the cut-off frequency for \n\n\n\nt\n>\n0\n\n\n\n{\\displaystyle t>0\\,}\n\n, then the output will be unbounded for all times other than the zero crossings.\nAlmost everything in continuous-time systems has a counterpart in discrete-time systems.\nIn many contexts, a discrete time (DT) system is really part of a larger continuous time (CT) system. For example, a digital recording system takes an analog sound, digitizes it, possibly processes the digital signals, and plays back an analog sound for people to listen to.\nFormally, the DT signals studied are almost always uniformly sampled versions of CT signals. If \n\n\n\nx\n(\nt\n)\n\n\n{\\displaystyle x(t)}\n\n is a CT signal, then an analog to digital converter will transform it to the DT signal:\nwhere T is the sampling period. It is very important to limit the range of frequencies in the input signal for faithful representation in the DT signal, since then the sampling theorem guarantees that no information about the CT signal is lost. A DT signal can only contain a frequency range of \n\n\n\n1\n\n/\n\n(\n2\nT\n)\n\n\n{\\displaystyle 1/(2T)}\n\n; other frequencies are aliased to the same range.\nLet \n\n\n\n{\nx\n[\nm\n\u2212\nk\n]\n;\n\u00a0\nm\n}\n\n\n{\\displaystyle \\{x[m-k];\\ m\\}}\n\n represent the sequence \n\n\n\n{\nx\n[\nm\n\u2212\nk\n]\n;\n\u00a0\n\nfor all integer values of m\n\n}\n\n\n{\\displaystyle \\{x[m-k];\\ {\\mbox{for all integer values of m}}\\}}\n\n.\nAnd let the shorter notation \n\n\n\n{\nx\n}\n\n\n\n{\\displaystyle \\{x\\}\\,}\n\n represent \n\n\n\n{\nx\n[\nm\n]\n;\n\u00a0\nm\n}\n.\n\n\n{\\displaystyle \\{x[m];\\ m\\}.}\n\n\nA discrete system transforms an input sequence, \n\n\n\n{\nx\n}\n\n\n{\\displaystyle \\{x\\}}\n\n into an output sequence, \n\n\n\n{\ny\n}\n.\n\n\n{\\displaystyle \\{y\\}.}\n\n In general, every element of the output can depend on every element of the input. Representing the transformation operator by \n\n\n\nO\n\n\n{\\displaystyle O}\n\n, we can write:\nNote that unless the transform itself changes with n, the output sequence is just constant, and the system is uninteresting. (Thus the subscript, n.) In a typical system, y[n] depends most heavily on the elements of x whose indices are near n.\nFor the special case of the Kronecker delta function, \n\n\n\nx\n[\nm\n]\n=\n\u03b4\n[\nm\n]\n,\n\n\n{\\displaystyle x[m]=\\delta [m],}\n\n the output sequence is the impulse response:\nFor a linear system, \n\n\n\nO\n\n\n{\\displaystyle O}\n\n must satisfy:\n\n\n\n\n\nO\n\nn\n\n\n\n{\n\n\u2211\n\nk\n=\n\u2212\n\u221e\n\n\n\u221e\n\n\n\nc\n\nk\n\n\n\u22c5\n\nx\n\nk\n\n\n[\nm\n]\n;\n\u00a0\nm\n}\n\n=\n\n\u2211\n\nk\n=\n\u2212\n\u221e\n\n\n\u221e\n\n\n\nc\n\nk\n\n\n\u22c5\n\nO\n\nn\n\n\n{\n\nx\n\nk\n\n\n}\n.\n\n\n\n{\\displaystyle O_{n}\\left\\{\\sum _{k=-\\infty }^{\\infty }c_{k}\\cdot x_{k}[m];\\ m\\right\\}=\\sum _{k=-\\infty }^{\\infty }c_{k}\\cdot O_{n}\\{x_{k}\\}.\\,}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(Eq.4)\nAnd the time-invariance requirement is:\n\n\n\n\n\n\n\n\n\nO\n\nn\n\n\n{\nx\n[\nm\n\u2212\nk\n]\n;\n\u00a0\nm\n}\n\u00a0\n\n\n\n\n\n\n\n=\n\n\n\n\n\n\n\n\u00a0\ny\n[\nn\n\u2212\nk\n]\n\n\n\n\n\n\n\n\n\n\n=\n\n\ndef\n\n\n\n\n\u00a0\n\nO\n\nn\n\u2212\nk\n\n\n{\nx\n}\n.\n\n\n\n\n\n\n\n{\\displaystyle {\\begin{aligned}O_{n}\\{x[m-k];\\ m\\}\\ &{\\stackrel {\\quad }{=}}\\ y[n-k]\\\\&{\\stackrel {\\text{def}}{=}}\\ O_{n-k}\\{x\\}.\\,\\end{aligned}}}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(Eq.5)\nIn such a system, the impulse response, \n\n\n\n{\nh\n}\n,\n\n\n\n{\\displaystyle \\{h\\},\\,}\n\n characterizes the system completely. I.e., for any input sequence, the output sequence can be calculated in terms of the input and the impulse response. To see how that is done, consider the identity:\nwhich expresses \n\n\n\n{\nx\n}\n\n\n\n{\\displaystyle \\{x\\}\\,}\n\n in terms of a sum of weighted delta functions.\nTherefore:\nwhere we have invoked Eq.4 for the case \n\n\n\n\nc\n\nk\n\n\n=\nx\n[\nk\n]\n\n\n\n{\\displaystyle c_{k}=x[k]\\,}\n\n and \n\n\n\n\nx\n\nk\n\n\n[\nm\n]\n=\n\u03b4\n[\nm\n\u2212\nk\n]\n.\n\n\n\n{\\displaystyle x_{k}[m]=\\delta [m-k].\\,}\n\n\nAnd because of Eq.5, we may write:\nTherefore:\nwhich is the familiar discrete convolution formula. The operator \n\n\n\n\nO\n\nn\n\n\n\n\n\n{\\displaystyle O_{n}\\,}\n\n can therefore be interpreted as proportional to a weighted average of the function x[k]. The weighting function is h[-k], simply shifted by amount n. As n changes, the weighting function emphasizes different parts of the input function. Equivalently, the system's response to an impulse at n=0 is a \"time\" reversed copy of the unshifted weighting function. When h[k] is zero for all negative k, the system is said to be causal.\nAn eigenfunction is a function for which the output of the operator is the same function, scaled by some constant. In symbols,\nwhere f is the eigenfunction and \n\n\n\n\u03bb\n\n\n{\\displaystyle \\lambda }\n\n is the eigenvalue, a constant.\nThe exponential functions \n\n\n\n\nz\n\nn\n\n\n=\n\ne\n\ns\nT\nn\n\n\n\n\n{\\displaystyle z^{n}=e^{sTn}}\n\n, where \n\n\n\nn\n\u2208\n\nZ\n\n\n\n{\\displaystyle n\\in \\mathbb {Z} }\n\n, are eigenfunctions of a linear, time-invariant operator. \n\n\n\nT\n\u2208\n\nR\n\n\n\n{\\displaystyle T\\in \\mathbb {R} }\n\n is the sampling interval, and \n\n\n\nz\n=\n\ne\n\ns\nT\n\n\n,\n\u00a0\nz\n,\ns\n\u2208\n\nC\n\n\n\n{\\displaystyle z=e^{sT},\\ z,s\\in \\mathbb {C} }\n\n. A simple proof illustrates this concept.\nSuppose the input is \n\n\n\nx\n[\nn\n]\n=\n\n\n\nz\n\nn\n\n\n\n\n{\\displaystyle x[n]=\\,\\!z^{n}}\n\n. The output of the system with impulse response \n\n\n\nh\n[\nn\n]\n\n\n{\\displaystyle h[n]}\n\n is then\nwhich is equivalent to the following by the commutative property of convolution\nwhere\nis dependent only on the parameter z.\nSo \n\n\n\n\nz\n\nn\n\n\n\n\n{\\displaystyle z^{n}}\n\n is an eigenfunction of an LTI system because the system response is the same as the input times the constant \n\n\n\nH\n(\nz\n)\n\n\n{\\displaystyle H(z)}\n\n.\nThe eigenfunction property of exponentials is very useful for both analysis and insight into LTI systems. The Z transform\nis exactly the way to get the eigenvalues from the impulse response. Of particular interest are pure sinusoids, i.e. exponentials of the form \n\n\n\n\ne\n\nj\n\u03c9\nn\n\n\n\n\n{\\displaystyle e^{j\\omega n}}\n\n, where \n\n\n\n\u03c9\n\u2208\n\nR\n\n\n\n{\\displaystyle \\omega \\in \\mathbb {R} }\n\n. These can also be written as \n\n\n\n\nz\n\nn\n\n\n\n\n{\\displaystyle z^{n}}\n\n with \n\n\n\nz\n=\n\ne\n\nj\n\u03c9\n\n\n\n\n{\\displaystyle z=e^{j\\omega }}\n\n. These are generally called complex exponentials even though the argument is purely imaginary. The Discrete-time Fourier transform (DTFT) \n\n\n\nH\n(\n\ne\n\nj\n\u03c9\n\n\n)\n=\n\n\nF\n\n\n{\nh\n[\nn\n]\n}\n\n\n{\\displaystyle H(e^{j\\omega })={\\mathcal {F}}\\{h[n]\\}}\n\n gives the eigenvalues of pure sinusoids. Both of \n\n\n\nH\n(\nz\n)\n\n\n{\\displaystyle H(z)}\n\n and \n\n\n\nH\n(\n\ne\n\nj\n\u03c9\n\n\n)\n\n\n{\\displaystyle H(e^{j\\omega })}\n\n are called the system function, system response, or transfer function'.\nThe Z transform is usually used in the context of one-sided signals, i.e. signals that are zero for all values of t less than some value. Usually, this \"start time\" is set to zero, for convenience and without loss of generality. The Fourier transform is used for analyzing signals that are infinite in extent.\nDue to the convolution property of both of these transforms, the convolution that gives the output of the system can be transformed to a multiplication in the transform domain. That is,\nJust as with the Laplace transform transfer function in continuous-time system analysis, the Z transform makes it easier to analyze systems and gain insight into their behavior. One can look at the modulus of the system function |H(z)| to see whether the input \n\n\n\n\nz\n\nn\n\n\n\n\n{\\displaystyle z^{n}}\n\n is passed (let through) by the system, or rejected or attenuated by the system (not let through).\nThe input-output characteristics of discrete-time LTI system are completely described by its impulse response \n\n\n\nh\n[\nn\n]\n\n\n{\\displaystyle h[n]}\n\n. Some of the most important properties of a system are causality and stability. Unlike CT systems, non-causal DT systems can be realized. It is trivial to make an acausal FIR system causal by adding delays. It is even possible to make acausal IIR systems.[4] Non-stable systems can be built and can be useful in many circumstances. Even non-real systems can be built and are very useful in many contexts.\nA discrete-time LTI system is causal if the current value of the output depends on only the current value and past values of the input.,[5] A necessary and sufficient condition for causality is\nwhere \n\n\n\nh\n[\nn\n]\n\n\n{\\displaystyle h[n]}\n\n is the impulse response. It is not possible in general to determine causality from the Z transform, because the inverse transform is not unique. When a region of convergence is specified, then causality can be determined.\nA system is bounded input, bounded output stable (BIBO stable) if, for every bounded input, the output is finite. Mathematically, if\nimplies that\n(that is, if bounded input implies bounded output, in the sense that the maximum absolute values of \n\n\n\nx\n[\nn\n]\n\n\n{\\displaystyle x[n]}\n\n and \n\n\n\ny\n[\nn\n]\n\n\n{\\displaystyle y[n]}\n\n are finite), then the system is stable. A necessary and sufficient condition is that \n\n\n\nh\n[\nn\n]\n\n\n{\\displaystyle h[n]}\n\n, the impulse response, satisfies\nIn the frequency domain, the region of convergence must contain the unit circle (i.e., the locus satisfying \n\n\n\n\n|\n\nz\n\n|\n\n=\n1\n\n\n{\\displaystyle |z|=1}\n\n for complex z).", 
    "dbpedia_url": "http://dbpedia.org/resource/LTI_system_theory", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/LTI_system_theory\n"
}