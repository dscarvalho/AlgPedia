{
    "about": "Loss of significance is an undesirable effect in calculations using finite-precision arithmetic. It occurs when an operation on two numbers increases relative error substantially more than it increases absolute error, for example in subtracting two nearly equal numbers (known as catastrophic cancellation). The effect is that the number of significant digits in the result is reduced unacceptably. Ways to avoid this effect are studied in numerical analysis.", 
    "name": "Loss Of Significance", 
    "classification": "Numerical Analysis", 
    "full_text": "Loss of significance is an undesirable effect in calculations using finite-precision arithmetic. It occurs when an operation on two numbers increases relative error substantially more than it increases absolute error, for example in subtracting two nearly equal numbers (known as catastrophic cancellation). The effect is that the number of significant digits in the result is reduced unacceptably. Ways to avoid this effect are studied in numerical analysis.\n\n\nThe effect can be demonstrated with decimal numbers. The following example demonstrates loss of significance for a decimal floating-point data type with 10 significant digits:\nConsider the decimal number\nA floating-point representation of this number on a machine that keeps 10 floating-point digits would be\nwhich is fairly close when measuring the error as a percentage of the value. It is very different when measured in order of precision. The first is accurate to 6981099999999999999\u266010\u00d710\u221220, while the second is only accurate to 6991100000000000000\u266010\u00d710\u221210.\nNow perform the calculation\nThe answer, accurate to 10 significant digits, is\nHowever, on the 10-digit floating-point machine, the calculation yields\nIn both cases the result is accurate to same order of magnitude as the inputs (-20 and -10, respectively). In the second case, the answer seems to have one significant digit, which would amount to loss of significance. However, in computer floating point arithmetic, all operations can be viewed as being performed on antilogarithms, for which the rules for significant figures indicate that the number of sigfigs remains the same as the smallest number of sigfigs in the mantissas. The way to indicate this and represent the answer to 10 sigfigs is:\nIt is possible to do computations using an exact fractional representation of rational numbers and keep all significant digits, but this is often prohibitively slower than floating-point arithmetic. Furthermore, it usually only postpones the problem: What if the data is accurate to only ten digits? The same effect will occur.\nOne of the most important parts of numerical analysis is to avoid or minimize loss of significance in calculations. If the underlying problem is well-posed, there should be a stable algorithm for solving it.\nLet x and y be positive normalized floating point numbers.\nIn the subtraction x \u2212 y, r significant bits are lost where\nfor some positive integers p and q.\nFor example, consider the quadratic equation:\nwith the two exact solutions:\nThis formula may not always produce an accurate result. For example, when \n\n\n\nc\n\n\n{\\displaystyle c}\n\n is very small, loss of significance can occur in either of the root calculations, depending on the sign of \n\n\n\nb\n\n\n{\\displaystyle b}\n\n.\nThe case \n\n\n\na\n=\n1\n\n\n{\\displaystyle a=1}\n\n, \n\n\n\nb\n=\n200\n\n\n{\\displaystyle b=200}\n\n, \n\n\n\nc\n=\n\u2212\n0.000015\n\n\n{\\displaystyle c=-0.000015}\n\n will serve to illustrate the problem:\nWe have\nIn real arithmetic, the roots are\nIn 10-digit floating-point arithmetic,\nNotice that the solution of greater magnitude is accurate to ten digits, but the first nonzero digit of the solution of lesser magnitude is wrong.\nBecause of the subtraction that occurs in the quadratic equation, it does not constitute a stable algorithm to calculate the two roots.\nA careful floating point computer implementation combines several strategies to produce a robust result. Assuming the discriminant, b2 \u2212 4ac, is positive and b is nonzero, the computation would be as follows:[1]\nHere sgn denotes the sign function, where \n\n\n\nsgn\n\u2061\n(\nb\n)\n\n\n{\\displaystyle \\operatorname {sgn}(b)}\n\n is 1 if \n\n\n\nb\n\n\n{\\displaystyle b}\n\n is positive and \u22121 if \n\n\n\nb\n\n\n{\\displaystyle b}\n\n is negative. This avoids cancellation problems between \n\n\n\nb\n\n\n{\\displaystyle b}\n\n and the square root of the discriminant by ensuring that only numbers of the same sign are added.\nTo illustrate the instability of the standard quadratic formula versus this variant formula, consider a quadratic equation with roots \n\n\n\n1.786737589984535\n\n\n{\\displaystyle 1.786737589984535}\n\n and \n\n\n\n1.149782767465722\n\u00d7\n\n10\n\n\u2212\n8\n\n\n\n\n{\\displaystyle 1.149782767465722\\times 10^{-8}}\n\n. To sixteen significant figures, roughly corresponding to double-precision accuracy on a computer, the monic quadratic equation with these roots may be written as:\nUsing the standard quadratic formula and maintaining sixteen significant figures at each step, the standard quadratic formula yields\nNote how cancellation has resulted in \n\n\n\n\nx\n\n2\n\n\n\n\n{\\displaystyle x_{2}}\n\n being computed to only eight significant digits of accuracy. The variant formula presented here, however, yields the following:\nNote the retention of all significant digits for \n\n\n\n\nx\n\n2\n\n\n\n\n{\\displaystyle x_{2}}\n\n.\nNote that while the above formulation avoids catastrophic cancellation between \n\n\n\nb\n\n\n{\\displaystyle b}\n\n and \n\n\n\n\n\n\nb\n\n2\n\n\n\u2212\n4\na\nc\n\n\n\n\n{\\displaystyle {\\sqrt {b^{2}-4ac}}}\n\n, there remains a form of cancellation between the terms \n\n\n\n\nb\n\n2\n\n\n\n\n{\\displaystyle b^{2}}\n\n and \n\n\n\n\u2212\n4\na\nc\n\n\n{\\displaystyle -4ac}\n\n of the discriminant, which can still lead to loss of up to half of correct significant figures.[2][3] The discriminant \n\n\n\n\nb\n\n2\n\n\n\u2212\n4\na\nc\n\n\n{\\displaystyle b^{2}-4ac}\n\n needs to be computed in arithmetic of twice the precision of the result to avoid this (e.g. quad precision if the final result is to be accurate to full double precision).[4] This can be in the form of a fused multiply-add operation.[2]\nTo illustrate this, consider the following quadratic equation, adapted from Kahan (2004):[2]\nThis equation has \n\n\n\n\u0394\n=\n7.5625\n\n\n{\\displaystyle \\Delta =7.5625}\n\n and has roots\nHowever, when computed using IEEE 754 double-precision arithmetic corresponding to 15 to 17 significant digits of accuracy, \n\n\n\n\u0394\n\n\n{\\displaystyle \\Delta }\n\n is rounded to 0.0, and the computed roots are\nwhich are both false after the eighth significant digit. This is despite the fact that superficially, the problem seems to require only eleven significant digits of accuracy for its solution.", 
    "dbpedia_url": "http://dbpedia.org/resource/Loss_of_significance", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Loss_of_significance\n"
}