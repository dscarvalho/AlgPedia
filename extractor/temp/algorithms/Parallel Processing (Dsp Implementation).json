{
    "about": "In digital signal processing (DSP), parallel processing is a technique duplicating function units to operate different tasks (signals) simultaneously.[1] Accordingly, we can perform the same processing for different signals on the corresponding duplicated function units. Further, due to the features of parallel processing, the parallel DSP design often contains multiple outputs, resulting in higher throughput than not parallel.", 
    "name": "Parallel Processing (Dsp Implementation)", 
    "classification": "Digital Signal Processing", 
    "full_text": "In digital signal processing (DSP), parallel processing is a technique duplicating function units to operate different tasks (signals) simultaneously.[1] Accordingly, we can perform the same processing for different signals on the corresponding duplicated function units. Further, due to the features of parallel processing, the parallel DSP design often contains multiple outputs, resulting in higher throughput than not parallel.\n\n\nConsider a function unit (F0) and three tasks (T0, T1 and T2). The required time for the function unit F0 to process those tasks is t0,t1 and t2 respectively. Then, if we operate these three tasks in a sequential order, the required time to complete them is t0\u00a0+\u00a0t1\u00a0+\u00a0t2.\n\nHowever, if we duplicate the function unit to another two copies (F), the aggregate time is reduced to max(t0,t1,t2), which is smaller than in a sequential order.\n\nMechanism:\nObjective:\nConsider a condition that we are able to apply both parallel processing and pipelining techniques, it is better to choose parallel processing techniques with the following reasons\nConsider a 3-tap FIR filter:[2]\nwhich is shown in the following figure.\nAssume the calculation time for multiplication units is Tm and Ta for add units. The sample period is given by\nBy parallelizing it, the resultant architecture is shown as follows. The sample rate now becomes\nwhere N represents the number of copies.\nPlease note that, in a parallel system, \n\n\n\n\nT\n\nsample\n\n\n\u2260\n\nT\n\nclock\n\n\n\n\n{\\displaystyle T_{\\text{sample}}\\neq T_{\\text{clock}}}\n\n while \n\n\n\n\nT\n\nsample\n\n\n=\n\nT\n\nclock\n\n\n\n\n{\\displaystyle T_{\\text{sample}}=T_{\\text{clock}}}\n\n holds in a pipelined system.\nConsider the transfer function of a 1st-order IIR filter formulated as\nwhere |a| \u2264 1 for stability, and such filter has only one pole located at z\u00a0=\u00a0a;\nThe corresponding recursive representation is\nConsider the design of a 4-parallel architecture (N\u00a0=\u00a04). In such parallel system, each delay element means a block delay and the clock period is four times the sample period.\nTherefore, by iterating the recursion with n\u00a0=\u00a04k, we have\nThe corresponding architecture is shown as follows.\nThe resultant parallel design has the following properties.\nThe square increase in hardware complexity can be reduced by exploiting the concurrency and the incremental computation to avoid repeated computing.\nAnother advantage for the parallel processing techniques is that it can reduce the power consumption of a system by reducing the supply voltage.\nConsider the following power consumption in a normal CMOS circuit.\nwhere the Ctotal represents the total capacitance of the CMOS circuit.\nFor a parallel version, the charging capacitance remains the same but the total capacitance increases by N times.\nIn order to maintain the same sample rate, the clock period of the N-parallel circuit increases to N times the propagation delay of the original circuit.\nIt makes the charging time prolongs N times. The supply voltage can be reduced to \u03b2V0.\nTherefore, the power consumption of the N-parallel system can be formulated as\nwhere \u03b2 can be computed by", 
    "dbpedia_url": "http://dbpedia.org/resource/Parallel_processing_(DSP_implementation)", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Parallel_processing_(DSP_implementation)\n"
}