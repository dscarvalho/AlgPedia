{
    "about": "In the theory of stochastic processes, the filtering problem is a mathematical model for a number of state estimation problems in signal processing and related fields. The general idea is to establish a \"best estimate\" for the true value of some system from an incomplete, potentially noisy set of observations on that system. The problem of optimal non-linear filtering (even for the non-stationary case) was solved by Ruslan L. Stratonovich (1959,[1] 1960[2]), see also Harold J. Kushner's work [3] and Moshe Zakai's, who introduced a simplified dynamics for the unnormalized conditional law of the filter[4] known as Zakai equation. The solution, however, is infinite-dimensional in the general case.[5] Certain approximations and special cases are well-understood: for example, the linear filters are optimal for Gaussian random variables, and are known as the Wiener filter and the Kalman-Bucy filter. More generally, as the solution is infinite dimensional, it requires finite dimensional approximations to be implemented in a computer with finite memory. A finite dimensional approximated nonlinear filter may be more based on heuristics, such as the Extended Kalman Filter or the Assumed Density Filters,[6] or more methodologically oriented such as for example the Projection Filters,[7] some sub-families of which are shown to coincide with the Assumed Density Filters.[8]", 
    "name": "Filtering Problem (Stochastic Processes)", 
    "classification": "Signal Processing", 
    "full_text": "In the theory of stochastic processes, the filtering problem is a mathematical model for a number of state estimation problems in signal processing and related fields. The general idea is to establish a \"best estimate\" for the true value of some system from an incomplete, potentially noisy set of observations on that system. The problem of optimal non-linear filtering (even for the non-stationary case) was solved by Ruslan L. Stratonovich (1959,[1] 1960[2]), see also Harold J. Kushner's work [3] and Moshe Zakai's, who introduced a simplified dynamics for the unnormalized conditional law of the filter[4] known as Zakai equation. The solution, however, is infinite-dimensional in the general case.[5] Certain approximations and special cases are well-understood: for example, the linear filters are optimal for Gaussian random variables, and are known as the Wiener filter and the Kalman-Bucy filter. More generally, as the solution is infinite dimensional, it requires finite dimensional approximations to be implemented in a computer with finite memory. A finite dimensional approximated nonlinear filter may be more based on heuristics, such as the Extended Kalman Filter or the Assumed Density Filters,[6] or more methodologically oriented such as for example the Projection Filters,[7] some sub-families of which are shown to coincide with the Assumed Density Filters.[8]\nIn general, if the separation principle applies, then filtering also arises as part of the solution of an optimal control problem. For example, the Kalman filter is the estimation part of the optimal control solution to the Linear-quadratic-Gaussian control problem.\nConsider a probability space (\u03a9,\u00a0\u03a3,\u00a0P) and suppose that the (random) state Yt in n-dimensional Euclidean space Rn of a system of interest at time t is a random variable Yt\u00a0:\u00a0\u03a9\u00a0\u2192\u00a0Rn given by the solution to an It\u014d stochastic differential equation of the form\nwhere B denotes standard p-dimensional Brownian motion, b\u00a0:\u00a0[0,\u00a0+\u221e)\u00a0\u00d7\u00a0Rn\u00a0\u2192\u00a0Rn is the drift field, and \u03c3\u00a0:\u00a0[0,\u00a0+\u221e)\u00a0\u00d7\u00a0Rn\u00a0\u2192\u00a0Rn\u00d7p is the diffusion field. It is assumed that observations Ht in Rm (note that m and n may, in general, be unequal) are taken for each time t according to\nAdopting the It\u014d interpretation of the stochastic differential and setting\nthis gives the following stochastic integral representation for the observations Zt:\nwhere W denotes standard r-dimensional Brownian motion, independent of B and the initial condition X0, and c\u00a0:\u00a0[0,\u00a0+\u221e)\u00a0\u00d7\u00a0Rn\u00a0\u2192\u00a0Rn and \u03b3\u00a0:\u00a0[0,\u00a0+\u221e)\u00a0\u00d7\u00a0Rn\u00a0\u2192\u00a0Rn\u00d7r satisfy\nfor all t and x and some constant C.\nThe filtering problem is the following: given observations Zs for 0\u00a0\u2264\u00a0s\u00a0\u2264\u00a0t, what is the best estimate \u0176t of the true state Yt of the system based on those observations?\nBy \"based on those observations\" it is meant that \u0176t is measurable with respect to the \u03c3-algebra Gt generated by the observations Zs, 0\u00a0\u2264\u00a0s\u00a0\u2264\u00a0t. Denote by K\u00a0=\u00a0K(Z,\u00a0t) be collection of all Rn-valued random variables Y that are square-integrable and Gt-measurable:\nBy \"best estimate\", it is meant that \u0176t minimizes the mean-square distance between Yt and all candidates in K:\nThe space K(Z,\u00a0t) of candidates is a Hilbert space, and the general theory of Hilbert spaces implies that the solution \u0176t of the minimization problem (M) is given by\nwhere PK(Z,t) denotes the orthogonal projection of L2(\u03a9,\u00a0\u03a3,\u00a0P;\u00a0Rn) onto the linear subspace K(Z,\u00a0t)\u00a0=\u00a0L2(\u03a9,\u00a0Gt,\u00a0P;\u00a0Rn). Furthermore, it is a general fact about conditional expectations that if F is any sub-\u03c3-algebra of \u03a3 then the orthogonal projection\nis exactly the conditional expectation operator E[\u00b7|F], i.e.,\nHence,\nThis elementary result is the basis for the general Fujisaki-Kallianpur-Kunita equation of filtering theory.", 
    "dbpedia_url": "http://dbpedia.org/resource/Filtering_problem_(stochastic_processes)", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Filtering_problem_(stochastic_processes)\n"
}