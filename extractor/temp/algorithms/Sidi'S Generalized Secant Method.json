{
    "about": "Sidi's generalized secant method is a root-finding algorithm, that is, a numerical method for solving equations of the form \n\n\n\nf\n(\nx\n)\n=\n0\n\n\n{\\displaystyle f(x)=0}\n\n . The method was published by Avram Sidi.[1]", 
    "name": "Sidi'S Generalized Secant Method", 
    "classification": "Root-Finding Algorithms", 
    "full_text": "Sidi's generalized secant method is a root-finding algorithm, that is, a numerical method for solving equations of the form \n\n\n\nf\n(\nx\n)\n=\n0\n\n\n{\\displaystyle f(x)=0}\n\n . The method was published by Avram Sidi.[1]\nThe method is a generalization of the secant method. Like the secant method, it is an iterative method which requires one evaluation of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n in each iteration and no derivatives of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n. The method can converge much faster though, with an order which approaches 2 provided that \n\n\n\nf\n\n\n{\\displaystyle f}\n\n satisfies the regularity conditions described below.\n\n\nWe call \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n the root of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n, that is, \n\n\n\nf\n(\n\u03b1\n)\n=\n0\n\n\n{\\displaystyle f(\\alpha )=0}\n\n. Sidi's method is an iterative method which generates a sequence \n\n\n\n{\n\nx\n\ni\n\n\n}\n\n\n{\\displaystyle \\{x_{i}\\}}\n\n of approximations of \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n. Starting with k + 1 initial approximations \n\n\n\n\nx\n\n1\n\n\n,\n\u2026\n,\n\nx\n\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{1},\\dots ,x_{k+1}}\n\n, the approximation \n\n\n\n\nx\n\nk\n+\n2\n\n\n\n\n{\\displaystyle x_{k+2}}\n\n is calculated in the first iteration, the approximation \n\n\n\n\nx\n\nk\n+\n3\n\n\n\n\n{\\displaystyle x_{k+3}}\n\n is calculated in the second iteration, etc. Each iteration takes as input the last k + 1 approximations and the value of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n at those approximations. Hence the nth iteration takes as input the approximations \n\n\n\n\nx\n\nn\n\n\n,\n\u2026\n,\n\nx\n\nn\n+\nk\n\n\n\n\n{\\displaystyle x_{n},\\dots ,x_{n+k}}\n\n and the values \n\n\n\nf\n(\n\nx\n\nn\n\n\n)\n,\n\u2026\n,\nf\n(\n\nx\n\nn\n+\nk\n\n\n)\n\n\n{\\displaystyle f(x_{n}),\\dots ,f(x_{n+k})}\n\n.\nThe number k must be 1 or larger: k = 1, 2, 3, .... It remains fixed during the execution of the algorithm. In order to obtain the starting approximations \n\n\n\n\nx\n\n1\n\n\n,\n\u2026\n,\n\nx\n\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{1},\\dots ,x_{k+1}}\n\n one could carry out a few initializing iterations with a lower value of k.\nThe approximation \n\n\n\n\nx\n\nn\n+\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{n+k+1}}\n\n is calculated as follows in the nth iteration. A polynomial of interpolation \n\n\n\n\np\n\nn\n,\nk\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{n,k}(x)}\n\n of degree k is fitted to the k + 1 points \n\n\n\n(\n\nx\n\nn\n\n\n,\nf\n(\n\nx\n\nn\n\n\n)\n)\n,\n\u2026\n(\n\nx\n\nn\n+\nk\n\n\n,\nf\n(\n\nx\n\nn\n+\nk\n\n\n)\n)\n\n\n{\\displaystyle (x_{n},f(x_{n})),\\dots (x_{n+k},f(x_{n+k}))}\n\n. With this polynomial, the next approximation \n\n\n\n\nx\n\nn\n+\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{n+k+1}}\n\n of \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n is calculated as\n\n\n\n\n\nx\n\nn\n+\nk\n+\n1\n\n\n=\n\nx\n\nn\n+\nk\n\n\n\u2212\n\n\n\nf\n(\n\nx\n\nn\n+\nk\n\n\n)\n\n\n\np\n\nn\n,\nk\n\n\u2032\n\n(\n\nx\n\nn\n+\nk\n\n\n)\n\n\n\n\n\n{\\displaystyle x_{n+k+1}=x_{n+k}-{\\frac {f(x_{n+k})}{p_{n,k}'(x_{n+k})}}}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(1)\nwith \n\n\n\n\np\n\nn\n,\nk\n\n\u2032\n\n(\n\nx\n\nn\n+\nk\n\n\n)\n\n\n{\\displaystyle p_{n,k}'(x_{n+k})}\n\n the derivative of \n\n\n\n\np\n\nn\n,\nk\n\n\n\n\n{\\displaystyle p_{n,k}}\n\n at \n\n\n\n\nx\n\nn\n+\nk\n\n\n\n\n{\\displaystyle x_{n+k}}\n\n. Having calculated \n\n\n\n\nx\n\nn\n+\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{n+k+1}}\n\n one calculates \n\n\n\nf\n(\n\nx\n\nn\n+\nk\n+\n1\n\n\n)\n\n\n{\\displaystyle f(x_{n+k+1})}\n\n and the algorithm can continue with the (n\u00a0+\u00a01)th iteration. Clearly, this method requires the function \n\n\n\nf\n\n\n{\\displaystyle f}\n\n to be evaluated only once per iteration; it requires no derivatives of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n.\nThe iterative cycle is stopped if an appropriate stop-criterion is met. Typically the criterion is that the last calculated approximation is close enough to the sought-after root \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n.\nTo execute the algorithm effectively, Sidi's method calculates the interpolating polynomial \n\n\n\n\np\n\nn\n,\nk\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{n,k}(x)}\n\n in its Newton form.\nSidi showed that if the function \n\n\n\nf\n\n\n{\\displaystyle f}\n\n is (k\u00a0+\u00a01)-times continuously differentiable in an open interval \n\n\n\nI\n\n\n{\\displaystyle I}\n\n containing \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n (that is, \n\n\n\nf\n\u2208\n\nC\n\nk\n+\n1\n\n\n(\nI\n)\n\n\n{\\displaystyle f\\in C^{k+1}(I)}\n\n), \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n is a simple root of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n (that is, \n\n\n\n\nf\n\u2032\n\n(\n\u03b1\n)\n\u2260\n0\n\n\n{\\displaystyle f'(\\alpha )\\neq 0}\n\n) and the initial approximations \n\n\n\n\nx\n\n1\n\n\n,\n\u2026\n,\n\nx\n\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{1},\\dots ,x_{k+1}}\n\n are chosen close enough to \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n, then the sequence \n\n\n\n{\n\nx\n\ni\n\n\n}\n\n\n{\\displaystyle \\{x_{i}\\}}\n\n converges to \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n, meaning that the following limit holds: \n\n\n\n\nlim\n\nn\n\u2192\n\u221e\n\n\n\nx\n\nn\n\n\n=\n\u03b1\n\n\n{\\displaystyle \\lim \\limits _{n\\to \\infty }x_{n}=\\alpha }\n\n.\nSidi furthermore showed that\nand that the sequence converges to \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n of order \n\n\n\n\n\u03c8\n\nk\n\n\n\n\n{\\displaystyle \\psi _{k}}\n\n, i.e.\nThe order of convergence \n\n\n\n\n\u03c8\n\nk\n\n\n\n\n{\\displaystyle \\psi _{k}}\n\n is the only positive root of the polynomial\nWe have e.g. \n\n\n\n\n\u03c8\n\n1\n\n\n=\n(\n1\n+\n\n\n5\n\n\n)\n\n/\n\n2\n\n\n{\\displaystyle \\psi _{1}=(1+{\\sqrt {5}})/2}\n\n \u2248 1.6180, \n\n\n\n\n\u03c8\n\n2\n\n\n\n\n{\\displaystyle \\psi _{2}}\n\n \u2248 1.8393 and \n\n\n\n\n\u03c8\n\n3\n\n\n\n\n{\\displaystyle \\psi _{3}}\n\n \u2248 1.9276. The order approaches 2 from below if k becomes large: \n\n\n\n\nlim\n\nk\n\u2192\n\u221e\n\n\n\n\u03c8\n\nk\n\n\n=\n2\n\n\n{\\displaystyle \\lim \\limits _{k\\to \\infty }\\psi _{k}=2}\n\n [2] [3]\nSidi's method reduces to the secant method if we take k = 1. In this case the polynomial \n\n\n\n\np\n\nn\n,\n1\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{n,1}(x)}\n\n is the linear approximation of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n around \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n which is used in the nth iteration of the secant method.\nWe can expect that the larger we choose k, the better \n\n\n\n\np\n\nn\n,\nk\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{n,k}(x)}\n\n is an approximation of \n\n\n\nf\n(\nx\n)\n\n\n{\\displaystyle f(x)}\n\n around \n\n\n\nx\n=\n\u03b1\n\n\n{\\displaystyle x=\\alpha }\n\n. Also, the better \n\n\n\n\np\n\nn\n,\nk\n\n\u2032\n\n(\nx\n)\n\n\n{\\displaystyle p_{n,k}'(x)}\n\n is an approximation of \n\n\n\n\nf\n\u2032\n\n(\nx\n)\n\n\n{\\displaystyle f'(x)}\n\n around \n\n\n\nx\n=\n\u03b1\n\n\n{\\displaystyle x=\\alpha }\n\n. If we replace \n\n\n\n\np\n\nn\n,\nk\n\n\u2032\n\n\n\n{\\displaystyle p_{n,k}'}\n\n with \n\n\n\n\nf\n\u2032\n\n\n\n{\\displaystyle f'}\n\n in (1) we obtain that the next approximation in each iteration is calculated as\n\n\n\n\n\nx\n\nn\n+\nk\n+\n1\n\n\n=\n\nx\n\nn\n+\nk\n\n\n\u2212\n\n\n\nf\n(\n\nx\n\nn\n+\nk\n\n\n)\n\n\n\nf\n\u2032\n\n(\n\nx\n\nn\n+\nk\n\n\n)\n\n\n\n\n\n{\\displaystyle x_{n+k+1}=x_{n+k}-{\\frac {f(x_{n+k})}{f'(x_{n+k})}}}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(2)\nThis is the Newton\u2013Raphson method. It starts off with a single approximation \n\n\n\n\nx\n\n1\n\n\n\n\n{\\displaystyle x_{1}}\n\n so we can take k = 0 in (2). It does not require an interpolating polynomial but instead one has to evaluate the derivative \n\n\n\n\nf\n\u2032\n\n\n\n{\\displaystyle f'}\n\n in each iteration. Depending on the nature of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n this may not be possible or practical.\nOnce the interpolating polynomial \n\n\n\n\np\n\nn\n,\nk\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{n,k}(x)}\n\n has been calculated, one can also calculate the next approximation \n\n\n\n\nx\n\nn\n+\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{n+k+1}}\n\n as a solution of \n\n\n\n\np\n\nn\n,\nk\n\n\n(\nx\n)\n=\n0\n\n\n{\\displaystyle p_{n,k}(x)=0}\n\n instead of using (1). For k\u00a0=\u00a01 these two methods are identical: it is the secant method. For k\u00a0=\u00a02 this method is known as Muller's method.[3] For k\u00a0=\u00a03 this approach involves finding the roots of a cubic function, which is unattractively complicated. This problem becomes worse for even larger values of\u00a0k. An additional complication is that the equation \n\n\n\n\np\n\nn\n,\nk\n\n\n(\nx\n)\n=\n0\n\n\n{\\displaystyle p_{n,k}(x)=0}\n\n will in general have multiple solutions and a prescription has to be given which of these solutions is the next approximation \n\n\n\n\nx\n\nn\n+\nk\n+\n1\n\n\n\n\n{\\displaystyle x_{n+k+1}}\n\n. Muller does this for the case k\u00a0=\u00a02 but no such prescriptions appear to exist\u00a0for k\u00a0>\u00a02.", 
    "dbpedia_url": "http://dbpedia.org/resource/Sidi's_generalized_secant_method", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Sidi's_generalized_secant_method\n"
}