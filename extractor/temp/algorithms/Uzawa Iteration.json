{
    "about": "In numerical mathematics, the Uzawa iteration is an algorithm for solving saddle point problems. It is named after Hirofumi Uzawa and was originally introduced in the context of concave programming.[1]", 
    "name": "Uzawa Iteration", 
    "classification": "Numerical Analysis", 
    "full_text": "In numerical mathematics, the Uzawa iteration is an algorithm for solving saddle point problems. It is named after Hirofumi Uzawa and was originally introduced in the context of concave programming.[1]\n\n\nWe consider a saddle point problem of the form\nwhere \n\n\n\nA\n\n\n{\\displaystyle A}\n\n is a symmetric positive-definite matrix. Multiplying the first row by \n\n\n\n\nB\n\n\u2217\n\n\n\nA\n\n\u2212\n1\n\n\n\n\n{\\displaystyle B^{*}A^{-1}}\n\n and subtracting from the second row yields the upper-triangular system\nwhere \n\n\n\nS\n:=\n\nB\n\n\u2217\n\n\n\nA\n\n\u2212\n1\n\n\nB\n\n\n{\\displaystyle S:=B^{*}A^{-1}B}\n\n denotes the Schur complement. Since \n\n\n\nS\n\n\n{\\displaystyle S}\n\n is symmetric positive-definite, we can apply standard iterative methods like the gradient descent method or the conjugate gradient method to\nin order to compute \n\n\n\n\nx\n\n2\n\n\n\n\n{\\displaystyle x_{2}}\n\n. The vector \n\n\n\n\nx\n\n1\n\n\n\n\n{\\displaystyle x_{1}}\n\n can be reconstructed by solving\nIt is possible to update \n\n\n\n\nx\n\n1\n\n\n\n\n{\\displaystyle x_{1}}\n\n alongside \n\n\n\n\nx\n\n2\n\n\n\n\n{\\displaystyle x_{2}}\n\n during the iteration for the Schur complement system and thus obtain an efficient algorithm.\nWe start the conjugate gradient iteration by computing the residual\nof the Schur complement system, where\ndenotes the upper half of the solution vector matching the initial guess \n\n\n\n\nx\n\n2\n\n\n\n\n{\\displaystyle x_{2}}\n\n for its lower half. We complete the initialization by choosing the first search direction\nIn each step, we compute\nand keep the intermediate result\nfor later. The scaling factor is given by\nand leads to the updates\nUsing the intermediate result \n\n\n\n\np\n\n1\n\n\n\n\n{\\displaystyle p_{1}}\n\n saved earlier, we can also update the upper part of the solution vector\nNow we only have to construct the new search direction by the Gram\u2013Schmidt process, i.e.,\nThe iteration terminates if the residual \n\n\n\n\nr\n\n2\n\n\n\n\n{\\displaystyle r_{2}}\n\n has become sufficiently small or if the norm of \n\n\n\n\np\n\n2\n\n\n\n\n{\\displaystyle p_{2}}\n\n is significantly smaller than \n\n\n\n\nr\n\n2\n\n\n\n\n{\\displaystyle r_{2}}\n\n indicating that the Krylov subspace has been almost exhausted.\nIf solving the linear system \n\n\n\nA\nx\n=\nb\n\n\n{\\displaystyle Ax=b}\n\n exactly is not feasible, inexact solvers can be applied.[2][3][4]\nIf the Schur complement system is ill-conditioned, preconditioners can be employed to improve the speed of convergence of the underlying gradient method.[2][5]\nInequality constraints can be incorporated, e.g., in order to handle obstacle problems.[5]", 
    "dbpedia_url": "http://dbpedia.org/resource/Uzawa_iteration", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Uzawa_iteration\n"
}