{
    "about": "A low-pass filter is a filter that passes signals with a frequency lower than a certain cutoff frequency and attenuates signals with frequencies higher than the cutoff frequency. The exact frequency response of the filter depends on the filter design. The filter is sometimes called a high-cut filter, or treble cut filter in audio applications. A low-pass filter is the complement of a high-pass filter.", 
    "classification": "Signal Processing", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Low-pass_filter\n", 
    "full_text": "A low-pass filter is a filter that passes signals with a frequency lower than a certain cutoff frequency and attenuates signals with frequencies higher than the cutoff frequency. The exact frequency response of the filter depends on the filter design. The filter is sometimes called a high-cut filter, or treble cut filter in audio applications. A low-pass filter is the complement of a high-pass filter.\nLow-pass filters exist in many different forms, including electronic circuits such as a hiss filter used in audio, anti-aliasing filters for conditioning signals prior to analog-to-digital conversion, digital filters for smoothing sets of data, acoustic barriers, blurring of images, and so on. The moving average operation used in fields such as finance is a particular kind of low-pass filter, and can be analyzed with the same signal processing techniques as are used for other low-pass filters. Low-pass filters provide a smoother form of a signal, removing the short-term fluctuations, and leaving the longer-term trend.\nFilter designers will often use the low-pass form as a prototype filter. That is, a filter with unity bandwidth and impedance. The desired filter is obtained from the prototype by scaling for the desired bandwidth and impedance and transforming into the desired bandform (that is low-pass, high-pass, band-pass or band-stop).\n\n\nExamples of low-pass filters occur in acoustics, optics and electronics.\nA stiff physical barrier tends to reflect higher sound frequencies, and so acts as a low-pass filter for transmitting sound. When music is playing in another room, the low notes are easily heard, while the high notes are attenuated.\nAn optical filter with the same function can correctly be called a low-pass filter, but conventionally is called a longpass filter (low frequency is long wavelength), to avoid confusion.\nIn an electronic low-pass RC filter for voltage signals, high frequencies in the input signal are attenuated, but the filter has little attenuation below the cutoff frequency determined by its RC time constant. For current signals, a similar circuit, using a resistor and capacitor in parallel, works in a similar manner. (See current divider discussed in more detail below.)\nElectronic low-pass filters are used on inputs to subwoofers and other types of loudspeakers, to block high pitches that they can't efficiently reproduce. Radio transmitters use low-pass filters to block harmonic emissions that might interfere with other communications. The tone knob on many electric guitars is a low-pass filter used to reduce the amount of treble in the sound. An integrator is another time constant low-pass filter.[1]\nTelephone lines fitted with DSL splitters use low-pass and high-pass filters to separate DSL and POTS signals sharing the same pair of wires.[2][3]\nLow-pass filters also play a significant role in the sculpting of sound created by analogue and virtual analogue synthesisers. See subtractive synthesis.\nAn ideal low-pass filter completely eliminates all frequencies above the cutoff frequency while passing those below unchanged; its frequency response is a rectangular function and is a brick-wall filter. The transition region present in practical filters does not exist in an ideal filter. An ideal low-pass filter can be realized mathematically (theoretically) by multiplying a signal by the rectangular function in the frequency domain or, equivalently, convolution with its impulse response, a sinc function, in the time domain.\nHowever, the ideal filter is impossible to realize without also having signals of infinite extent in time, and so generally needs to be approximated for real ongoing signals, because the sinc function's support region extends to all past and future times. The filter would therefore need to have infinite delay, or knowledge of the infinite future and past, in order to perform the convolution. It is effectively realizable for pre-recorded digital signals by assuming extensions of zero into the past and future, or more typically by making the signal repetitive and using Fourier analysis.\nReal filters for real-time applications approximate the ideal filter by truncating and windowing the infinite impulse response to make a finite impulse response; applying that filter requires delaying the signal for a moderate period of time, allowing the computation to \"see\" a little bit into the future. This delay is manifested as phase shift. Greater accuracy in approximation requires a longer delay.\nAn ideal low-pass filter results in ringing artifacts via the Gibbs phenomenon. These can be reduced or worsened by choice of windowing function, and the design and choice of real filters involves understanding and minimizing these artifacts. For example, \"simple truncation [of sinc] causes severe ringing artifacts,\" in signal reconstruction, and to reduce these artifacts one uses window functions \"which drop off more smoothly at the edges.\"[4]\nThe Whittaker\u2013Shannon interpolation formula describes how to use a perfect low-pass filter to reconstruct a continuous signal from a sampled digital signal. Real digital-to-analog converters use real filter approximations.\nThere are many different types of filter circuits, with different responses to changing frequency. The frequency response of a filter is generally represented using a Bode plot, and the filter is characterized by its cutoff frequency and rate of frequency rolloff. In all cases, at the cutoff frequency, the filter attenuates the input power by half or 3\u00a0dB. So the order of the filter determines the amount of additional attenuation for frequencies higher than the cutoff frequency.\nOn any Butterworth filter, if one extends the horizontal line to the right and the diagonal line to the upper-left (the asymptotes of the function), they intersect at exactly the cutoff frequency. The frequency response at the cutoff frequency in a first-order filter is 3\u00a0dB below the horizontal line. The various types of filters (Butterworth filter, Chebyshev filter, Bessel filter, etc.) all have different-looking knee curves. Many second-order filters have \"peaking\" or resonance that puts their frequency response at the cutoff frequency above the horizontal line. Furthermore, the actual frequency where this peaking occurs can be predicted without calculus, as shown by Cartwright[5] et al. For third-order filters, the peaking and its frequency of occurrence can too be predicted without calculus as recently shown by Cartwright[6] et al. See electronic filter for other types.\nThe meanings of 'low' and 'high'\u2014that is, the cutoff frequency\u2014depend on the characteristics of the filter. The term \"low-pass filter\" merely refers to the shape of the filter's response; a high-pass filter could be built that cuts off at a lower frequency than any low-pass filter\u2014it is their responses that set them apart. Electronic circuits can be devised for any desired frequency range, right up through microwave frequencies (above 1\u00a0GHz) and higher.\nContinuous-time filters can also be described in terms of the Laplace transform of their impulse response, in a way that lets all characteristics of the filter be easily analyzed by considering the pattern of poles and zeros of the Laplace transform in the complex plane. (In discrete time, one can similarly consider the Z-transform of the impulse response.)\nFor example, a first-order low-pass filter can be described in Laplace notation as:\nwhere s is the Laplace transform variable, \u03c4 is the filter time constant, and K is the gain of the filter in the passband.\nOne simple low-pass filter circuit consists of a resistor in series with a load, and a capacitor in parallel with the load. The capacitor exhibits reactance, and blocks low-frequency signals, forcing them through the load instead. At higher frequencies the reactance drops, and the capacitor effectively functions as a short circuit. The combination of resistance and capacitance gives the time constant of the filter \n\n\n\n\n\u03c4\n\n=\n\nR\nC\n\n\n\n{\\displaystyle \\scriptstyle \\tau \\;=\\;RC}\n\n (represented by the Greek letter tau). The break frequency, also called the turnover frequency or cutoff frequency (in hertz), is determined by the time constant:\nor equivalently (in radians per second):\nThis circuit may be understood by considering the time the capacitor needs to charge or discharge through the resistor:\nAnother way to understand this circuit is through the concept of reactance at a particular frequency:\nThe capacitor is not an \"on/off\" object (like the block or pass fluidic explanation above). The capacitor variably acts between these two extremes. It is the Bode plot and frequency response that show this variability.\nA resistor\u2013inductor circuit or RL filter is an electric circuit composed of resistors and inductors driven by a voltage or current source. A first order RL circuit is composed of one resistor and one inductor and is the simplest type of RL circuit.\nA first order RL circuit is one of the simplest analogue infinite impulse response electronic filters. It consists of a resistor and an inductor, either in series driven by a voltage source or in parallel driven by a current source.\nAn RLC circuit (the letters R, L and C can be in other orders) is an electrical circuit consisting of a resistor, an inductor, and a capacitor, connected in series or in parallel. The RLC part of the name is due to those letters being the usual electrical symbols for resistance, inductance and capacitance respectively. The circuit forms a harmonic oscillator for current and will resonate in a similar way as an LC circuit will. The main difference that the presence of the resistor makes is that any oscillation induced in the circuit will die away over time if it is not kept going by a source. This effect of the resistor is called damping. The presence of the resistance also reduces the peak resonant frequency somewhat. Some resistance is unavoidable in real circuits, even if a resistor is not specifically included as a component. An ideal, pure LC circuit is an abstraction for the purpose of theory.\nThere are many applications for this circuit. They are used in many different types of oscillator circuits. Another important application is for tuning, such as in radio receivers or television sets, where they are used to select a narrow range of frequencies from the ambient radio waves. In this role the circuit is often referred to as a tuned circuit. An RLC circuit can be used as a band-pass filter, band-stop filter, low-pass filter or high-pass filter. The RLC filter is described as a second-order circuit, meaning that any voltage or current in the circuit can be described by a second-order differential equation in circuit analysis.\nHigher order passive filters, can also be constructed (see diagram for a third order example).\nAnother type of electrical circuit is an active low-pass filter.\nIn the operational amplifier circuit shown in the figure, the cutoff frequency (in hertz) is defined as:\nor equivalently (in radians per second):\nThe gain in the passband is \u2212R2/R1, and the stopband drops off at \u22126\u00a0dB per octave (that is \u221220\u00a0dB per decade) as it is a first-order filter.\nMany digital filters are designed to give low-pass characteristics. Both infinite impulse response and finite impulse response low pass filters as well as filters using Fourier transforms are widely used.\nThe effect of an infinite impulse response low-pass filter can be simulated on a computer by analyzing an RC filter's behavior in the time domain, and then discretizing the model.\nFrom the circuit diagram to the right, according to Kirchhoff's Laws and the definition of capacitance:\n\n\n\n\n\nv\n\nin\n\n\n(\nt\n)\n\u2212\n\nv\n\nout\n\n\n(\nt\n)\n=\nR\n\ni\n(\nt\n)\n\n\n{\\displaystyle v_{\\text{in}}(t)-v_{\\text{out}}(t)=R\\;i(t)}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(V)\n\n\n\n\n\nQ\n\nc\n\n\n(\nt\n)\n=\nC\n\n\nv\n\nout\n\n\n(\nt\n)\n\n\n{\\displaystyle Q_{c}(t)=C\\,v_{\\text{out}}(t)}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(Q)\n\n\n\n\ni\n(\nt\n)\n=\n\n\n\nd\n\u2061\n\nQ\n\nc\n\n\n\n\nd\n\u2061\nt\n\n\n\n\n\n{\\displaystyle i(t)={\\frac {\\operatorname {d} Q_{c}}{\\operatorname {d} t}}}\n\n\n\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n(I)\nwhere \n\n\n\n\nQ\n\nc\n\n\n(\nt\n)\n\n\n{\\displaystyle Q_{c}(t)}\n\n is the charge stored in the capacitor at time \n\n\n\n\nt\n\n\n\n{\\displaystyle \\scriptstyle t}\n\n. Substituting equation Q into equation I gives \n\n\n\n\ni\n(\nt\n)\n\n=\n\nC\n\n\n\nd\n\u2061\n\nv\n\nout\n\n\n\n\nd\n\u2061\nt\n\n\n\n\n\n\n{\\displaystyle \\scriptstyle i(t)\\;=\\;C{\\frac {\\operatorname {d} v_{\\text{out}}}{\\operatorname {d} t}}}\n\n, which can be substituted into equation V so that:\nThis equation can be discretized. For simplicity, assume that samples of the input and output are taken at evenly spaced points in time separated by \n\n\n\n\n\n\u0394\n\nT\n\n\n\n\n\n{\\displaystyle \\scriptstyle \\Delta _{T}}\n\n time. Let the samples of \n\n\n\n\n\nv\n\nin\n\n\n\n\n\n{\\displaystyle \\scriptstyle v_{\\text{in}}}\n\n be represented by the sequence \n\n\n\n\n(\n\nx\n\n1\n\n\n,\n\n\nx\n\n2\n\n\n,\n\n\u2026\n,\n\n\nx\n\nn\n\n\n)\n\n\n\n{\\displaystyle \\scriptstyle (x_{1},\\,x_{2},\\,\\ldots ,\\,x_{n})}\n\n, and let \n\n\n\n\n\nv\n\nout\n\n\n\n\n\n{\\displaystyle \\scriptstyle v_{\\text{out}}}\n\n be represented by the sequence \n\n\n\n\n(\n\ny\n\n1\n\n\n,\n\n\ny\n\n2\n\n\n,\n\n\u2026\n,\n\n\ny\n\nn\n\n\n)\n\n\n\n{\\displaystyle \\scriptstyle (y_{1},\\,y_{2},\\,\\ldots ,\\,y_{n})}\n\n, which correspond to the same points in time. Making these substitutions:\nAnd rearranging terms gives the recurrence relation\nThat is, this discrete-time implementation of a simple RC low-pass filter is the exponentially weighted moving average\nBy definition, the smoothing factor \n\n\n\n\n0\n\n\u2264\n\n\u03b1\n\n\u2264\n\n1\n\n\n\n{\\displaystyle \\scriptstyle 0\\;\\leq \\;\\alpha \\;\\leq \\;1}\n\n. The expression for \n\n\n\n\n\u03b1\n\n\n\n{\\displaystyle \\scriptstyle \\alpha }\n\n yields the equivalent time constant \n\n\n\n\nR\nC\n\n\n\n{\\displaystyle \\scriptstyle RC}\n\n in terms of the sampling period \n\n\n\n\n\n\u0394\n\nT\n\n\n\n\n\n{\\displaystyle \\scriptstyle \\Delta _{T}}\n\n and smoothing factor \n\n\n\n\n\u03b1\n\n\n\n{\\displaystyle \\scriptstyle \\alpha }\n\n:\nRecalling that\nthen \n\n\n\n\u03b1\n\n\n{\\displaystyle \\alpha }\n\n and \n\n\n\n\nf\n\nc\n\n\n\n\n{\\displaystyle f_{c}}\n\n are related by:\nand\nIf \n\n\n\n\n\u03b1\n\n=\n\n0.5\n\n\n\n{\\displaystyle \\scriptstyle \\alpha \\;=\\;0.5}\n\n, then the \n\n\n\n\nR\nC\n\n\n\n{\\displaystyle \\scriptstyle RC}\n\n time constant is equal to the sampling period. If \n\n\n\n\n\u03b1\n\n\u226a\n\n0.5\n\n\n\n{\\displaystyle \\scriptstyle \\alpha \\;\\ll \\;0.5}\n\n, then \n\n\n\n\nR\nC\n\n\n\n{\\displaystyle \\scriptstyle RC}\n\n is significantly larger than the sampling interval, and \n\n\n\n\n\n\u0394\n\nT\n\n\n\n\u2248\n\n\u03b1\nR\nC\n\n\n\n{\\displaystyle \\scriptstyle \\Delta _{T}\\;\\approx \\;\\alpha RC}\n\n.\nThe filter recurrence relation provides a way to determine the output samples in terms of the input samples and the preceding output. The following pseudocode algorithm simulates the effect of a low-pass filter on a series of digital samples:\nThe loop that calculates each of the n outputs can be refactored into the equivalent:\nThat is, the change from one filter output to the next is proportional to the difference between the previous output and the next input. This exponential smoothing property matches the exponential decay seen in the continuous-time system. As expected, as the time constant \n\n\n\n\nR\nC\n\n\n\n{\\displaystyle \\scriptstyle RC}\n\n increases, the discrete-time smoothing parameter \n\n\n\n\n\u03b1\n\n\n\n{\\displaystyle \\scriptstyle \\alpha }\n\n decreases, and the output samples \n\n\n\n\n(\n\ny\n\n1\n\n\n,\n\n\ny\n\n2\n\n\n,\n\n\u2026\n,\n\n\ny\n\nn\n\n\n)\n\n\n\n{\\displaystyle \\scriptstyle (y_{1},\\,y_{2},\\,\\ldots ,\\,y_{n})}\n\n respond more slowly to a change in the input samples \n\n\n\n\n(\n\nx\n\n1\n\n\n,\n\n\nx\n\n2\n\n\n,\n\n\u2026\n,\n\n\nx\n\nn\n\n\n)\n\n\n\n{\\displaystyle \\scriptstyle (x_{1},\\,x_{2},\\,\\ldots ,\\,x_{n})}\n\n; the system has more inertia. This filter is an infinite-impulse-response (IIR) single-pole low-pass filter.\nFinite-impulse-response filters can be built that approximate to the sinc function time-domain response of an ideal sharp-cutoff low-pass filter. In practice, the time-domain response must be time truncated and is often of a simplified shape; in the simplest case, a running average can be used, giving a square time response.[7]\nFor minimum distortion the finite impulse response filter has an unbounded number of coefficients.\nFor non-realtime filtering, to achieve a low pass filter, the entire signal is usually taken as a looped signal, the Fourier transform is taken, filtered in the frequency domain, followed by an inverse Fourier transform. Only O(n log(n)) operations are required compared to O(n2) for the time domain filtering algorithm.\nThis can also sometimes be done in real-time, where the signal is delayed long enough to perform the Fourier transformation on shorter, overlapping blocks.", 
    "name": "Low Pass Filter"
}