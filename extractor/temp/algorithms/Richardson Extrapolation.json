{
    "about": "In numerical analysis, Richardson extrapolation is a sequence acceleration method, used to improve the rate of convergence of a sequence. It is named after Lewis Fry Richardson, who introduced the technique in the early 20th century.[1][2] In the words of Birkhoff and Rota, \"its usefulness for practical computations can hardly be overestimated.\"[3]", 
    "name": "Richardson Extrapolation", 
    "classification": "Numerical Analysis", 
    "full_text": "In numerical analysis, Richardson extrapolation is a sequence acceleration method, used to improve the rate of convergence of a sequence. It is named after Lewis Fry Richardson, who introduced the technique in the early 20th century.[1][2] In the words of Birkhoff and Rota, \"its usefulness for practical computations can hardly be overestimated.\"[3]\nPractical applications of Richardson extrapolation include Romberg integration, which applies Richardson extrapolation to the trapezoid rule, and the Bulirsch\u2013Stoer algorithm for solving ordinary differential equations.\n\n\nSuppose that we wish to approximate \n\n\n\n\nA\n\n\u2217\n\n\n\n\n{\\displaystyle A^{*}}\n\n, and we have a method \n\n\n\nA\n(\nh\n)\n\n\n{\\displaystyle A(h)}\n\n that depends on a small parameter \n\n\n\nh\n\n\n{\\displaystyle h}\n\n, so that\n\n\n\n\nA\n(\nh\n)\n=\n\nA\n\n\u2217\n\n\n+\nC\n\nh\n\nn\n\n\n+\nO\n(\n\nh\n\nn\n+\n1\n\n\n)\n\n\n\n{\\displaystyle A(h)=A^{\\ast }+Ch^{n}+O(h^{n+1})\\;}\n\n\nDefine a new method\n\n\n\n\nR\n(\nh\n,\nk\n)\n:=\n\n\n\n\nk\n\nn\n\n\nA\n(\nh\n)\n\u2212\nA\n(\nk\n\nh\n)\n\n\n\nk\n\nn\n\n\n\u2212\n1\n\n\n\n\n\n{\\displaystyle R(h,k):={\\frac {k^{n}A(h)-A(k\\,h)}{k^{n}-1}}}\n\n\nThen\n\n\n\n\nR\n(\nh\n,\nk\n)\n=\n\n\n\n\nk\n\nn\n\n\n(\n\nA\n\n\u2217\n\n\n+\nC\n\nh\n\nn\n\n\n+\nO\n(\n\nh\n\nn\n+\n1\n\n\n)\n)\n\u2212\n(\n\nA\n\n\u2217\n\n\n+\nC\n\nk\n\nn\n\n\n\nh\n\nn\n\n\n+\nO\n(\n\nh\n\nn\n+\n1\n\n\n)\n)\n\n\n\nk\n\nn\n\n\n\u2212\n1\n\n\n\n=\n\nA\n\n\u2217\n\n\n+\nO\n(\n\nh\n\nn\n+\n1\n\n\n)\n.\n\n\n{\\displaystyle R(h,k)={\\frac {k^{n}(A^{*}+Ch^{n}+O(h^{n+1}))-(A^{*}+Ck^{n}h^{n}+O(h^{n+1}))}{k^{n}-1}}=A^{*}+O(h^{n+1}).}\n\n\n\n\n\n\nR\n(\nh\n,\nk\n)\n\n\n{\\displaystyle R(h,k)}\n\n is called the Richardson extrapolation of A(h), and has a higher-order error estimate \n\n\n\nO\n(\n\nh\n\nn\n+\n1\n\n\n)\n\n\n{\\displaystyle O(h^{n+1})}\n\n compared to \n\n\n\nA\n(\nh\n)\n\n\n{\\displaystyle A(h)}\n\n.\nVery often, it is much easier to obtain a given precision by using R(h) rather than A(h') with a much smaller h' , which can cause problems due to limited precision (rounding errors) and/or due to the increasing number of calculations needed (see examples below).\nLet A(h) be an approximation of A that depends on a positive step size h with an error formula of the form\nwhere the ai are unknown constants and the ki are known constants such that hki > hki+1.\nThe exact value sought can be given by\nwhich can be simplified with Big O notation to be\nUsing the step sizes h and h / t for some t, the two formulas for A are:\nMultiplying the second equation by tk0 and subtracting the first equation gives\nwhich can be solved for A to give\nBy this process, we have achieved a better approximation of A by subtracting the largest term in the error which was O(hk0). This process can be repeated to remove more error terms to get even better approximations.\nA general recurrence relation beginning with \n\n\n\n\nA\n\n0\n\n\n=\nA\n(\nh\n)\n\n\n{\\displaystyle A_{0}=A(h)}\n\n can be defined for the approximations by\nwhere \n\n\n\n\nk\n\ni\n+\n1\n\n\n\n\n{\\displaystyle k_{i+1}}\n\n satisfies\n\nThe Richardson extrapolation can be considered as a linear sequence transformation.\nAdditionally, the general formula can be used to estimate k0 when neither its value nor A is known a priori. Such a technique can be useful for quantifying an unknown rate of convergence. Given approximations of A from three distinct step sizes h, h / t, and h / s, the exact relationship\nyields an approximate relationship\nwhich can be solved numerically to estimate k0.\nUsing Taylor's theorem about h=0,\nthe derivative of f(x) is given by\nIf the initial approximations of the derivative are chosen to be\nthen ki = i+1.\nFor t = 2, the first formula extrapolated for A would be\nFor the new approximation\nwe can extrapolate again to obtain\n\nThe following pseudocode in MATLAB style demonstrates Richardson extrapolation to help solve the ODE \n\n\n\n\ny\n\u2032\n\n(\nt\n)\n=\n\u2212\n\ny\n\n2\n\n\n\n\n{\\displaystyle y'(t)=-y^{2}}\n\n, \n\n\n\ny\n(\n0\n)\n=\n1\n\n\n{\\displaystyle y(0)=1}\n\n with the Trapezoidal method. In this example we halve the step size \n\n\n\nh\n\n\n{\\displaystyle h}\n\n each iteration and so in the discussion above we'd have that \n\n\n\nt\n=\n2\n\n\n{\\displaystyle t=2}\n\n. The error of the Trapezoidal method can be expressed in terms of odd powers so that the error over multiple steps can be expressed in even powers and so we take powers of \n\n\n\n4\n=\n\n2\n\n2\n\n\n=\n\nt\n\n2\n\n\n\n\n{\\displaystyle 4=2^{2}=t^{2}}\n\n in the pseudocode. We want to find the value of \n\n\n\ny\n(\n5\n)\n\n\n{\\displaystyle y(5)}\n\n, which has the exact solution of \n\n\n\n\n\n1\n\n5\n+\n1\n\n\n\n=\n\n\n1\n6\n\n\n=\n0.1666...\n\n\n{\\displaystyle {\\frac {1}{5+1}}={\\frac {1}{6}}=0.1666...}\n\n since the exact solution of the ODE is \n\n\n\ny\n(\nt\n)\n=\n\n\n1\n\n1\n+\nt\n\n\n\n\n\n{\\displaystyle y(t)={\\frac {1}{1+t}}}\n\n. This pseudocode assumes that a function called Trapezoidal(f, tStart, tEnd, h, y0) exists which performs the trapezoidal method on the function f, with starting point y0 and tStart, step size h, and attempts to computes y(tEnd)\nStarting with too small an initial step size can potentially introduce error into the final solution. Although there are methods designed to help pick the best initial step size, one option is to start with a large step size and then to allow the Richardson extrapolation to reduce the step size each iteration until the error reaches the desired tolerance.", 
    "dbpedia_url": "http://dbpedia.org/resource/Richardson_extrapolation", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Richardson_extrapolation\n"
}