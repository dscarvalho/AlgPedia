{
    "about": "Constrained optimization by linear approximation (COBYLA) is a numerical optimization method for constrained problems where the derivative of the objective function is not known, invented by Michael J. D. Powell. That is, COBYLA can find the vector \n\n\n\n\n\n\nx\n\u2192\n\n\n\n\u2208\n\n\nS\n\n\n\n\n{\\displaystyle {\\vec {x}}\\in {\\mathcal {S}}}\n\n with \n\n\n\n\n\nS\n\n\n\u2286\n\n\nR\n\n\nn\n\n\n\n\n{\\displaystyle {\\mathcal {S}}\\subseteq \\mathbb {R} ^{n}}\n\n that has the minimal (or maximal) \n\n\n\nf\n(\n\n\n\nx\n\u2192\n\n\n\n)\n\n\n{\\displaystyle f({\\vec {x}})}\n\n without knowing the gradient of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n. COBYLA is also the name of Powell's software implementation of the algorithm in Fortran.[1]", 
    "name": "Cobyla", 
    "classification": "Optimization Algorithms And Methods", 
    "full_text": "Constrained optimization by linear approximation (COBYLA) is a numerical optimization method for constrained problems where the derivative of the objective function is not known, invented by Michael J. D. Powell. That is, COBYLA can find the vector \n\n\n\n\n\n\nx\n\u2192\n\n\n\n\u2208\n\n\nS\n\n\n\n\n{\\displaystyle {\\vec {x}}\\in {\\mathcal {S}}}\n\n with \n\n\n\n\n\nS\n\n\n\u2286\n\n\nR\n\n\nn\n\n\n\n\n{\\displaystyle {\\mathcal {S}}\\subseteq \\mathbb {R} ^{n}}\n\n that has the minimal (or maximal) \n\n\n\nf\n(\n\n\n\nx\n\u2192\n\n\n\n)\n\n\n{\\displaystyle f({\\vec {x}})}\n\n without knowing the gradient of \n\n\n\nf\n\n\n{\\displaystyle f}\n\n. COBYLA is also the name of Powell's software implementation of the algorithm in Fortran.[1]\nPowell invented COBYLA while working for Westland Helicopters.[2]\nIt works by iteratively approximating the actual constrained optimization problem with linear programming problems. During an iteration, an approximating linear programming problem is solved to obtain a candidate for the optimal solution. The candidate solution is evaluated using the original objective and constraint functions, yielding a new data point in the optimization space. This information is used to improve the approximating linear programming problem used for the next iteration of the algorithm. When the solution cannot be improved anymore, the step size is reduced, refining the search. When the step size becomes sufficiently small, the algorithm finishes.\nThe COBYLA software is distributed under The GNU Lesser General Public License (LGPL).[3]\n", 
    "dbpedia_url": "http://dbpedia.org/resource/COBYLA", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/COBYLA\n"
}