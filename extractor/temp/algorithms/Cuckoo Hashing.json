{
    "about": "Cuckoo hashing is a scheme in computer programming for resolving hash collisions of values of hash functions in a table, with worst-case constant lookup time. The name derives from the behavior of some species of cuckoo, where the cuckoo chick pushes the other eggs or young out of the nest when it hatches; analogously, inserting a new key into a cuckoo hashing table may push an older key to a different location in the table.", 
    "name": "Cuckoo Hashing", 
    "classification": "Search Algorithms", 
    "full_text": "Cuckoo hashing is a scheme in computer programming for resolving hash collisions of values of hash functions in a table, with worst-case constant lookup time. The name derives from the behavior of some species of cuckoo, where the cuckoo chick pushes the other eggs or young out of the nest when it hatches; analogously, inserting a new key into a cuckoo hashing table may push an older key to a different location in the table.\n\n\nCuckoo hashing was first described by Rasmus Pagh and Flemming Friche Rodler in 2001.[1]\nCuckoo hashing is a form of open addressing in which each non-empty cell of a hash table contains a key or key\u2013value pair. A hash function is used to determine the location for each key, and its presence in the table (or the value associated with it) can be found by examining that cell of the table. However, open addressing suffers from collisions, which happen when more than one key is mapped to the same cell. The basic idea of cuckoo hashing is to resolve collisions by using two hash functions instead of only one. This provides two possible locations in the hash table for each key. In one of the commonly used variants of the algorithm, the hash table is split into two smaller tables of equal size, and each hash function provides an index into one of these two tables. It is also possible for both hash functions to provide indexes into a single table.\nLookup requires inspection of just two locations in the hash table, which takes constant time in the worst case (see Big O notation). This is in contrast to many other hash table algorithms, which may not have a constant worst-case bound on the time to do a lookup. Deletions, also, may be performed by blanking the cell containing a key, in constant worst case time, more simply than some other schemes such as linear probing.\nWhen a new key is inserted, and one of its two cells is empty, it may be placed in that cell. However, when both cells are already full, it will be necessary to move other keys to their second locations (or back to their first locations) to make room for the new key. A greedy algorithm is used: The new key is inserted in one of its two possible locations, \"kicking out\", that is, displacing, any key that might already reside in this location. This displaced key is then inserted in its alternative location, again kicking out any key that might reside there. The process continues in the same way until an empty position is found, completing the algorithm. However, it is possible for this insertion process to fail, by entering an infinite loop or by finding a very long chain (longer than a preset threshold that is logarithmic in the table size). In this case, the hash table is rebuilt in-place using new hash functions:\nThere is no need to allocate new tables for the rehashing: We may simply run through the tables to delete and perform the usual insertion procedure on all keys found not to be at their intended position in the table.\nInsertions succeed in expected constant time,[1] even considering the possibility of having to rebuild the table, as long as the number of keys is kept below half of the capacity of the hash table, i.e., the load factor is below 50%.\nOne method of proving this uses the theory of random graphs: one may form an undirected graph called the \"cuckoo graph\" that has a vertex for each hash table location, and an edge for each hashed value, with the endpoints of the edge being the two possible locations of the value. Then, the greedy insertion algorithm for adding a set of values to a cuckoo hash table succeeds if and only if the cuckoo graph for this set of values is a pseudoforest, a graph with at most one cycle in each of its connected components. Any vertex-induced subgraph with more edges than vertices corresponds to a set of keys for which there are an insufficient number of slots in the hash table. When the hash function is chosen randomly, the cuckoo graph is a random graph in the Erd\u0151s\u2013R\u00e9nyi model. With high probability, for a random graph in which the ratio of the number of edges to the number of vertices is bounded below 1/2, the graph is a pseudoforest and the cuckoo hashing algorithm succeeds in placing all keys. Moreover, the same theory also proves that the expected size of a connected component of the cuckoo graph is small, ensuring that each insertion takes constant expected time.[2]\nThe following hash functions are given:\n\n\n\n\nh\n\n(\nk\n)\n\n=\nk\n\nmod\n\n\n11\n\n\n{\\displaystyle h\\left(k\\right)=k\\mod 11}\n\n\n\n\n\n\n\nh\n\u2032\n\n\n(\nk\n)\n\n=\n\n\u230a\n\n\nk\n11\n\n\n\u230b\n\n\nmod\n\n\n11\n\n\n{\\displaystyle h'\\left(k\\right)=\\left\\lfloor {\\frac {k}{11}}\\right\\rfloor \\mod 11}\n\n\nColumns in the following two tables show the state of the hash tables over time as the elements are inserted.\nIf you now wish to insert the element 6, then you get into a cycle. In the last row of the table we find the same initial situation as at the beginning again.\n\n\n\n\nh\n\n(\n6\n)\n\n=\n6\n\nmod\n\n\n11\n=\n6\n\n\n{\\displaystyle h\\left(6\\right)=6\\mod 11=6}\n\n\n\n\n\n\n\nh\n\u2032\n\n\n(\n6\n)\n\n=\n\n\u230a\n\n\n6\n11\n\n\n\u230b\n\n\nmod\n\n\n11\n=\n0\n\n\n{\\displaystyle h'\\left(6\\right)=\\left\\lfloor {\\frac {6}{11}}\\right\\rfloor \\mod 11=0}\n\n\nSeveral variations of cuckoo hashing have been studied, primarily with the aim of improving its space usage by increasing the load factor that it can tolerate to a number greater than the 50% threshold of the basic algorithm. Some of these methods can also be used to reduce the failure rate of cuckoo hashing, causing rebuilds of the data structure to be much less frequent.\nGeneralizations of cuckoo hashing that use more than two alternative hash functions can be expected to utilize a larger part of the capacity of the hash table efficiently while sacrificing some lookup and insertion speed. Using just three hash functions increases the load to 91%.[3] Another generalization of cuckoo hashing, called blocked cuckoo hashing consists in using more than one key per bucket. Using just 2 keys per bucket permits a load factor above 80%.[4]\nAnother variation of cuckoo hashing that has been studied is cuckoo hashing with a stash. The stash, in this data structure, is an array of a constant number of keys, used to store keys that cannot successfully be inserted into the main hash table of the structure. This modification reduces the failure rate of cuckoo hashing to an inverse-polynomial function with an exponent that can be made arbitrarily large by increasing the stash size. However, larger stashes also mean slower searches for keys that are not present or are in the stash. A stash can be used in combination with more than two hash functions or with blocked cuckoo hashing to achieve both high load factors and small failure rates.[5] The analysis of cuckoo hashing with a stash extends to practical hash functions, not just to the random hash function model commonly used in theoretical analysis of hashing.[6]\nSome people recommend a simplified generalization of cuckoo hashing called skewed-associative cache in some CPU caches.[7]\nOther algorithms that use multiple hash functions include the Bloom filter, a memory-efficient data structure for inexact sets. An alternative data structure for the same inexact set problem, based on cuckoo hashing and called the cuckoo filter, uses even less memory and (unlike classical Bloom flters) allows element deletions as well as insertions and membership tests; however, its theoretical analysis is much less developed than the analysis of Bloom filters.[8]\nA study by Zukowski et al.[9] has shown that cuckoo hashing is much faster than chained hashing for small, cache-resident hash tables on modern processors. Kenneth Ross[10] has shown bucketized versions of cuckoo hashing (variants that use buckets that contain more than one key) to be faster than conventional methods also for large hash tables, when space utilization is high. The performance of the bucketized cuckoo hash table was investigated further by Askitis,[11] with its performance compared against alternative hashing schemes.\nA survey by Mitzenmacher[3] presents open problems related to cuckoo hashing as of 2009.", 
    "dbpedia_url": "http://dbpedia.org/resource/Cuckoo_hashing", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Cuckoo_hashing\n"
}