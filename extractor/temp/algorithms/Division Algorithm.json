{
    "about": "A division algorithm is an algorithm which, given two integers N and D, computes their quotient and/or remainder, the result of division. Some are applied by hand, while others are employed by digital circuit designs and software.", 
    "name": "Division Algorithm", 
    "classification": "Computer Arithmetic Algorithms", 
    "full_text": "A division algorithm is an algorithm which, given two integers N and D, computes their quotient and/or remainder, the result of division. Some are applied by hand, while others are employed by digital circuit designs and software.\nDivision algorithms fall into two main categories: slow division and fast division. Slow division algorithms produce one digit of the final quotient per iteration. Examples of slow division include restoring, non-performing restoring, non-restoring, and SRT division. Fast division methods start with a close approximation to the final quotient and produce twice as many digits of the final quotient on each iteration. Newton\u2013Raphson and Goldschmidt fall into this category.\nDiscussion will refer to the form \n\n\n\nN\n\n/\n\nD\n=\n(\nQ\n,\nR\n)\n\n\n{\\displaystyle N/D=(Q,R)}\n\n, where\nis the input, and\nis the output.\n\n\nThe simplest division algorithm, historically incorporated into a greatest common divisor algorithm presented in Euclid's Elements, Book VII, Proposition 1, finds the remainder given two positive integers using only subtractions and comparisons:\nThe proof that the quotient and remainder exist and are unique, ascertained by Euclidean division, gives rise to a complete division algorithm using additions, subtractions, and comparisons:\nThis procedure always produces R \u2265 0. Although very simple, it takes \u03a9(Q) steps, and so is exponentially slower than even slow division algorithms like long division. It is useful if Q is known to be small (being an output-sensitive algorithm), and can serve as an executable specification.\nLong division is the standard algorithm used for pen-and-paper division of multidigit numbers expressed in decimal notation. It shifts gradually from the left to the right end of the dividend, subtracting the largest possible multiple of the divisor at each stage; the multiples become the digits of the quotient, and the final difference is the remainder. When used with a binary radix, it forms the basis for the integer division (unsigned) with remainder algorithm below. Short division is an abbreviated form of long division suitable for one-digit divisors. Chunking (also known as the partial quotients method or the hangman method) is a less-efficient form of long division which may be easier to understand.\nThe following algorithm, the binary version of the famous long division, will divide N by D, placing the quotient in Q and the remainder in R. All values are treated as unsigned integers.[citation needed]\nIf we take N=11002 (1210) and D=1002 (410)\nStep 1: Set R=0 and Q=0\nStep 2: Take i=3 (one less than the number of bits in N)\nStep 3: R=00 (left shifted by 1)\nStep 4: R=01 (setting R(0) to N(i))\nStep 5: R<D, so skip statement\nStep 2: Set i=2\nStep 3: R=010\nStep 4: R=011\nStep 5: R<D, statement skipped\nStep 2: Set i=1\nStep 3: R=0110\nStep 4: R=0110\nStep 5: R>=D, statement entered\nStep 5b: R=10 (R\u2212D)\nStep 5c: Q=10 (setting Q(i) to 1)\nStep 2: Set i=0\nStep 3: R=100\nStep 4: R=100\nStep 5: R>=D, statement entered\nStep 5b: R=0 (R\u2212D)\nStep 5c: Q=11 (setting Q(i) to 1)\nend\nQ=112 (310) and R=0.\nSlow division methods are all based on a standard recurrence equation\nwhere:\nRestoring division operates on fixed-point fractional numbers and depends on the following assumptions:[citation needed]\nThe quotient digits q are formed from the digit set {0,1}.\nThe basic algorithm for binary (radix 2) restoring division is:\nThe above restoring division algorithm can avoid the restoring step by saving the shifted value 2P before the subtraction in an additional register T (i.e., T =\u00a0P\u00a0<<\u00a01) and copying register T to P when the result of the subtraction 2P\u00a0\u2212\u00a0D is negative.\nNon-performing restoring division is similar to restoring division except that the value of 2*P[i] is saved, so D does not need to be added back in for the case of TP[i] \u2264 0.\nNon-restoring division uses the digit set {\u22121,1} for the quotient digits instead of {0,1}. The algorithm is more complex, but has the advantage when implemented in hardware that there is only one decision and addition/subtraction per quotient bit; there is no restoring step after the subtraction. This lets it be executed faster. The basic algorithm for binary (radix 2) non-restoring division of non-negative numbers is:\nFollowing this algorithm, the quotient is in a non-standard form consisting of digits of \u22121 and +1. This form needs to be converted to binary to form the final quotient. Example:\nIf the \u22121 digits of \n\n\n\nQ\n\n\n{\\displaystyle Q}\n\n are stored as zeros (0) as is common, then \n\n\n\nP\n\n\n{\\displaystyle P}\n\n is \n\n\n\nQ\n\n\n{\\displaystyle Q}\n\n and computing \n\n\n\nN\n\n\n{\\displaystyle N}\n\n is trivial: perform a bit-complement on the original \n\n\n\nQ\n\n\n{\\displaystyle Q}\n\n.\nFinally, quotients computed by this algorithm are always odd, and the remainder in P is in the range \u2212D < P < D. For example, 5 / 2 = 3 R \u22121. To convert to a positive remainder, do a single restoring step after Q is converted from non-standard form to standard form:\nThe actual remainder is P >> n. (As with restoring division, the low-order bits of P are used up at the same rate as bits of the quotient Q are produced, and it is common to use a single shift register for both.)\nNamed for its creators (Sweeney, Robertson, and Tocher), SRT division is a popular method for division in many microprocessor implementations.[1][2] SRT division is similar to non-restoring division, but it uses a lookup table based on the dividend and the divisor to determine each quotient digit. The Intel Pentium processor's infamous floating-point division bug was caused by an incorrectly coded lookup table. Five of the 1066 entries had been mistakenly omitted.[3][4]\nNewton\u2013Raphson uses Newton's method to find the reciprocal of \n\n\n\nD\n\n\n{\\displaystyle D}\n\n and multiply that reciprocal by \n\n\n\nN\n\n\n{\\displaystyle N}\n\n to find the final quotient \n\n\n\nQ\n\n\n{\\displaystyle Q}\n\n.\nThe steps of Newton\u2013Raphson division are:\nIn order to apply Newton's method to find the reciprocal of \n\n\n\nD\n\n\n{\\displaystyle D}\n\n, it is necessary to find a function \n\n\n\nf\n(\nX\n)\n\n\n{\\displaystyle f(X)}\n\n that has a zero at \n\n\n\nX\n=\n1\n\n/\n\nD\n\n\n{\\displaystyle X=1/D}\n\n. The obvious such function is \n\n\n\nf\n(\nX\n)\n=\nD\nX\n\u2212\n1\n\n\n{\\displaystyle f(X)=DX-1}\n\n, but the Newton\u2013Raphson iteration for this is unhelpful, since it cannot be computed without already knowing the reciprocal of \n\n\n\nD\n\n\n{\\displaystyle D}\n\n. Moreover, multiple iterations for refining reciprocal are not possible, since higher-order derivatives do not exist for \n\n\n\nf\n(\nX\n)\n\n\n{\\displaystyle f(X)}\n\n. A function that does work is \n\n\n\nf\n(\nX\n)\n=\n(\n1\n\n/\n\nX\n)\n\u2212\nD\n\n\n{\\displaystyle f(X)=(1/X)-D}\n\n, for which the Newton\u2013Raphson iteration gives\nwhich can be calculated from \n\n\n\n\nX\n\ni\n\n\n\n\n{\\displaystyle X_{i}}\n\n using only multiplication and subtraction, or using two fused multiply\u2013adds.\nFrom a computation point of view, the expressions \n\n\n\n\nX\n\ni\n+\n1\n\n\n=\n\nX\n\ni\n\n\n+\n\nX\n\ni\n\n\n(\n1\n\u2212\nD\n\nX\n\ni\n\n\n)\n\n\n{\\displaystyle X_{i+1}=X_{i}+X_{i}(1-DX_{i})}\n\n and \n\n\n\n\nX\n\ni\n+\n1\n\n\n=\n\nX\n\ni\n\n\n(\n2\n\u2212\nD\n\nX\n\ni\n\n\n)\n\n\n{\\displaystyle X_{i+1}=X_{i}(2-DX_{i})}\n\n are not equivalent. To obtain a result with a precision of n bits while making use of the second expression, one must compute the product between \n\n\n\n\nX\n\ni\n\n\n\n\n{\\displaystyle X_{i}}\n\n and \n\n\n\n(\n2\n\u2212\nD\n\nX\n\ni\n\n\n)\n\n\n{\\displaystyle (2-DX_{i})}\n\n with double the required precision (2n bits).[citation needed] In contrast, the product between \n\n\n\n\nX\n\ni\n\n\n\n\n{\\displaystyle X_{i}}\n\n and \n\n\n\n(\n1\n\u2212\nD\n\nX\n\ni\n\n\n)\n\n\n{\\displaystyle (1-DX_{i})}\n\n need only be computed with a precision of n bits.[why?]\nIf the error is defined as \n\n\n\n\n\u03f5\n\ni\n\n\n=\nD\n\nX\n\ni\n\n\n\u2212\n1\n\n\n{\\displaystyle \\epsilon _{i}=DX_{i}-1}\n\n, then:\nThis squaring of the error at each iteration step \u2014 the so-called quadratic convergence of Newton\u2013Raphson's method \u2014 has the effect that the number of correct digits in the result roughly doubles for every iteration, a property that becomes extremely valuable when the numbers involved have many digits (e.g. in the large integer domain). But it also means that the initial convergence of the method can be comparatively slow, especially if the initial estimate \n\n\n\n\nX\n\n0\n\n\n\n\n{\\displaystyle X_{0}}\n\n is poorly chosen.\nApply a bit-shift to the divisor D to scale it so that 0.5\u00a0\u2264\u00a0D\u00a0\u2264\u00a01. The same bit-shift should be applied to the numerator N so that the quotient does not change. Then one could use a linear approximation in the form\nto initialize Newton\u2013Raphson. To minimize the maximum of the relative error of this approximation on interval \n\n\n\n[\n0.5\n,\n1\n]\n\n\n{\\displaystyle [0.5,1]}\n\n, one should use\nThe coefficients of the linear approximation are determined as follows. The relative error is \n\n\n\n\n|\n\n(\n\nT\n\n1\n\n\n+\n\nT\n\n2\n\n\nD\n\u2212\n1\n\n/\n\nD\n)\n\n/\n\n(\n1\n\n/\n\nD\n)\n\n|\n\n=\n\n|\n\nD\n(\n\nT\n\n1\n\n\n+\n\nT\n\n2\n\n\nD\n)\n\u2212\n1\n\n|\n\n\n\n{\\displaystyle |(T_{1}+T_{2}D-1/D)/(1/D)|=|D(T_{1}+T_{2}D)-1|}\n\n. The minimum of the maximum relative error is determined by the Chebyshev equioscillation theorem applied to \n\n\n\nF\n(\nD\n)\n=\nD\n(\n\nT\n\n1\n\n\n+\n\nT\n\n2\n\n\nD\n)\n\u2212\n1\n\n\n{\\displaystyle F(D)=D(T_{1}+T_{2}D)-1}\n\n. The local extremum of \n\n\n\nF\n(\nD\n)\n\n\n{\\displaystyle F(D)}\n\n occurs when \n\n\n\n\nF\n\u2032\n\n(\nD\n)\n=\n0\n\n\n{\\displaystyle F'(D)=0}\n\n, which has solution \n\n\n\nD\n=\n\u2212\n\nT\n\n1\n\n\n\n/\n\n(\n2\n\nT\n\n2\n\n\n)\n\n\n{\\displaystyle D=-T_{1}/(2T_{2})}\n\n. The function at the extremum must be of opposite sign as the function at the endpoints, namely, \n\n\n\nF\n(\n1\n\n/\n\n2\n)\n=\nF\n(\n1\n)\n=\n\u2212\nF\n(\n\u2212\n\nT\n\n1\n\n\n\n/\n\n(\n2\n\nT\n\n2\n\n\n)\n)\n\n\n{\\displaystyle F(1/2)=F(1)=-F(-T_{1}/(2T_{2}))}\n\n. The two equations in the two unknowns have solution \n\n\n\n\nT\n\n1\n\n\n=\n48\n\n/\n\n17\n\n\n{\\displaystyle T_{1}=48/17}\n\n and \n\n\n\n\nT\n\n2\n\n\n=\n\u2212\n32\n\n/\n\n17\n\n\n{\\displaystyle T_{2}=-32/17}\n\n, and the maximum relative error is \n\n\n\nF\n(\n1\n)\n=\n1\n\n/\n\n17\n\n\n{\\displaystyle F(1)=1/17}\n\n. Using this approximation, the relative error of the initial value is less than\nIt is possible to generate a polynomial fit of degree larger than 1, computing the coefficients using the Remez algorithm. The trade-off is that the initial guess requires more computational cycles but hopefully in exchange for fewer iterations of Newton\u2013Raphson.\nSince for this method the convergence is exactly quadratic, it follows that\nsteps are enough to calculate the value up to \n\n\n\nP\n\n\n\n{\\displaystyle P\\,}\n\n binary places. This evaluates to 3 for IEEE single precision and 4 for both double precision and double extended formats.\nThe following computes the quotient of N and D with a precision of P binary places:\nFor example, for a double-precision floating-point division, this method uses 10 multiplies, 9 adds, and 2 shifts.\nGoldschmidt (after Robert Elliott Goldschmidt)[5] division uses an iterative process of repeatedly multiplying both the dividend and divisor by a common factor Fi, chosen such that the divisor converges to 1. This causes the dividend to converge to the sought quotient Q:\nThe steps for Goldschmidt division are:\nAssuming N/D has been scaled so that 0\u00a0<\u00a0D\u00a0<\u00a01, each Fi is based on D:\nMultiplying the dividend and divisor by the factor yields:\nAfter a sufficient number k of iterations \n\n\n\nQ\n=\n\nN\n\nk\n\n\n\n\n{\\displaystyle Q=N_{k}}\n\n.\nThe Goldschmidt method is used in AMD Athlon CPUs and later models.[6][7]\nThe Goldschmidt method can be used with factors that allow simplifications by the binomial theorem. Assuming N/D has been scaled by a power of two such that \n\n\n\nD\n\u2208\n(\n\n\n\n1\n2\n\n\n\n,\n1\n]\n\n\n{\\displaystyle D\\in ({\\tfrac {1}{2}},1]}\n\n. We choose \n\n\n\nD\n=\n1\n\u2212\nx\n\n\n{\\displaystyle D=1-x}\n\n and \n\n\n\n\nF\n\ni\n\n\n=\n1\n+\n\nx\n\n\n2\n\ni\n\n\n\n\n\n\n{\\displaystyle F_{i}=1+x^{2^{i}}}\n\n. This yields\nAfter \n\n\n\nn\n\n\n{\\displaystyle n}\n\n steps \n\n\n\n(\nx\n\u2208\n[\n0\n,\n\n\n\n1\n2\n\n\n\n)\n)\n\n\n{\\displaystyle (x\\in [0,{\\tfrac {1}{2}}))}\n\n, the denominator \n\n\n\n1\n\u2212\n\nx\n\n\n2\n\nn\n\n\n\n\n\n\n{\\displaystyle 1-x^{2^{n}}}\n\n can be rounded to \n\n\n\n1\n\n\n{\\displaystyle 1}\n\n with a relative error\nwhich is maximum at \n\n\n\n\n2\n\n\u2212\n\n2\n\nn\n\n\n\n\n\n\n{\\displaystyle 2^{-2^{n}}}\n\n when \n\n\n\nx\n=\n\n\n1\n2\n\n\n\n\n{\\displaystyle x={1 \\over 2}}\n\n, thus providing a minimum precision of \n\n\n\n\n2\n\nn\n\n\n\n\n{\\displaystyle 2^{n}}\n\n binary digits.\nMethods designed for hardware implementation generally do not scale to integers with thousands or millions of decimal digits; these frequently occur, for example, in modular reductions in cryptography. For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, Toom\u2013Cook multiplication or the Sch\u00f6nhage\u2013Strassen algorithm. It results that the computational complexity of the division is of the same order (up to a multiplicative constant) as that of the multiplication. Examples include reduction to multiplication by Newton's method as described above,[8] as well as the slightly faster Barrett reduction algorithm.[9][verification needed] Newton's method is particularly efficient in scenarios where one must divide by the same divisor many times, since after the initial Newton inversion only one (truncated) multiplication is needed for each division.\nThe division by a constant D is equivalent to the multiplication by its reciprocal. Since the denominator is constant, so is its reciprocal (1/D). Thus it is possible to compute the value of (1/D) once at compile time, and at run time perform the multiplication N\u00b7(1/D) rather than the division N/D. In floating-point arithmetic the use of (1/D) presents little problem, but in integer arithmetic the reciprocal will always evaluate to zero (assuming |D| > 1).\nIt is not necessary to use specifically (1/D); any value (X/Y) that reduces to (1/D) may be used. For example, for division by 3, the factors 1/3, 2/6, 3/9, or 194/582 could be used. Consequently, if Y were a power of two so the division step reduces to a fast right bit shift. The effect of calculating N/D as (N\u00b7X)/Y replaces a division with a multiply and a shift. Note that the parentheses are important, as N\u00b7(X/Y) will evaluate to zero.\nHowever, unless D itself is a power of two, there is no X and Y that satisfies the conditions above. Fortunately, (N\u00b7X)/Y gives exactly the same result as N/D in integer arithmetic even when (X/Y) is not exactly equal to 1/D, but \"close enough\" that the error introduced by the approximation is in the bits that are discarded by the shift operation.[10][11][12]\nAs a concrete fixed-point arithmetic example, for 32-bit unsigned integers, division by 3 can be replaced with a multiply by 2863311531\u2009\u2044\u2009233, a multiplication by 2863311531 (hexadecimal 0xAAAAAAAB) followed by a 33 right bit shift. The value of 2863311531 is calculated as 233\u2009\u2044\u20093, then rounded up.\nLikewise, division by 10 can be expressed as a multiplication by 3435973837 (0xCCCCCCCD) followed by division by 235 (or 35 right bit shift).\nIn some cases, division by a constant can be accomplished in even less time by converting the \"multiply by a constant\" into a series of shifts and adds or subtracts.[13] Of particular interest is division by 10, for which the exact quotient is obtained, with remainder if required.[14]\nRound-off error can be introduced by division operations due to limited precision.", 
    "dbpedia_url": "http://dbpedia.org/resource/Division_algorithm", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Division_algorithm\n"
}