{
    "about": "A Savitzky\u2013Golay filter is a digital filter that can be applied to a set of digital data points for the purpose of smoothing the data, that is, to increase the signal-to-noise ratio without greatly distorting the signal. This is achieved, in a process known as convolution, by fitting successive sub-sets of adjacent data points with a low-degree polynomial by the method of linear least squares. When the data points are equally spaced, an analytical solution to the least-squares equations can be found, in the form of a single set of \"convolution coefficients\" that can be applied to all data sub-sets, to give estimates of the smoothed signal, (or derivatives of the smoothed signal) at the central point of each sub-set. The method, based on established mathematical procedures,[1][2] was popularized by Abraham Savitzky and Marcel J. E. Golay who published tables of convolution coefficients for various polynomials and sub-set sizes in 1964.[3][4] Some errors in the tables have been corrected.[5] The method has been extended for the treatment of 2- and 3-dimensional data.", 
    "name": "Numerical Smoothing And Differentiation", 
    "classification": "Numerical Analysis", 
    "full_text": "A Savitzky\u2013Golay filter is a digital filter that can be applied to a set of digital data points for the purpose of smoothing the data, that is, to increase the signal-to-noise ratio without greatly distorting the signal. This is achieved, in a process known as convolution, by fitting successive sub-sets of adjacent data points with a low-degree polynomial by the method of linear least squares. When the data points are equally spaced, an analytical solution to the least-squares equations can be found, in the form of a single set of \"convolution coefficients\" that can be applied to all data sub-sets, to give estimates of the smoothed signal, (or derivatives of the smoothed signal) at the central point of each sub-set. The method, based on established mathematical procedures,[1][2] was popularized by Abraham Savitzky and Marcel J. E. Golay who published tables of convolution coefficients for various polynomials and sub-set sizes in 1964.[3][4] Some errors in the tables have been corrected.[5] The method has been extended for the treatment of 2- and 3-dimensional data.\nSavitzky and Golay's paper is one of the most widely cited papers in the journal Analytical Chemistry[6] and is classed by that journal as one of its \"10 seminal papers\" saying \"it can be argued that the dawn of the computer-controlled analytical instrument can be traced to this article\".[7]\n\n\nThe data consists of a set of n {xj, yj} points (j = 1, ..., n), where x is an independent variable and yj is an observed value. They are treated with a set of m convolution coefficients, Ci, according to the expression\nIt is easy to apply this formula in a spreadsheet. Selected convolution coefficients are shown in the tables, below. For example, for smoothing by a 5-point quadratic polynomial, m = 5, i = \u22122, \u22121, 0, 1, 2 and the jth smoothed data point, Yj, is given by\nwhere, C\u22122 = \u22123/35, C\u22121 = 12 / 35, etc. There are numerous applications of smoothing, which is performed primarily to make the data appear to be less noisy than it really is. The following are applications of numerical differentiation of data.[8] Note When calculating the nth. derivative an additional scaling factor of \n\n\n\n\n\n\nn\n!\n\n\nh\n\nn\n\n\n\n\n\n\n{\\displaystyle {\\frac {n!}{h^{n}}}}\n\n may be applied to all calculated data points to obtain absolute values (see expressions for \n\n\n\n\n\n\n\nd\n\nn\n\n\nY\n\n\nd\n\nx\n\nn\n\n\n\n\n\n\n\n{\\displaystyle {\\frac {d^{n}Y}{dx^{n}}}}\n\n, below, for details).\nA moving average filter is commonly used with time series data to smooth out short-term fluctuations and highlight longer-term trends or cycles. It is often used in technical analysis of financial data, like stock prices, returns or trading volumes. It is also used in economics to examine gross domestic product, employment or other macroeconomic time series.\nAn unweighted moving average filter is the simplest convolution filter. Each subset of the data set is fitted by a straight line. It was not included in the Savitzsky-Golay tables of convolution coefficients as all the coefficient values are simply equal to 1/m.\nWhen the data points are equally spaced, an analytical solution to the least-squares equations can be found.[2] This solution forms the basis of the convolution method of numerical smoothing and differentiation. Suppose that the data consists of a set of n points (xj, yj) (j = 1, ..., n), where x is an independent variable and yj is a datum value. A polynomial will be fitted by linear least squares to a set of m (an odd number) adjacent data points, each separated by an interval h. Firstly, a change of variable is made\nwhere \n\n\n\n\n\n\nx\n\u00af\n\n\n\n\n\n{\\displaystyle {\\bar {x}}}\n\n is the value of the central point. z takes the values \n\n\n\n\n\n\n\n1\n\u2212\nm\n\n2\n\n\n\n,\n\u22ef\n,\n0\n,\n\u22ef\n,\n\n\n\n\nm\n\u2212\n1\n\n2\n\n\n\n\n\n{\\displaystyle {\\tfrac {1-m}{2}},\\cdots ,0,\\cdots ,{\\tfrac {m-1}{2}}}\n\n (e.g. m = 5 \u2192 z = \u22122, \u22121, 0, 1, 2).[note 1] The polynomial, of degree k is defined as\nThe coefficients a0, a1 etc. are obtained by solving the normal equations (bold a represents a vector, bold J represents a matrix).\nThe \n\n\n\ni\n\n\n{\\displaystyle i}\n\n-th row of \n\n\n\n\nJ\n\n\n\n{\\displaystyle \\mathbf {J} }\n\n has values \n\n\n\n1\n,\n\nz\n\ni\n\n\n,\n\nz\n\ni\n\n\n2\n\n\n,\n\u2026\n\n\n{\\displaystyle 1,z_{i},z_{i}^{2},\\dots }\n\n .\nFor example, for a cubic polynomial fitted to 5 points, z= \u22122, \u22121, 0, 1, 2 the normal equations are solved as follows.\nNow, the normal equations can be factored into two separate sets of equations, by rearranging rows and columns, with\nExpressions for the inverse of each of these matrices can be obtained using Cramer's rule\nThe normal equations become\nand\nMultiplying out and removing common factors,\nThe coefficients of y in these expressions are known as convolution coefficients. They are elements of the matrix\nIn general,\nIn matrix notation this example is written as\nTables of convolution coefficients, calculated in the same way for m up to 25, were published for the Savitzky\u2013Golay smoothing filter in 1964,[3][5] The value of the central point, z = 0, is obtained from a single set of coefficients, a0 for smoothing, a1 for 1st. derivative etc. The numerical derivatives are obtained by differentiating Y. This means that the derivatives are calculated for the smoothed data curve. For a cubic polynomial\nIn general, polynomials of degree (0 and 1),[note 3] (2 and 3), (4 and 5) etc. give the same coefficients for smoothing and even derivatives. Polynomials of degree (1 and 2), (3 and 4) etc. give the same coefficients for odd derivatives.\nIt is not necessary always to use the Savitzky\u2013Golay tables. The summations in the matrix JTJ can be evaluated in closed form,\nso that algebraic formulae can be derived for the convolution coefficients.[13][note 4] Functions that are suitable for use with a curve that has an inflection point are:\n\n\n\nSimpler expressions that can be used with curves that don't have an inflection point are:\nHigher derivatives can be obtained. For example, a fourth derivative can be obtained by performing two passes of a second derivative function.[14]\nAn alternative to fitting m data points by a simple polynomial in the subsidiary variable, z, is to use orthogonal polynomials.\nwhere P0 .. Pk is a set of mutually orthogonal polynomials of degree 0 .. k. Full details on how to obtain expressions for the orthogonal polynomials and the relationship between the coefficients b and a are given by Guest.[2] Expressions for the convolution coefficients are easily obtained because the normal equations matrix, JTJ, is a diagonal matrix as the product of any two orthogonal polynomials is zero by virtue of their mutual orthogonality. Therefore, each non-zero element of its inverse is simply the reciprocal the corresponding element in the normal equation matrix. The calculation is further simplified by using recursion to build orthogonal Gram polynomials. The whole calculation can be coded in a few lines of PASCAL, a computer language well-adapted for calculations involving recursion.[15]\nSavitzky\u2013Golay filters are most commonly used to obtain the smoothed or derivative value at the central point, z = 0, using a single set of convolution coefficients. (m\u00a0\u2212\u00a01)/2 points at the start and end of the series cannot be calculated using this process. Various strategies can be employed to avoid this inconvenience.\nIt is implicit in the above treatment that the data points are all given equal weight. Technically, the objective function\nbeing minimized in the least-squares process has unit weights, wi=1. When weights are not all the same the normal equations become\nIf the same set of diagonal weights is used for all data subsets, W = diag(w1,w2,...wm), an analytical solution to the normal equations can be written down. For example, with a quadratic polynomial,\nAn explicit expression for the inverse of this matrix can be obtained using Cramer's rule. A set of convolution coefficients may then be derived as\nAlternatively the coefficients, C, could be calculated in a spreadsheet, employing a built-in matrix inversion routine to obtain the inverse of the normal equations matrix. This set of coefficients, once calculated and stored, can be used with all calculations in which the same weighting scheme applies. A different set of coefficients is needed for each different weighting scheme.\nTwo-dimensional smoothing and differentiation can also be applied to tables of data values, such as intensity values in a photographic image which is composed of a rectangular grid of pixels.[16] [17] The trick is to transform part of the table into a row by a simple ordering of the indices of the pixels. Whereas the one-dimensional filter coefficients are found by fitting a polynomial in the subsidiary variable, z to a set of m data points, the two-dimensional coefficients are found by fitting a polynomial in subsidiary variables v and w to a set of m \u00d7 m data points. The following example, for a bicubic polynomial and m = 5, illustrates the process, which parallels the process for the one dimensional case, above.[18]\nThe square of 25 data values, d1\u00a0\u2212\u00a0d25\nbecomes a vector when the rows are placed one after another.\nThe Jacobian has 10 columns, one for each of the parameters a00\u00a0\u2212\u00a0a03 and 25 rows, one for each pair of v and w values. Each row has the form\nThe convolution coefficients are calculated as\nThe first row of C contains 25 convolution coefficients which can be multiplied with the 25 data values to provide a smoothed value for the central data point (13) of the 25.\nA Matlab[19] routine for computing the coefficients is available. 3-dimensional filters can be obtained with a similar procedure.[16][20]\nIt is inevitable that the signal will be distorted in the convolution process. From property 3 above, when data which has a peak is smoothed the peak height will be reduced and the half-width will be increased. Both the extent of the distortion and S/N (signal-to-noise ratio) improvement:\nFor example, If the noise in all data points is uncorrelated and has a constant standard deviation, \u03c3, the standard deviation on the noise will be decreased by convolution with an m-point smoothing function to[22][note 5]\nThese functions are shown in the plot at the right. For example, with a 9-point linear function (moving average) two thirds of the noise is removed and with a 9-point quadratic/cubic smoothing function only about half the noise is removed. Most of the noise remaining is low-frequency noise(see Frequency characteristics of convolution filters, below).\nAlthough the moving average function gives the best noise reduction it is unsuitable for smoothing data which has curvature over m points. A quadratic filter function is unsuitable for getting a derivative of a data curve with an inflection point because a quadratic polynomial does not have one. The optimal choice of polynomial order and number of convolution coefficients will be a compromise between noise reduction and distortion.[24]\nOne way to mitigate distortion and improve noise removal is to use a filter of smaller width and perform more than one convolution with it. For two passes of the same filter this is equivalent to one pass of a filter obtained by convolution of the original filter with itself.[25] For example, 2 passes of the filter with coefficients (1/3, 1/3, 1/3) is equivalent to 1 pass of the filter with coefficients (1/9, 2/9, 3/9, 2/9, 1/9).\nThe disadvantage of multipassing is that the equivalent filter width for n passes of an m-point function is n(m \u2212 1) + 1 so multipassing is subject to greater end-effects. Nevertheless, multipassing has been used to great advantage. For instance, some 40\u201380 passes on data with a signal-to-noise ratio of only 5 gave useful results.[26] The noise reduction formulae given above do not apply because correlation between calculated data points increases with each pass.\nConvolution maps to multiplication in the Fourier co-domain. The discrete Fourier transform of a convolution filter is a real-valued function which can be represented as\n\u03b8 runs from 0 to 180 degrees, after which the function merely repeats itself. The plot for a 9-point quadratic/cubic smoothing function is typical. At very low angle, the plot is almost flat, meaning that low-frequency components of the data will be virtually unchanged by the smoothing operation. As the angle increases the value decreases so that higher frequency components are more and more attenuated. This shows that the convolution filter can be described as a low-pass filter: the noise that is removed is primarily high-frequency noise and low-frequency noise passes through the filter.[27] Some high-frequency noise components are attenuated more than others, as shown by undulations in the Fourier transform at large angles. This can give rise to small oscillations in the smoothed data.[28]\nConvolution affects the correlation between errors in the data. The effect of convolution can be expressed as a linear transformation.\nBy the law of error propagation, the variance-covariance matrix of the data, A will be transformed into B according to\nTo see how this applies in practice, consider the effect of a 3-point moving average on the first three calculated points, Y2\u00a0\u2212\u00a0Y4, assuming that the data points have equal variance and that there is no correlation between them. A will be an identity matrix multiplied by a constant, \u03c32, the variance at each point.\nIn this case the correlation coefficients,\nbetween calculated points i and j will be\nIn general, the calculated values are correlated even when the observed values are not correlated. The correlation extends over m\u00a0\u2212\u00a01 calculated points at a time.[29]\nTo illustrate the effect of multipassing on the noise and correlation of a set of data, consider the effects of a second pass of a 3-point moving average filter. For the second pass[note 6]\nAfter two passes, the standard deviation of the central point has decreased to \n\n\n\n\n\n\n\n19\n81\n\n\n\n\n\u03c3\n=\n0.48\n\u03c3\n\n\n{\\displaystyle {\\sqrt {\\tfrac {19}{81}}}\\sigma =0.48\\sigma }\n\n, compared to 0.58\u03c3 for one pass. The noise reduction is a little less than would be obtained with one pass of a 5-point moving average which, under the same conditions, would result in the smoothed points having the smaller standard deviation of 0.45\u03c3.\nCorrelation now extends over a span of 4 sequential points with correlation coefficients\nThe advantage obtained by performing two passes with the narrower smoothing function is that it introduces less distortion into the calculated data.\nConsider a set of data points \n\n\n\n(\n\nx\n\nj\n\n\n,\n\ny\n\nj\n\n\n\n)\n\n1\n\u2264\nj\n\u2264\nn\n\n\n\n\n{\\displaystyle (x_{j},y_{j})_{1\\leq j\\leq n}}\n\n. The Savitzky\u2013Golay tables refer to the case that the step \n\n\n\n\nx\n\nj\n\n\n\u2212\n\nx\n\nj\n\u2212\n1\n\n\n\n\n{\\displaystyle x_{j}-x_{j-1}}\n\n is constant, h. Examples of the use of the so-called convolution coefficients, with a cubic polynomial and a window size, m, of 5 points are as follows.\nSelected values of the convolution coefficients for polynomials of degree 1,2,3, 4 and 5 are given in the following tables. The values were calculated using the PASCAL code provided in Gorry.[15]", 
    "dbpedia_url": "http://dbpedia.org/resource/Numerical_smoothing_and_differentiation", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Numerical_smoothing_and_differentiation\n"
}