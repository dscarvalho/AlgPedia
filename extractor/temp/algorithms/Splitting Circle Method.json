{
    "about": "In mathematics, the splitting circle method is a numerical algorithm for the numerical factorization of a polynomial and, ultimately, for finding its complex roots. It was introduced by Arnold Sch\u00f6nhage in his 1982 paper The fundamental theorem of algebra in terms of computational complexity (Technical report, Mathematisches Institut der Universit\u00e4t T\u00fcbingen). A revised algorithm was presented by Victor Pan in 1998. An implementation was provided by Xavier Gourdon in 1996 for the Magma and PARI/GP computer algebra systems.", 
    "name": "Splitting Circle Method", 
    "classification": "Root-Finding Algorithms", 
    "full_text": "In mathematics, the splitting circle method is a numerical algorithm for the numerical factorization of a polynomial and, ultimately, for finding its complex roots. It was introduced by Arnold Sch\u00f6nhage in his 1982 paper The fundamental theorem of algebra in terms of computational complexity (Technical report, Mathematisches Institut der Universit\u00e4t T\u00fcbingen). A revised algorithm was presented by Victor Pan in 1998. An implementation was provided by Xavier Gourdon in 1996 for the Magma and PARI/GP computer algebra systems.\n\n\nThe fundamental idea of the splitting circle method is to use methods of complex analysis, more precisely the residue theorem, to construct factors of polynomials. With those methods it is possible to construct a factor of a given polynomial \n\n\n\np\n(\nx\n)\n=\n\nx\n\nn\n\n\n+\n\np\n\nn\n\u2212\n1\n\n\n\nx\n\nn\n\u2212\n1\n\n\n+\n\u22ef\n+\n\np\n\n0\n\n\n\n\n{\\displaystyle p(x)=x^{n}+p_{n-1}x^{n-1}+\\cdots +p_{0}}\n\n for any region of the complex plane with a piecewise smooth boundary. Most of those factors will be trivial, that is constant polynomials. Only regions that contain roots of p(x) result in nontrivial factors that have exactly those roots of p(x) as their own roots, preserving multiplicity.\nIn the numerical realization of this method one uses disks D(c,r) (center c, radius r) in the complex plane as regions. The boundary circle of a disk splits the set of roots of p(x) in two parts, hence the name of the method. To a given disk one computes approximate factors following the analytical theory and refines them using Newton's method. To avoid numerical instability one has to demand that all roots are well separated from the boundary circle of the disk. So to obtain a good splitting circle it should be embedded in a root free annulus A(c,r,R) (center c, inner radius r, outer radius R) with a large relative width R/r.\nRepeating this process for the factors found, one finally arrives at an approximative factorization of the polynomial at a required precision. The factors are either linear polynomials representing well isolated zeros or higher order polynomials representing clusters of zeros.\nNewton's identities are a bijective relation between the elementary symmetric polynomials of a tuple of complex numbers and its sums of powers. Therefore, it is possible to compute the coefficients of a polynomial\n(or of a factor of it) from the sums of powers of its zeros\nby solving the triangular system that is obtained by comparing the powers of u in the following identity of formal power series\nIf \n\n\n\nG\n\u2282\n\nC\n\n\n\n{\\displaystyle G\\subset \\mathbb {C} }\n\n is a domain with piecewise smooth boundary C and if the zeros of p(x) are pairwise distinct and not on the boundary C, then from the residue theorem of residual calculus one gets\nThe identity of the left to the right side of this equation also holds for zeros with multiplicities. By using the Newton identities one is able to compute from those sums of powers the factor\nof p(x) corresponding to the zeros of p(x) inside G. By polynomial division one also obtains the second factor g(x) in p(x) = f(x)g(x).\nThe commonly used regions are circles in the complex plane. Each circle gives raise to a split of the polynomial p(x) in factors f(x) and g(x). Repeating this procedure on the factors using different circles yields finer and finer factorizations. This recursion stops after a finite number of proper splits with all factors being nontrivial powers of linear polynomials.\nThe challenge now consists in the conversion of this analytical procedure into a numerical algorithm with good running time. The integration is approximated by a finite sum of a numerical integration method, making use of the fast Fourier transform for the evaluation of the polynomials p(x) and p'(x). The polynomial f(x) that results will only be an approximate factor. To ensure that its zeros are close to the zeros of p inside G and only to those, one must demand that all zeros of p are far away from the boundary C of the region G.\n(Sch\u00f6nhage 1982) Let \n\n\n\np\n\u2208\n\nC\n\n[\nX\n]\n\n\n{\\displaystyle p\\in \\mathbb {C} [X]}\n\n be a polynomial of degree n has k zeros inside the circle of radius 1/2 and the remaining n-k zeros outside the circle of radius 2. With N=O(k) large enough, the approximation of the contour integrals using N points results in an approximation \n\n\n\n\nf\n\n0\n\n\n\n\n{\\displaystyle f_{0}}\n\n of the factor f with error\nwhere the norm of a polynomial is the sum of the moduli of its coefficients.\nSince the zeros of a polynomial are continuous in its coefficients, one can make the zeros of \n\n\n\n\nf\n\n0\n\n\n\n\n{\\displaystyle f_{0}}\n\n as close as wanted to the zeros of f by choosing N large enough. However, one can improve this approximation faster using a Newton method. Division of p with remainder yields an approximation \n\n\n\n\ng\n\n0\n\n\n\n\n{\\displaystyle g_{0}}\n\n of the remaining factor g. Now\nso discarding the last second order term one has to solve \n\n\n\np\n\u2212\n\nf\n\n0\n\n\n\ng\n\n0\n\n\n=\n\nf\n\n0\n\n\n\u0394\ng\n+\n\ng\n\n0\n\n\n\u0394\nf\n\n\n{\\displaystyle p-f_{0}g_{0}=f_{0}\\Delta g+g_{0}\\Delta f}\n\n using any variant of the extended Euclidean algorithm to obtain the incremented approximations \n\n\n\n\nf\n\n1\n\n\n=\n\nf\n\n0\n\n\n+\n\u0394\nf\n\n\n{\\displaystyle f_{1}=f_{0}+\\Delta f}\n\n and \n\n\n\n\ng\n\n1\n\n\n=\n\ng\n\n0\n\n\n+\n\u0394\ng\n\n\n{\\displaystyle g_{1}=g_{0}+\\Delta g}\n\n. This is repeated until the increments are zero relative to the chosen precision.\nThe crucial step in this method is to find an annulus of relative width 4 in the complex plane that contains no zeros of p and contains approximately as many zeros of p inside as outside of it. Any annulus of this characteristic can be transformed, by translation and scaling of the polynomial, into the annulus between the radii 1/2 and 2 around the origin. But, not every polynomial admits such a splitting annulus.\nTo remedy this situation, the Graeffe iteration is applied. It computes a sequence of polynomials\nwhere the roots of \n\n\n\n\np\n\nj\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{j}(x)}\n\n are the \n\n\n\n\n2\n\nj\n\n\n\n\n{\\displaystyle 2^{j}}\n\n-th dyadic powers of the roots of the initial polynomial p. By splitting \n\n\n\n\np\n\nj\n\n\n(\nx\n)\n=\ne\n(\nx\n)\n+\nx\n\no\n(\nx\n)\n\n\n{\\displaystyle p_{j}(x)=e(x)+x\\,o(x)}\n\n into even and odd parts, the succeeding polynomial is obtained by purely arithmetic operations as \n\n\n\n\np\n\nj\n+\n1\n\n\n(\nx\n)\n=\n(\n\u2212\n1\n\n)\n\ndeg\n\u2061\np\n\n\n(\ne\n(\nx\n\n)\n\n2\n\n\n\u2212\nx\n\no\n(\nx\n\n)\n\n2\n\n\n)\n\n\n{\\displaystyle p_{j+1}(x)=(-1)^{\\deg p}(e(x)^{2}-x\\,o(x)^{2})}\n\n. The ratios of the absolute moduli of the roots increase by the same power \n\n\n\n\n2\n\nj\n\n\n\n\n{\\displaystyle 2^{j}}\n\n and thus tend to infinity. Choosing j large enough one finally finds a splitting annulus of relative width 4 around the origin.\nThe approximate factorization of \n\n\n\n\np\n\nj\n\n\n(\nx\n)\n\u2248\n\nf\n\nj\n\n\n(\nx\n)\n\n\ng\n\nj\n\n\n(\nx\n)\n\n\n{\\displaystyle p_{j}(x)\\approx f_{j}(x)\\,g_{j}(x)}\n\n is now to be lifted back to the original polynomial. To this end an alternation of Newton steps and Pad\u00e9 approximations is used. It is easy to check that\nholds. The polynomials on the left side are known in step j, the polynomials on the right side can be obtained as Pad\u00e9 approximants of the corresponding degrees for the power series expansion of the fraction on the left side.\nMaking use of the Graeffe iteration and any known estimate for the absolute value of the largest root one can find estimates R of this absolute value of any precision. Now one computes estimates for the largest and smallest distances \n\n\n\n\nR\n\nj\n\n\n>\n\nr\n\nj\n\n\n>\n0\n\n\n{\\displaystyle R_{j}>r_{j}>0}\n\n of any root of p(x) to any of the five center points 0, 2R, \u22122R, 2Ri, \u22122Ri and selects the one with the largest ratio \n\n\n\n\nR\n\nj\n\n\n\n/\n\n\nr\n\nj\n\n\n\n\n{\\displaystyle R_{j}/r_{j}}\n\n between the two. By this construction it can be guaranteed that \n\n\n\n\nR\n\nj\n\n\n\n/\n\n\nr\n\nj\n\n\n>\n\ne\n\n0\n\n.\n\n3\n\n\n\u2248\n1.35\n\n\n{\\displaystyle R_{j}/r_{j}>e^{0{.}3}\\approx 1.35}\n\n for at least one center. For such a center there has to be a root-free annulus of relative width \n\n\n\n\n\ne\n\n0\n\n.\n\n3\n\n/\n\nn\n\n\n\u2248\n1\n+\n\n\n\n0\n\n.\n\n3\n\nn\n\n\n\n\n\n{\\displaystyle \\textstyle e^{0{.}3/n}\\approx 1+{\\frac {0{.}3}{n}}}\n\n. After \n\n\n\n\n3\n+\n\nlog\n\n2\n\n\n\u2061\n(\nn\n)\n\n\n\n{\\displaystyle \\textstyle 3+\\log _{2}(n)}\n\n Graeffe iterations, the corresponding annulus of the iterated polynomial has a relative width greater than 11 > 4, as required for the initial splitting described above (see Sch\u00f6nhage (1982)). After \n\n\n\n\n4\n+\n\nlog\n\n2\n\n\n\u2061\n(\nn\n)\n+\n\nlog\n\n2\n\n\n\u2061\n(\n2\n+\n\nlog\n\n2\n\n\n\u2061\n(\nn\n)\n)\n\n\n\n{\\displaystyle \\textstyle 4+\\log _{2}(n)+\\log _{2}(2+\\log _{2}(n))}\n\n Graeffe iterations, the corresponding annulus has a relative width greater than \n\n\n\n\n\n2\n\n13\n\n.\n\n8\n\n\n\u22c5\n\nn\n\n6\n\n.\n\n9\n\n\n>\n(\n64\n\u22c5\n\nn\n\n3\n\n\n\n)\n\n2\n\n\n\n\n\n{\\displaystyle \\textstyle 2^{13{.}8}\\cdot n^{6{.}9}>(64\\cdot n^{3})^{2}}\n\n, allowing a much simplified initial splitting (see Malajovich/Zubelli (1997))\nTo locate the best root-free annulus one uses a consequence of the Rouch\u00e9 theorem: For k = 1, ..., n\u00a0\u2212\u00a01 the polynomial equation\nu > 0, has, by Descartes' rule of signs zero or two positive roots \n\n\n\n\nu\n\nk\n\n\n<\n\nv\n\nk\n\n\n\n\n{\\displaystyle u_{k}<v_{k}}\n\n. In the latter case, there are exactly k roots inside the (closed) disk \n\n\n\nD\n(\n0\n,\n\nu\n\nk\n\n\n)\n\n\n{\\displaystyle D(0,u_{k})}\n\n and \n\n\n\nA\n(\n0\n,\n\nu\n\nk\n\n\n,\n\nv\n\nk\n\n\n)\n\n\n{\\displaystyle A(0,u_{k},v_{k})}\n\n is a root-free (open) annulus.", 
    "dbpedia_url": "http://dbpedia.org/resource/Splitting_circle_method", 
    "wikipedia_url": "http://en.wikipedia.org/wiki/Splitting_circle_method\n"
}